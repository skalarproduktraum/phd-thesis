
@article{:20098th,
  title = {8th {{International Joint Conference}} on {{Autonomous Agents}} and {{Multiagent}}                {{Systems}} ({{AAMAS}} 2009), {{Budapest}}, {{Hungary}}, {{May}} 10-15, 2009, {{Volume}}                2},
  year = {2009}
}

@article{:2018b12,
  title = {{{Noise2Noise}}: {{Learning Image Restoration}} without {{Clean Data}}},
  author = {Lehtinen, Jaakko and Munkberg, Jacob and Hasselgren, Jon and Laine, Samuli and Karras, Tero and Aittala, Miika and Aila, Timo},
  year = {2018},
  abstract = {We apply basic statistical reasoning to signal reconstruction by machine learning -- learning to map corrupted observations to clean signals -- with a simple and powerful conclusion: it is possible to learn to restore images by only looking at corrupted examples, at performance at and sometimes exceeding training using clean data, without explicit image priors or likelihood models of the corruption. In practice, we show that a single model learns photographic noise removal, denoising synthetic Monte Carlo images, and reconstruction of undersampled MRI scans -- all corrupted by different processes -- based on noisy data only.}
}

@article{:delivery,
  title = {Delivery.Acm.Org 7/28/2019, 3:10:37 {{PM}}.Pdf},
  author = {{(} and {E} and {m} and {p} and {t} and {y} and {a} and {u} and {t} and {h} and {o} and {r} and {s} and {)}}
}

@article{:Dynamic,
  title = {Dynamic\_{{Fringe}}-{{Saving}}\_{{A}}.Pdf},
  author = {{(} and {E} and {m} and {p} and {t} and {y} and {a} and {u} and {t} and {h} and {o} and {r} and {s} and {)}}
}

@article{2016PLoSOneEduSPIM,
  title = {{{eduSPIM}}: {{Light Sheet Microscopy}} in the {{Museum}}.},
  author = {Jahr, Wiebke and Schmid, Benjamin and Weber, Michael and Huisken, Jan},
  year = {2016},
  volume = {11},
  doi = {10.1371/journal.pone.0161402},
  abstract = {LIGHT SHEET MICROSCOPY IN THE MUSEUM:Light sheet microscopy (or selective plane illumination microscopy) is an important imaging technique in the life sciences. At the same time, this technique is also ideally suited for community outreach projects, because it produces visually appealing, highly dynamic images of living organisms and its working principle can be understood with basic optics knowledge. Still, the underlying concepts are widely unknown to the non-scientific public. On the occasion of the UNESCO International Year of Light, a technical museum in Dresden, Germany, launched a special, interactive exhibition. We built a fully functional, educational selective plane illumination microscope (eduSPIM) to demonstrate how developments in microscopy promote discoveries in biology. DESIGN PRINCIPLES OF AN EDUCATIONAL LIGHT SHEET MICROSCOPE:To maximize educational impact, we radically reduced a standard light sheet microscope to its essential components without compromising functionality and incorporated stringent safety concepts beyond those needed in the lab. Our eduSPIM system features one illumination and one detection path and a sealed sample chamber. We image fixed zebrafish embryos with fluorescent vasculature, because the structure is meaningful to laymen and visualises the optical principles of light sheet microscopy. Via a simplified interface, visitors acquire fluorescence and transmission data simultaneously. THE EDUSPIM DESIGN IS TAILORED EASILY TO FIT NUMEROUS APPLICATIONS:The universal concepts presented here may also apply to other scientific approaches that are communicated to laymen in interactive settings. The specific eduSPIM design is adapted easily for various outreach and teaching activities. eduSPIM may even prove useful for labs needing a simple SPIM. A detailed parts list and schematics to rebuild eduSPIM are provided.},
  journal = {PLoS ONE},
  number = {8}
}

@article{3Dseg,
  title = {Repository of Static {{3D}}-Meshes},
  journal = {193.48.251.101}
}

@article{Abdellah:2016il,
  title = {Physically-Based Rendering of Highly Scattering Fluorescent Solutions Using Path Tracing},
  author = {Abdellah, M and Bilgili, A and Eilemann, S},
  year = {2016},
  doi = {10.2312/egp.20161045},
  abstract = {... The termVfi is called the path binary fluorescence visibility that c 2016 The Author(s) Eurographics Proceedings c 2016 The Eurographics Association. DOI: 10.2312 / egp . 20161045 Page 2. Marwan Abdellah et al. / Physically ...},
  journal = {Proceedings of the \ldots}
}

@article{Abdellah:2017cq,
  title = {Bio-Physically Plausible Visualization of Highly Scattering Fluorescent Neocortical Models for in Silico Experimentation},
  author = {Abdellah, Marwan and Bilgili, Ahmet and Eilemann, Stefan and Shillcock, Julian and Markram, Henry and Sch{\"u}rmann, Felix},
  year = {2017},
  volume = {18},
  doi = {10.1186/s12859-016-1444-4},
  abstract = {BMC Bioinformatics, 2017, doi:10.1186/s12859-016-1444-4},
  journal = {BMC Bioinformatics},
  number = {S2}
}

@article{achanta2012slic,
  title = {{{SLIC}} Superpixels Compared to State-of-the-Art Superpixel Methods},
  author = {Achanta, Radhakrishna and Shaji, Appu and Smith, Kevin and Lucchi, Aurelien and Fua, Pascal and S{\"u}sstrunk, Sabine},
  year = {2012},
  volume = {34},
  doi = {10.1109/tpami.2012.120},
  journal = {IEEE transactions on pattern analysis and machine intelligence},
  number = {11}
}

@article{adams2011flexible,
  title = {A Flexible Content-Adaptive Mesh-Generation Strategy for Image Representation},
  author = {Adams, Michael D},
  year = {2011},
  volume = {20},
  journal = {IEEE Transactions on Image Processing},
  number = {9}
}

@article{adcock2017infinite,
  title = {Infinite-{{Dimensionalell}}\^ 1 {{Minimization}} and {{Function Approximation}} from {{Pointwise Data}}},
  author = {Adcock, Ben},
  year = {2017},
  volume = {45},
  journal = {Constructive Approximation},
  number = {3}
}

@article{adelson1984pyramid,
  title = {Pyramid Methods in Image Processing},
  author = {Adelson, Edward H and Anderson, Charles H and Bergen, James R and Burt, Peter J and Ogden, Joan M},
  year = {1984},
  volume = {29},
  journal = {RCA engineer},
  number = {6}
}

@article{Adrian:1984vv,
  title = {Cryo-Electron Microscopy of Viruses.},
  author = {Adrian, Marc and Dubochet, Jacques and Lepault, Jean and McDowall, Alasdair W.},
  year = {1984},
  volume = {308},
  doi = {10.1038/308032a0},
  abstract = {Thin vitrified layers of unfixed, unstained and unsupported virus suspensions can be prepared for observation by cryo-electron microscopy in easily controlled conditions. The viral particles appear free from the kind of damage caused by dehydration, freezing or adsorption to a support that is encountered in preparing biological samples for conventional electron microscopy. Cryo-electron microscopy of vitrified specimens offers possibilities for high resolution observations that compare favourably with any other electron microscopical method.},
  journal = {Nature},
  number = {5954}
}

@article{Afshar:2016gm,
  title = {A {{Parallel Distributed}}-{{Memory Particle Method Enables Acquisition}}-{{Rate Segmentation}} of {{Large Fluorescence Microscopy Images}}.},
  author = {Afshar, Yaser and Sbalzarini, Ivo F},
  year = {2016},
  volume = {11},
  doi = {10.1371/journal.pone.0152528},
  abstract = {Modern fluorescence microscopy modalities, such as light-sheet microscopy, are capable of acquiring large three-dimensional images at high data rate. This creates a bottleneck in computational processing and analysis of the acquired images, as the rate of acquisition outpaces the speed of processing. Moreover, images can be so large that they do not fit the main memory of a single computer. We address both issues by developing a distributed parallel algorithm for segmentation of large fluorescence microscopy images. The method is based on the versatile Discrete Region Competition algorithm, which has previously proven useful in microscopy image segmentation. The present distributed implementation decomposes the input image into smaller sub-images that are distributed across multiple computers. Using network communication, the computers orchestrate the collectively solving of the global segmentation problem. This not only enables segmentation of large images (we test images of up to 1010 pixels), but also accelerates segmentation to match the time scale of image acquisition. Such acquisition-rate image segmentation is a prerequisite for the smart microscopes of the future and enables online data compression and interactive experiments.},
  journal = {PLoS ONE},
  number = {4}
}

@article{afshar2016parallel,
  title = {A Parallel Distributed-Memory Particle Method Enables Acquisition-Rate Segmentation of Large Fluorescence Microscopy Images},
  author = {Afshar, Yaser and Sbalzarini, Ivo F},
  year = {2016},
  volume = {11},
  journal = {PLoS ONE},
  number = {4}
}

@article{agarwal1998surface,
  title = {Surface Approximation and Geometric Partitions},
  author = {Agarwal, Pankaj K and Suri, Subhash},
  year = {1998},
  volume = {27},
  journal = {SIAM Journal on Computing},
  number = {4}
}

@article{Airey:1990151,
  title = {Towards Image Realism with Interactive Update Rates in Complex Virtual Building Environments},
  author = {Airey, John M and Rohlf, John H and Brooks, Frederick P},
  year = {1990},
  volume = {24},
  doi = {10.1145/91385.91416},
  journal = {ACM SIGGRAPH Computer Graphics},
  number = {2}
}

@article{al-awamiNeuroBlocksVisualTracking2015,
  title = {{{NeuroBlocks}} - {{Visual Tracking}} of {{Segmentation}} and {{Proofreading}} for {{Large Connectomics Projects}}},
  author = {{Al-Awami}, Ali K. and Beyer, Johanna and Haehn, Daniel and Kasthuri, Narayanan and Lichtman, Jeff W. and Pfister, Hanspeter and Hadwiger, Markus},
  year = {2015},
  volume = {22},
  doi = {10.1109/tvcg.2015.2467441},
  abstract = {In the field of connectomics, neuroscientists acquire electron microscopy volumes at nanometer resolution in order to reconstruct a detailed wiring diagram of the neurons in the brain. The resulting image volumes, which often are hundreds of terabytes in size, need to be segmented to identify cell boundaries, synapses, and important cell organelles. However, the segmentation process of a single volume is very complex, time-intensive, and usually performed using a diverse set of tools and many users. To tackle the associated challenges, this paper presents NeuroBlocks, which is a novel visualization system for tracking the state, progress, and evolution of very large volumetric segmentation data in neuroscience. NeuroBlocks is a multi-user web-based application that seamlessly integrates the diverse set of tools that neuroscientists currently use for manual and semi-automatic segmentation, proofreading, visualization, and analysis. NeuroBlocks is the first system that integrates this heterogeneous tool set, providing crucial support for the management, provenance, accountability, and auditing of large-scale segmentations. We describe the design of NeuroBlocks, starting with an analysis of the domain-specific tasks, their inherent challenges, and our subsequent task abstraction and visual representation. We demonstrate the utility of our design based on two case studies that focus on different user roles and their respective requirements for performing and tracking the progress of segmentation and proofreading in a large real-world connectomics project.},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  number = {1}
}

@article{almgren1998conservative,
  title = {A Conservative Adaptive Projection Method for the Variable Density Incompressible {{Navier}}--{{Stokes}} Equations},
  author = {Almgren, Ann S and Bell, John B and Colella, Phillip and Howell, Louis H and Welcome, Michael L},
  year = {1998},
  volume = {142},
  journal = {Journal of Computational Physics},
  number = {1}
}

@article{alted2017blosc,
  title = {Blosc, an Extremely Fast, Multi-Threaded, Meta-Compressor Library},
  author = {Alted, F},
  year = {2017},
  journal = {github.com}
}

@article{amat2012fast,
  title = {Fast and Robust Optical Flow for Time-Lapse Microscopy Using Super-Voxels},
  author = {Amat, Fernando and Myers, Eugene W and Keller, Philipp J},
  year = {2012},
  volume = {29},
  doi = {10.1093/bioinformatics/bts706},
  journal = {Bioinformatics},
  number = {3}
}

@article{amat2013towards,
  title = {Towards Comprehensive Cell Lineage Reconstructions in Complex Organisms Using Light-Sheet Microscopy},
  author = {Amat, Fernando and Keller, Philipp J},
  year = {2013},
  volume = {55},
  journal = {Development, Growth \& Differentiation},
  number = {4}
}

@article{amat2014,
  title = {Fast, Accurate Reconstruction of Cell Lineages from Large-Scale Fluorescence Microscopy Data},
  author = {Amat, Fernando and Lemon, William and Mossing, Daniel P and McDole, Katie and Wan, Yinan and Branson, Kristin and Myers, Eugene W and Keller, Philipp J},
  year = {2014},
  volume = {11},
  doi = {10.1038/nmeth.3036},
  abstract = {The comprehensive reconstruction of cell lineages in complex multicellular organisms is a central goal of developmental biology. We present an open-source computational framework for the segmentation and tracking of cell nuclei with high accuracy and speed. We demonstrate its (i) generality by reconstructing cell lineages in four-dimensional, terabyte-sized image data sets of fruit fly, zebrafish and mouse embryos acquired with three types of fluorescence microscopes, (ii) scalability by analyzing advanced stages of development with up to 20,000 cells per time point at 26,000 cells min-1 on a single computer workstation and (iii) ease of use by adjusting only two parameters across all data sets and providing visualization and editing tools for efficient data curation. Our approach achieves on average 97.0\% linkage accuracy across all species and imaging modalities. Using our system, we performed the first cell lineage reconstruction of early Drosophila melanogaster nervous system development, revealing neuroblast dynamics throughout an entire embryo.},
  journal = {Nature Methods},
  number = {9}
}

@article{amat2014fast,
  title = {Fast, Accurate Reconstruction of Cell Lineages from Large-Scale Fluorescence Microscopy Data},
  author = {Amat, Fernando and Lemon, William and Mossing, Daniel P and McDole, Katie and Wan, Yinan and Branson, Kristin and Myers, Eugene W and Keller, Philipp J},
  year = {2014},
  journal = {Nature Methods}
}

@article{amat2015efficient,
  title = {Efficient Processing and Analysis of Large-Scale Light-Sheet Microscopy Data},
  author = {Amat, Fernando and H{\"o}ckendorf, Burkhard and Wan, Yinan and Lemon, William C and McDole, Katie and Keller, Philipp J},
  year = {2015},
  volume = {10},
  journal = {Nature Protocols},
  number = {11}
}

@article{amoresHoloARtPaintingHolograms2017,
  title = {{{HoloARt}}: {{Painting}} with {{Holograms}} in {{Mixed Reality}}},
  author = {Amores, Judith and Lanier, Jaron},
  year = {2017},
  abstract = {We propose HoloARt, a new media art that explores the use of holograms in mixed reality for creative self expression. We designed a system that allows the user to turn their physical environment into a canvas where digital holograms and physical objects co-exist in the real and virtual world. Users are able to virtually spray and splatter hologram paint on top of physical objects and surfaces as well as painting in the air by only using their hands. The content grows dynamically, following the natural movements of the user. The system is self-contained and does not require hand controllers nor positional tracking sensors on the space.}
}

@article{AndujarGran:2017wx,
  title = {A Multi-Projector {{CAVE}} System with Commodity Hardware and Gesture-Based Interaction},
  author = {Gran, Carlos Antonio And{\'u}jar and Crosa, Pere Brunet and Pla, {\'A}lvaro Vinacua and Moya, Miguel {\'A}ngel Vico and Garc{\'i}a, Jes{\'u}s D{\'i}az},
  year = {2017},
  abstract = {Spatially-immersive systems such as CAVEs provide users with surrounding worlds by projecting 3D models on multiple screens around the viewer. Compared to alternative immersive systems such as HMDs, CAVE systems are a powerful tool for collaborative inspection of virtual environments due to better use of peripheral vision, less sensitivity to tracking errors, and higher communication possibilities among users. Unfortunately, traditional CAVE setups require sophisticated equipment including stereo-ready projectors and tracking systems with high acquisition and maintenance costs. In this paper we present the design and construction of a passive-stereo, four-wall CAVE system based on commodity hardware. Our system works with any mix of a wide range of projector models that can be replaced independently at any time, and achieves high resolution and brightness at a minimum cost. The key ingredients of our CAVE are a self-calibration approach that guarantees continuity across the screen, as well as a gesture-based interaction approach based on a clever  combination of skeletal data from multiple Kinect sensors.}
}

@article{Anonymous:2009fx,
  title = {{{CATMAID}}: Collaborative Annotation Toolkit for Massive Amounts of Image Data.},
  author = {Saalfeld, Stephan and Cardona, Albert and Hartenstein, Volker and Tomancak, Pavel},
  year = {2009},
  volume = {25},
  doi = {10.1093/bioinformatics/btp266},
  abstract = {SUMMARY:High-resolution, three-dimensional (3D) imaging of large biological specimens generates massive image datasets that are difficult to navigate, annotate and share effectively. Inspired by online mapping applications like GoogleMaps, we developed a decentralized web interface that allows seamless navigation of arbitrarily large image stacks. Our interface provides means for online, collaborative annotation of the biological image data and seamless sharing of regions of interest by bookmarking. The CATMAID interface enables synchronized navigation through multiple registered datasets even at vastly different scales such as in comparisons between optical and electron microscopy. AVAILABILITY:http://fly.mpi-cbg.de/catmaid.},
  journal = {Bioinformatics},
  number = {15}
}

@article{Anonymous:48d,
  title = {Iris\_seg\_chapter.Pdf},
  author = {{(} and {E} and {m} and {p} and {t} and {y} and {a} and {u} and {t} and {h} and {o} and {r} and {s} and {)}}
}

@article{Anonymous:877,
  title = {An {{Algorithmic Information Calculus}} for {{Causal Discovery}} and {{Reprogramming Systems}}},
  author = {Zenil, Hector and Kiani, Narsis A. and Marabita, Francesco and Deng, Yue and Elias, Szabolcs and Schmidt, Angelika and Ball, Gordon and Tegner, Jesper},
  year = {2018},
  doi = {10.1101/185637},
  abstract = {We introduce a conceptual framework and an interventional calculus to steer, manipulate, and reconstruct the dynamics and generating mechanisms of non-linear dynamical systems from partial and disordered observations based on the algorithmic contribution of each of the systems elements to the whole by exploiting principles from the theory of computability and algorithmic randomness. This calculus entails finding and applying controlled interventions to an evolving object to estimate how its algorithmic information content is affected in terms of positive or negative shifts towards and away from randomness in connection to causation. The approach is an alternative to statistical approaches for inferring causal relationships and formulating theoretical expectations from perturbation analysis. We find that the algorithmic information landscape of a system runs parallel to its dynamic landscape, affording an avenue for moving systems on one plane so they may have controlled effects on the other plane. Based on these methods, we advance tools for reprogramming a system that do not require full knowledge or access to the system's actual kinetic equations or to probability distributions. This new approach yields a suite of powerful parameter-free algorithms of wide applicability, ranging from the discovery of causality, dimension reduction, feature selection, model generation, a maximal algorithmic-randomness principle and a system's (re)programmability index. We apply these methods to static (e.coli Transcription Factor network) and to evolving genetic regulatory networks (differentiating naive from Th17 cells, and the CellNet database). We highlight the capability of the methods to pinpoint key elements related to cell function and cell development, conforming with biological knowledge and experimentally validated data, and demonstrate how the method can reshape a system's dynamics in a controlled manner through algorithmic causal mechanisms.},
  journal = {bioRxiv}
}

@article{Anonymous:9ef,
  title = {535187a (Corrected).Pdf},
  author = {{(} and {E} and {m} and {p} and {t} and {y} and {a} and {u} and {t} and {h} and {o} and {r} and {s} and {)}}
}

@article{Anonymous:b12,
  title = {Mars {{Terrain Image Classification}} Using {{Cartesian Genetic Programming}}},
  author = {J., Leitner and S., Harding and A., Foerster and J., Schmidhuber}
}

@article{Anonymous:c8b,
  title = {Irisrecog.Pdf},
  author = {{(} and {E} and {m} and {p} and {t} and {y} and {a} and {u} and {t} and {h} and {o} and {r} and {s} and {)}}
}

@article{arrayfire2015,
  title = {{{ArrayFire Library}}},
  author = {A, r},
  year = {2015},
  journal = {arrayfire.com}
}

@article{Arthur:199845f,
  title = {Designing and Building the Pit: A Head-Tracked Stereo Workspace for Two Users},
  author = {Arthur, Kevin and Preston, Timothy and Taylor, Russell and Brooks, Frederick and Whitton, Mary and Wright, William},
  year = {1998},
  journal = {2nd International Immersive Projection Technology Workshop}
}

@inproceedings{ashtiani2010,
  title = {{{BlinkWrite2}}: An Improved Text Entry Method Using Eye Blinks},
  shorttitle = {{{BlinkWrite2}}},
  booktitle = {Proceedings of the 2010 {{Symposium}} on {{Eye}}-{{Tracking Research}} \& {{Applications}} - {{ETRA}} '10},
  author = {Ashtiani, Behrooz and MacKenzie, I. Scott},
  year = {2010},
  pages = {339},
  publisher = {{ACM Press}},
  address = {{Austin, Texas}},
  doi = {10.1145/1743666.1743742},
  language = {en}
}

@article{awile2012fast,
  title = {Fast Neighbor Lists for Adaptive-Resolution Particle Simulations},
  author = {Awile, Omar and B{\"u}y{\"u}kke{\c c}eci, Ferit and Reboux, Sylvain and Sbalzarini, Ivo F},
  year = {2012},
  volume = {183},
  journal = {Computer Physics Communications},
  number = {5}
}

@article{ayachit2015paraview,
  title = {The Paraview Guide: A Parallel Visualization Application},
  author = {Ayachit, Utkarsh},
  year = {2015}
}

@article{babuska1995partition,
  title = {The Partition of Unity Finite Element Method},
  author = {Babuska, Ivo and Melenk, Jens M},
  year = {1995}
}

@article{babuvska1979direct,
  title = {Direct and Inverse Error Estimates for Finite Elements with Mesh Refinements},
  author = {Babu{\v s}ka, Ivo and Kellogg, R B and Pitk{\"a}ranta, J},
  year = {1979},
  volume = {33},
  journal = {Numerische Mathematik},
  number = {4}
}

@article{babuvska1992h,
  title = {The h, p and Hp Version of the Finite Element Method; Basis Theory and Applications},
  author = {Babu{\v s}ka, Ivo and Guo, B Q},
  year = {1992},
  volume = {15},
  journal = {Advances in Engineering Software},
  number = {3-4}
}

@article{balazs2017real,
  title = {A Real-Time Compression Library for Microscopy Images},
  author = {Balazs, Balint and Deschamps, Joran and Albert, Marvin and Ries, Jonas and Hufnagel, Lars},
  year = {2017},
  journal = {bioRxiv}
}

@incollection{Barron:2016Attention,
  title = {Attention {{Networks}}},
  booktitle = {Neuroscience in the 21st {{Century}}},
  author = {Barron, Daniel S. and Castellanos, Francisco Xavier},
  editor = {Pfaff, Donald W. and Volkow, Nora D.},
  year = {2016},
  pages = {1705--1719},
  publisher = {{Springer New York}},
  address = {{New York, NY}},
  doi = {10.1007/978-1-4939-3474-4_177},
  isbn = {978-1-4939-3473-7 978-1-4939-3474-4},
  language = {en}
}

@article{bastug2016,
  title = {Toward {{Interconnected Virtual Reality}}: {{Opportunities}}, {{Challenges}}, and {{Enablers}}},
  author = {Bastug, Ejder and Bennis, Mehdi and Medard, Muriel and Debbah, Merouane},
  year = {2017},
  volume = {55},
  doi = {10.1109/mcom.2017.1601089},
  abstract = {Just recently, the concept of augmented and virtual reality (AR/VR) over wireless has taken the entire 5G ecosystem by storm, spurring an unprecedented interest from academia, industry, and others. However, the success of an immersive VR experience hinges on solving a plethora of grand challenges cutting across multiple disciplines. This article underscores the importance of VR technology as a disruptive use case of 5G (and beyond) harnessing the latest development of storage/ memory, fog/edge computing, computer vision, artificial intelligence, and others. In particular, the main requirements of wireless interconnected VR are described followed by a selection of key enablers; then research avenues and their underlying grand challenges are presented. Furthermore, we examine three VR case studies and provide numerical results under various storage, computing, and network configurations. Finally, this article exposes the limitations of current networks and makes the case for more theory, and innovations to spearhead VR for the masses.},
  journal = {IEEE Communications Magazine},
  number = {6}
}

@article{Bavoil:2008a61,
  title = {Image-Space Horizon-Based Ambient Occlusion},
  author = {Bavoil, Louis and Sainz, Miguel and Dimitrov, Rouslan},
  year = {2008},
  journal = {ACM SIGGRAPH 2008 talks}
}

@article{Bayer:2002ds,
  title = {Organization and Maintenance of Large Ordered Indexes},
  author = {Bayer, Rudolf and McCreight, Edward M.},
  year = {1972},
  volume = {1},
  pages = {173--189},
  issn = {0001-5903, 1432-0525},
  doi = {10.1007/BF00288683},
  journal = {Acta Informatica},
  language = {en},
  number = {3}
}

@article{berger1989local,
  title = {Local Adaptive Mesh Refinement for Shock Hydrodynamics},
  author = {Berger, Marsha J and Colella, Phillip},
  year = {1989},
  volume = {82},
  journal = {Journal of Computational Physics},
  number = {1}
}

@incollection{berthold2008,
  title = {{{KNIME}}: {{The Konstanz Information Miner}}},
  shorttitle = {{{KNIME}}},
  booktitle = {Data {{Analysis}}, {{Machine Learning}} and {{Applications}}},
  author = {Berthold, Michael R. and Cebron, Nicolas and Dill, Fabian and Gabriel, Thomas R. and K{\"o}tter, Tobias and Meinl, Thorsten and Ohl, Peter and Sieb, Christoph and Thiel, Kilian and Wiswedel, Bernd},
  editor = {Preisach, Christine and Burkhardt, Hans and {Schmidt-Thieme}, Lars and Decker, Reinhold},
  year = {2008},
  pages = {319--326},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-540-78246-9_38},
  isbn = {978-3-540-78239-1 978-3-540-78246-9}
}

@article{bertoluzza1996wavelet,
  title = {A Wavelet Collocation Method for the Numerical Solution of Partial Differential Equations},
  author = {Bertoluzza, S and Naldi, G},
  year = {1996},
  volume = {3},
  journal = {Applied and Computational Harmonic Analysis},
  number = {1}
}

@article{Beyer:2008Smooth,
  title = {Smooth {{Mixed}}-{{Resolution GPU Volume Rendering}}},
  author = {Beyer, Johanna and Hadwiger, Markus and M{\"o}ller, Torsten and Fritz, Laura},
  year = {2008}
}

@article{Bisley:2011cad,
  title = {The Neural Basis of Visual Attention},
  author = {Bisley, James W.},
  year = {2011},
  volume = {589},
  doi = {10.1113/jphysiol.2010.192666},
  abstract = {Visual attention is the mechanism the nervous system uses to highlight specific locations, objects or features within the visual field. This can be accomplished by making an eye movement to bring the object onto the fovea (overt attention) or by increased processing of visual information in neurons representing more peripheral regions of the visual field (covert attention). This review will examine two aspects of visual attention: the changes in neural responses within visual cortices due to the allocation of covert attention; and the neural activity in higher cortical areas involved in guiding the allocation of attention. The first section will highlight processes that occur during visual spatial attention and feature-based attention in cortical visual areas and several related models that have recently been proposed to explain this activity. The second section will focus on the parietofrontal network thought to be involved in targeting eye movements and allocating covert attention. It will describe evidence that the lateral intraparietal area, frontal eye field and superior colliculus are involved in the guidance of visual attention, and describe the priority map model, which is thought to operate in at least several of these areas.},
  journal = {The Journal of Physiology},
  number = {1}
}

@inproceedings{Bonetta:2018GraalVM,
  ids = {bonettaGraalVMMetaprogrammingPolyglot2018},
  title = {{{GraalVM}}: Metaprogramming inside a Polyglot System (Invited Talk)},
  author = {Bonetta, Daniele},
  year = {2018},
  abstract = {GraalVM is a polyglot virtual machine for running applications written in a variety of languages such as JavaScript, Ruby, Python, R, JVM-based languages like Java, Scala, Kotlin, and LLVM-based languages such as C and C++. GraalVM enables interoperability between different programming languages in a shared runtime, and can run either standalone or embedded in other software systems such as Node.js, the Oracle RDBMS, and MySQL. In this talk I will give an overview of GraalVM and present how polyglot features such as language interoperability and language-agnostic instrumentation are enabled in GraalVM by means of VM-internal metaprogramming.}
}

@article{Boothe:20178ad,
  title = {A Tunable Refractive Index Matching Medium for Live Imaging Cells, Tissues and Model Organisms},
  author = {Boothe, Tobias and Hilbert, Lennart and Heide, Michael and Berninger, Lea and Huttner, Wieland B and Zaburdaev, Vasily and Vastenhouw, Nadine L and Myers, Eugene W and Drechsel, David N and Rink, Jochen C},
  year = {2017},
  volume = {6},
  doi = {10.7554/elife.27240},
  abstract = {In light microscopy, refractive index mismatches between media and sample cause spherical aberrations that often limit penetration depth and resolution. Optical clearing techniques can alleviate these mismatches, but they are so far limited to fixed samples. We present Iodixanol as a non-toxic medium supplement that allows refractive index matching in live specimens and thus a substantial improvement of the live-imaging of primary cell cultures, planarians, zebrafish and human cerebral organoids.},
  journal = {eLife}
}

@article{Bostock:2011da,
  title = {D\&amp;\#{{x0B3}}; {{Data}}-{{Driven Documents}}},
  author = {Bostock, M. and Ogievetsky, V. and Heer, J.},
  year = {2011},
  volume = {17},
  doi = {10.1109/tvcg.2011.185},
  abstract = {Data-Driven Documents (D3) is a novel representation-transparent approach to visualization for the web. Rather than hide the underlying scenegraph within a toolkit-specific abstraction, D3 enables direct inspection and manipulation of a native representation: the standard document object model (DOM). With D3, designers selectively bind input data to arbitrary document elements, applying dynamic transforms to both generate and modify content. We show how representational transparency improves expressiveness and better integrates with developer tools than prior approaches, while offering comparable notational efficiency and retaining powerful declarative components. Immediate evaluation of operators further simplifies debugging and allows iterative development. Additionally, we demonstrate how D3 transforms naturally enable animation and interaction with dramatic performance improvements over intermediate representations.},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  number = {12}
}

@inproceedings{boudier2015,
  title = {{{GPU Driven Large Scene Rendering}}},
  booktitle = {{{GPU Technology Conference}}},
  author = {Boudier, Pierre and Kubisch, Cristoph},
  year = {2015},
  address = {{San Jose}}
}

@article{Boyden:2005cd,
  title = {Millisecond-Timescale, Genetically Targeted Optical Control of Neural Activity.},
  author = {Boyden, Edward S and Zhang, Feng and Bamberg, Ernst and Nagel, Georg and Deisseroth, Karl},
  year = {2005},
  volume = {8},
  doi = {10.1038/nn1525},
  abstract = {Temporally precise, noninvasive control of activity in well-defined neuronal populations is a long-sought goal of systems neuroscience. We adapted for this purpose the naturally occurring algal protein Channelrhodopsin-2, a rapidly gated light-sensitive cation channel, by using lentiviral gene delivery in combination with high-speed optical switching to photostimulate mammalian neurons. We demonstrate reliable, millisecond-timescale control of neuronal spiking, as well as control of excitatory and inhibitory synaptic transmission. This technology allows the use of light to alter neural processing at the level of single spikes and synaptic events, yielding a widely applicable tool for neuroscientists and biomedical engineers.},
  journal = {Nature Neuroscience},
  number = {9}
}

@article{boykov2004experimental,
  title = {An Experimental Comparison of Min-Cut/Max-Flow Algorithms for Energy Minimization in Vision},
  author = {Boykov, Yuri and Kolmogorov, Vladimir},
  year = {2004},
  volume = {26},
  journal = {IEEE transactions on pattern analysis and machine intelligence},
  number = {9}
}

@book{breiman1984classification,
  title = {Classification and Regression Trees},
  author = {Breiman, Leo and Friedman, Jerome and Stone, Charles J and Olshen, Richard A},
  year = {1984}
}

@article{brenner2000adaptive,
  title = {Adaptive Rescaling Maximizes Information Transmission},
  author = {Brenner, Naama and Bialek, William and Steveninck, Rob de Ruyter Van},
  year = {2000},
  volume = {26},
  journal = {Neuron},
  number = {3}
}

@article{brevis2019,
  title = {Kephale/Brevis 0.10.4},
  author = {Harrington, Kyle I.S. and Stiles, Tim},
  year = {2017},
  doi = {10.5281/zenodo.822902},
  journal = {Github}
}

@article{Bria:2016fl,
  title = {{{TeraFly}}: Real-Time Three-Dimensional Visualization and Annotation of Terabytes of Multidimensional Volumetric Images},
  author = {Bria, Alessandro and Iannello, Giulio and Onofri, Leonardo and Peng, Hanchuan},
  year = {2016},
  volume = {13},
  doi = {10.1038/nmeth.3767},
  abstract = {Nature Methods 13, 192 (2016). doi:10.1038/nmeth.3767},
  journal = {Nature Methods},
  number = {3}
}

@article{brockmann1993locally,
  title = {Locally Adaptive Bandwidth Choice for Kernel Regression Estimators},
  author = {Brockmann, Michael and Gasser, Theo and Herrmann, Eva},
  year = {1993},
  volume = {88},
  journal = {Journal of the American Statistical Association},
  number = {424}
}

@incollection{Brooke:1996SUS,
  title = {{{SUS}} - {{A}} Quick and Dirty Usability Scale},
  booktitle = {Usability {{Evaluation In Industry}}},
  author = {Brooke, John},
  year = {1996},
  month = jun,
  pages = {7},
  publisher = {{CRC Press}},
  abstract = {Usability does not exist in any absolute sense; it can only be defined with reference to particular contexts. This, in turn, means that there are no absolute measures of usability, since, if the usability of an artefact is defined by the context in which that artefact is used, measures of usability must of necessity be defined by that context too. Despite this, there is a need for broad general measures which can be used to compare usability across a range of contexts. In addition, there is a need for ``quick and dirty'' methods to allow low cost assessments of usability in industrial systems evaluation. This chapter describes the System Usability Scale (SUS) a reliable, low-cost usability scale that can be used for global assessments of systems usability.},
  isbn = {978-0-7484-0460-5},
  language = {en}
}

@book{Brooks:1988bi,
  title = {Grasping Reality through Illusion\textemdash Interactive Graphics Serving Science},
  author = {Brooks, F P},
  year = {1988},
  abstract = {I treat three related subjects: virtual-worlds research\textemdash the construction of real-time 3-D illusions by computer graphics; some observations about interfaces to virtual worlds; and the coming application of virtual-worlds techniques to the enhancement of scientific computing. We need to design generalized interfaces for visualizing, exploring, and steering scientific computations. Our interfaces must be direct-manipulation, not command-string; interactive, not batch; 3-D, not 2-D; multisensory, not just visual. We need generalized research results~\ldots},
  isbn = {0-201-14237-6}
}

@article{Brooks:1990be2,
  title = {Project {{GROPEHaptic}} Displays for Scientific Visualization},
  author = {Brooks, Frederick P. and {Ouh-Young}, Ming and Batter, James J. and Kilpatrick, P. Jerome},
  year = {1990},
  volume = {24},
  doi = {10.1145/97879.97899},
  abstract = {We began in 1967 a project to develop a haptic+display for 6-D force fields of interacting protein molecules. We approached it in four stages: a 2-D system, a 3-D system tested with a simple task, a 6-D system tested with a simple task, and a full 6-D molecular docking system, our initial goal. This paper summarizes the entire project---the four systems, the evaluation experiments, the results, and our observations. The molecular docking system results are new.Our principal conclusions are:\&amp;bull; Haptic display as an augmentation to visual display can improve perception and understanding both of force fields and of world models populated with impenetrable objects.\&amp;bull; Whereas man-machine systems can outperform computer-only systems by orders of magnitude on some problems, haptic-augmented interactive systems seem to give about a two-fold performance improvement over purely graphical interactive systems. Better technology may give somewhat more, but a ten-fold improvement does not seem to be in the cards.\&amp;bull; Chemists using GROPE-III can readily reproduce the true docking positions for drugs whose docking is known (but not to them) and can find very good docks for drugs whose true docks are unknown. The present tool promises to yield new chemistry research results; it is being actively used by research chemists.\&amp;bull; The most valuable result from using GROPE-III for drug docking is probably the radically improved situation awareness that serious users report. Chemists say they have a new understanding of the details of the receptor site and its force fields, and of why a particular drug docks well or poorly.\&amp;bull; We see various scientific/education applications for haptic displays but believe entertainment, not scientific visualization, will drive and pace the technology.\&amp;bull; The hardware-software system technology we have used is barely adequate, and our experience sets priorities for future development.\&amp;bull; Some unexpected perceptual phenomena were observed. All of these worked for us, not against us.},
  journal = {ACM SIGGRAPH Computer Graphics},
  number = {4}
}

@article{Brooks:2010wb,
  title = {The {{Design}} of {{Design}}},
  author = {Brooks, F P},
  year = {2010},
  abstract = {Making Sense of Design Effective design is at the heart of everything from software development to engineering to architecture. But what do we really know about the design process? What leads to effective, elegant designs? The Design of Design addresses these questions. These new essays by Fred Brooks contain extraordinary insights for designers in every discipline. Brooks pinpoints constants inherent in all design projects and uncovers processes and patterns likely to lead to excellence. Drawing on conversations with dozens~\ldots}
}

@inproceedings{bruder2019,
  title = {Voronoi-Based {{Foveated Volume Rendering}}},
  booktitle = {{{EUROVIS}} 2019},
  author = {Bruder, Valentin and Schulz, Christoph and Bauer, Ruben and Frey, Steffen and Weiskopf, Daniel and Ertl, Thomas},
  year = {2019},
  address = {{Porto, Portugal}},
  abstract = {Foveal vision is located in the center of the field of view with a rich impression of detail and color, whereas peripheral vision occurs on the side with more fuzzy and colorless perception. This visual acuity fall-off can be used to achieve higher frame rates by adapting rendering quality to the human visual system. Volume raycasting has unique characteristics, preventing a direct transfer of many traditional foveated rendering techniques. We present an approach that utilizes the visual acuity fall-off to accelerate volume rendering based on Linde-Buzo-Gray sampling and natural neighbor interpolation. First, we measure gaze using a stationary 1200 Hz eye-tracking system. Then, we adapt our sampling and reconstruction strategy to that gaze. Finally, we apply a temporal smoothing filter to attenuate undersampling artifacts since peripheral vision is particularly sensitive to contrast changes and movement. Our approach substantially improves rendering performance with barely perceptible changes in visual quality. We demonstrate the usefulness of our approach through performance measurements on various data sets.}
}

@article{Brugues:2012fx,
  title = {Nucleation and {{Transport Organize Microtubules}} in {{Metaphase Spindles}}},
  author = {Brugu{\'e}s, Jan and Nuzzo, Valeria and Mazur, Eric and Needleman, Daniel J},
  year = {2012},
  volume = {149},
  doi = {10.1016/j.cell.2012.03.027},
  abstract = {Spindles are arrays of microtubules that segregate chromosomes during cell division. It has been difficult to validate models of spindle assembly due to a lack of information on the organization of microtubules in these structures. Here we present a method, based on femtosecond laser ablation, capable of measuring the detailed architecture of spindles. We used this method to study the metaphase spindle in Xenopus laevis egg extracts and found that microtubules are shortest near poles and become progressively longer toward the center of the spindle. These data, in combination with mathematical modeling, imaging, and biochemical perturbations, are sufficient to reject previously proposed mechanisms of spindle assembly. Our results support a model of spindle assembly in which microtubule polymerization dynamics are not spatially regulated, and the proper organization of microtubules in the spindle is determined by nonuniform microtubule nucleation and the local sorting of microtubules by transport.},
  journal = {Cell},
  number = {3}
}

@inproceedings{Bryson:19942f4,
  title = {Research Frontiers in Virtual Reality},
  booktitle = {Proceedings of the 21st Annual Conference on {{Computer}} Graphics and Interactive Techniques  - {{SIGGRAPH}} '94},
  author = {Bryson, Steve and Feiner, Steven K. and Brooks, Frederick P. and Hubbard, Philip and Pausch, Randy and {van Dam}, Andries},
  year = {1994},
  pages = {473--474},
  publisher = {{ACM Press}},
  doi = {10.1145/192161.192287},
  isbn = {978-0-89791-667-7},
  language = {en}
}

@article{brysonResearchFrontiersVirtual1994,
  title = {Research Frontiers in Virtual Reality},
  author = {Bryson, Steve and Feiner, Steven K. and Jr., Frederick P. Brooks and Hubbard, Philip and Pausch, Randy and van Dam, Andries},
  year = {1994},
  abstract = {An abstract is not available.}
}

@article{bulling2016,
  title = {Pervasive {{Attentive User Interfaces}}},
  author = {Bulling, Andreas},
  year = {2016},
  volume = {49},
  doi = {10.1109/mc.2016.32},
  abstract = {As the number of displays we interact with rapidly increases, managing user attention has emerged as a critical challenge for next-generation human-computer interfaces.},
  journal = {Computer},
  number = {1}
}

@article{burchard1974splines,
  title = {Splines (with Optimal Knots) Are Better},
  author = {Burchard, Hermann G},
  year = {1974},
  volume = {3},
  journal = {Applicable Analysis},
  number = {4}
}

@article{burt1983laplacian,
  title = {The {{Laplacian}} Pyramid as a Compact Image Code},
  author = {Burt, Peter and Adelson, Edward},
  year = {1983},
  volume = {31},
  journal = {IEEE Transactions on communications},
  number = {4}
}

@article{Buschel:2019a5d,
  title = {Augmented {{Reality Graph Visualizations}}: {{Investigation}} of {{Visual Styles}} in {{3D Node}}-{{Link Diagrams}}},
  author = {B{\"u}schel, Wolfgang and Vogt, Stefan and Dachselt, Raimund},
  year = {2019},
  volume = {PP},
  doi = {10.1109/mcg.2019.2897927},
  abstract = {3D Node-link diagrams are an important class of visualization for immersive analysis. Yet, there is little knowledge on how to visualize edges to support efficient analysis. We present an exploration of the design space for edge styles and discuss the results of a user study comparing six different edge variants.},
  journal = {IEEE Computer Graphics and Applications},
  number = {99}
}

@article{cao2015real,
  title = {Real-Time Deconvolution with {{GPU}} and Spark for Big Imaging Data Analysis},
  author = {Cao, Lianyu and Juan, Penghui and Zhang, Yinghua},
  year = {2015},
  journal = {International Conference on Algorithms and Architectures for Parallel Processing}
}

@article{Card:1980kl,
  title = {The Keystroke-Level Model for User Performance Time with Interactive Systems},
  author = {Card, Stuart K. and Moran, Thomas P. and Newell, Allen},
  year = {1980},
  volume = {23},
  doi = {10.1145/358886.358895},
  abstract = {An abstract is not available.},
  journal = {Communications of the ACM},
  number = {7}
}

@article{Casagrande:1994tp,
  title = {A Third Parallel Visual Pathway to Primate Area {{V1}}},
  author = {Casagrande, Vivien A.},
  year = {1994},
  volume = {17},
  pages = {305--310},
  issn = {01662236},
  doi = {10.1016/0166-2236(94)90065-5},
  journal = {Trends in Neurosciences},
  language = {en},
  number = {7}
}

@article{cassidyVirtualRealityPlatform2018,
  title = {A {{Virtual Reality Platform}} for {{Analyzing Remote Archaeological Sites}}},
  author = {Cassidy, Brendan and Robinson, David Wayne and Sim, Gavin and Gandy, Devlin},
  year = {2018}
}

@inproceedings{Castellina:vg,
  title = {Multimodal Gaze Interaction in {{3D}} Virtual Environments},
  booktitle = {Proceedings of the 4th {{Conference}} on {{Communication}} by {{Gaze Interaction}} \textendash{} {{COGAIN}} 2008: {{Communication}}, {{Environment}} and {{Mobility Control}} by {{Gaze}}},
  author = {Castellina, Emiliano and Corno, Fulvio},
  year = {2008},
  pages = {33--37},
  abstract = {Nowadays the computer game industry is developing more and more innovative interaction and control methods for user inputs. Nevertheless Gaze tracking, that is a fast natural and intuitive input channel, is not exploited in any commercial computer game, yet. In recent years several research groups started to study gaze tracking devices applied to computer games. In (Isokoschi \&amp; Martin, 2006) and (Isokoski et al., 2007) we find a comparison of different input methods, also including gaze tracking, for a first person shooter game. The~\ldots}
}

@incollection{Catmull:1974cf,
  title = {A Class of Local Interpolating Splines},
  booktitle = {Computer {{Aided Geometric Design}}},
  author = {Catmull, Edwin and Rom, Raphael},
  year = {1974},
  pages = {317--326},
  publisher = {{Elsevier}},
  doi = {10.1016/B978-0-12-079050-0.50020-5},
  isbn = {978-0-12-079050-0},
  language = {en}
}

@article{Chaumont:2012icy,
  title = {Icy: An Open Bioimage Informatics Platform for Extended Reproducible Research},
  author = {de Chaumont, Fabrice and Dallongeville, St{\'e}phane and Chenouard, Nicolas and Herv{\'e}, Nicolas and Pop, Sorin and Provoost, Thomas and {Meas-Yedid}, Vannary and Pankajakshan, Praveen and Lecomte, Timoth{\'e}e and Montagner, Yoann Le and Lagache, Thibault and Dufour, Alexandre and {Olivo-Marin}, Jean-Christophe},
  year = {2012},
  volume = {9},
  doi = {10.1038/nmeth.2075},
  abstract = {Current research in biology uses evermore complex computational and imaging tools. Here we describe Icy, a collaborative bioimage informatics platform that combines a community website for contributing and sharing tools and material, and software with a high-end visual programming framework for seamless development of sophisticated imaging workflows. Icy extends the reproducible research principles, by encouraging and facilitating the reusability, modularity, standardization and management of algorithms and protocols. Icy is free, open-source and available at http://icy.bioimageanalysis.org/.},
  journal = {Nature Methods},
  number = {7}
}

@article{Cheeseman:2018b12,
  title = {Adaptive Particle Representation of Fluorescence Microscopy Images},
  author = {Cheeseman, Bevan L. and G{\"u}nther, Ulrik and Gonciarz, Krzysztof and Susik, Mateusz and Sbalzarini, Ivo F.},
  year = {2018},
  volume = {9},
  doi = {10.1038/s41467-018-07390-9},
  abstract = {Modern microscopes can generate high volumes of 3D images, driving difficulties in data handling and processing. Here, the authors present a content-adaptive image representation as an alternative to standard pixels that goes beyond data compression to overcome storage, memory, and processing bottlenecks.},
  copyright = {Creative Commons Attribution 4.0 International License (CC-BY)},
  journal = {Nature Communications},
  number = {1}
}

@article{Cheeseman:ia,
  title = {Forget {{Pixels}}: {{Adaptive Particle Representation}} of {{Fluorescence Microscopy Images}}},
  author = {Cheeseman, B L and G{\"u}nther, U and Susik, M and {bioRxiv}, K Gonciarz and 2, 0},
  doi = {10.1101/263061},
  abstract = {\ldots{} The copyright holder for this preprint (which was not . http://dx.doi.org/ 10.1101 / 263061 doi: bioRxiv preprint first posted online Feb. 9, 2018;~\ldots{} The copyright holder for this preprint (which was not . http://dx.doi.org/ 10.1101 / 263061 doi: bioRxiv preprint first posted online Feb~\ldots},
  journal = {biorxiv.org}
}

@article{cheeseman2014cell,
  title = {Cell Lineage Tracing in the Developing Enteric Nervous System: Superstars Revealed by Experiment and Simulation},
  author = {Cheeseman, Bevan L and Zhang, Dongcheng and Binder, Benjamin J and Newgreen, Donald F and Landman, Kerry A},
  year = {2014},
  volume = {11},
  journal = {Journal of The Royal Society Interface},
  number = {93}
}

@article{chen2014lattice,
  title = {Lattice Light-Sheet Microscopy: Imaging Molecules to Embryos at High Spatiotemporal Resolution},
  author = {Chen, Bi-Chang and Legant, Wesley R and Wang, Kai and Shao, Lin and Milkie, Daniel E and Davidson, Michael W and Janetopoulos, Chris and Wu, Xufeng S and Hammer, John A and Liu, Zhe and {o}, t},
  year = {2014},
  volume = {346},
  journal = {Science},
  number = {6208}
}

@article{Chisholm:2004a0e,
  title = {Insights into Morphogenesis from a Simple Developmental System},
  author = {Chisholm, Rex L. and Firtel, Richard A.},
  year = {2004},
  volume = {5},
  doi = {10.1038/nrm1427},
  abstract = {We are only starting to understand the molecular mechanisms that underlie cell and tissue movements during morphogenesis in metazoans. Dictyostelium discoideum provides a valuable model system for understanding these events \textemdash{} as it has for chemotaxis \textemdash{} despite the many differences that exist between this social amoeba and more complex organisms. Genetic and genomic studies, combined with real-time imaging, have identified key pathways that regulate morphogenesis in D. discoideum, and which are likely to have similar roles in metazoans.},
  journal = {Nature Reviews Molecular Cell Biology},
  number = {7}
}

@phdthesis{Chlumsky:2015Shape,
  title = {Shape {{Decomposition}} for {{Multi}}-Channel {{Distance Fields}}},
  author = {Chlumsky, Viktor},
  year = {2015},
  address = {{Prague, Czech Republic}},
  school = {Czech Technical University}
}

@book{christensen2010functions,
  title = {Functions, Spaces, and Expansions: Mathematical Tools in Physics and Engineering},
  author = {Christensen, Ole},
  year = {2010}
}

@article{christopoulos2000jpeg2000,
  title = {The {{JPEG2000}} Still Image Coding System: An Overview},
  author = {Christopoulos, Charilaos and Skodras, Athanassios and Ebrahimi, Touradj},
  year = {2000},
  volume = {46},
  journal = {IEEE transactions on consumer electronics},
  number = {4}
}

@article{Christou:2012b12,
  title = {Codein\textemdash{{A New Notation}} for {{GOMS}} to {{Handle Evaluations}} of {{Reality}}-{{Based Interaction Style Interfaces}}},
  author = {Christou, Georgios and Ritter, Frank E. and Jacob, Robert J. K.},
  year = {2012},
  volume = {28},
  doi = {10.1080/10447318.2011.581893},
  abstract = {We propose a new diagrammatic notation system for Goals, Operators, Methods, Selection rules (GOMS), called Codein, with extensions to support the evaluation of Reality Based Interaction Styles. The proposed notation gives added power to GOMS to model and evaluate the task completion time of parallel actions during the performance of a task, something that was previously only possible using CPM-GOMS, which is far more complicated to use. Codein's evaluative power is verified through an experiment. The first condition of the experiment compares the completion time predicted by a GOMSL model, a Codein model, and the actual completion time of participants in a direct manipulation task. The second compares the completion time of participants in a Tangible User Interface task with predictions by a GOMSL model and a Codein model. Predicted task times by Codein in both conditions come close to the actual experimental results.},
  journal = {International Journal of Human-Computer Interaction},
  number = {3}
}

@article{Chukoskie:cy,
  title = {Learning Where to Look for a Hidden Target},
  author = {Chukoskie, L and Snider, J and of {the}, MC Mozer Proceedings and 2, 0},
  doi = {10.1073/pnas.1301216110/-/dcsupplemental},
  journal = {National Acad Sciences}
}

@article{ckendorf:2015ch,
  title = {Efficient Processing and Analysis of Large-Scale Light-Sheet Microscopy Data},
  author = {Amat, Fernando and H{\"o}ckendorf, Burkhard and Wan, Yinan and Lemon, William C and McDole, Katie and Keller, Philipp J},
  year = {2015},
  volume = {10},
  doi = {10.1038/nprot.2015.111},
  abstract = {Light-sheet microscopy is a powerful method for imaging the development and function of complex biological systems at high spatiotemporal resolution and over long time scales. Such experiments typically generate terabytes of multidimensional image data, and thus they demand efficient computational solutions for data management, processing and analysis. We present protocols and software to tackle these steps, focusing on the imaging-based study of animal development. Our protocols facilitate (i) high-speed lossless data compression and content-based multiview image fusion optimized for multicore CPU architectures, reducing image data size 30\textendash 500-fold; (ii) automated large-scale cell tracking and segmentation; and (iii) visualization, editing and annotation of multiterabyte image data and cell-lineage reconstructions with tens of millions of data points. These software modules are open source. They provide high data throughput using a single computer workstation and are readily applicable to a wide spectrum of biological model systems.},
  journal = {Nature Protocols},
  number = {11}
}

@unpublished{Clift:2018ncs,
  title = {Novel {{Control Systems}} for {{Virtual Reality}}, and Their {{Effects}} on {{Cyber Sickness}}},
  author = {Clift, Lee},
  year = {2018},
  abstract = {One of the major issues affecting users of virtual reality is a phenomenon known as cyber sickness, a type of motion sickness which occurs to some users when interacting with virtual reality. We look at the reasons for this, and possible software and hardware solutions to this problem. The investigation showed that software solutions are not more popular, but also extremely effective in dealing with the issue, whereas hardware solutions are expensive and impractical.}
}

@article{Cockburn:2009kj,
  title = {A Review of Overview+detail, Zooming, and Focus+context Interfaces},
  author = {Cockburn, Andy and Karlson, Amy and Bederson, Benjamin B},
  year = {2009},
  volume = {41},
  doi = {10.1145/1456650.1456652},
  abstract = {There are many interface schemes that allow users to work at, and move between, focused and contextual views of a dataset. We review and categorize these schemes according to the interface mechanisms used to separate and blend views. The four approaches are~\ldots},
  journal = {ACM Computing Surveys (CSUR)},
  number = {1}
}

@article{coifman1992entropy,
  title = {Entropy-Based Algorithms for Best Basis Selection},
  author = {Coifman, Ronald R and Wickerhauser, M Victor},
  year = {1992},
  volume = {38},
  journal = {IEEE Transactions on Information Theory},
  number = {2}
}

@article{Collins:2004ks,
  title = {The Measurement of Perceptual Curiosity},
  author = {Collins, Robert P and Litman, Jordan A and Spielberger, Charles D},
  year = {2004},
  volume = {36},
  doi = {10.1016/s0191-8869(03)00205-8},
  journal = {Personality and Individual Differences},
  number = {5}
}

@phdthesis{Crassin:2011uo,
  title = {{{GigaVoxels}}: A Voxel-Based Rendering Pipeline for Efficient Exploration of Large and Detailed Scenes},
  author = {Crassin, Cyril},
  year = {2011},
  abstract = {Abstract: In this thesis, we present a new approach to efficiently render large scenes and detailed objects in real-time. Our approach is based on a new volumetric pre-filtered geometry representation and an associated voxel-based approximate cone tracing that ...},
  school = {Universite de Grenoble}
}

@article{crow1984summed,
  title = {Summed-Area Tables for Texture Mapping},
  author = {Crow, Franklin C},
  year = {1984},
  volume = {18},
  journal = {ACM SIGGRAPH Computer Graphics},
  number = {3}
}

@article{CruzNeira:1992fa,
  title = {The {{CAVE}}: Audio Visual Experience Automatic Virtual Environment},
  author = {{Cruz-Neira}, Carolina and Sandin, Daniel J and DeFanti, Thomas A and Kenyon, Robert V and Hart, John C},
  year = {1992},
  volume = {35},
  doi = {10.1145/129888.129892},
  abstract = {. In its abstract aeslgn, It consists of a room whose walls, celling and floor surround a vlewer wlth prolectecl Images. Its design overcomes many of the problems encountered by other virtual reality systems and can be constructed from currently available technology. ...},
  journal = {Communications of the ACM},
  number = {6}
}

@article{CruzNeira:1992vt,
  title = {The {{CAVE}}: Audio Visual Experience Automatic Virtual Environment},
  author = {{Cruz-Neira}, C and Sandin, D J and DeFanti, T A},
  year = {1992},
  abstract = {Abstract: The CAVE virtual reality interface overcomes many of the problems of other virtual reality systems and can be built using currently available technology. Two important aspects of virtual reality are suspension of disbelief, in which the user ignores the medium, and ...},
  journal = {Communications of the ACM}
}

@incollection{Cullen:2016Visuomotor,
  title = {Visuomotor {{Integration}}},
  booktitle = {Neuroscience in the 21st {{Century}}},
  author = {Cullen, Kathleen E.},
  editor = {Pfaff, Donald W. and Volkow, Nora D.},
  year = {2016},
  pages = {961--1005},
  publisher = {{Springer New York}},
  address = {{New York, NY}},
  doi = {10.1007/978-1-4939-3474-4_25},
  isbn = {978-1-4939-3473-7 978-1-4939-3474-4},
  language = {en}
}

@article{Daetwyler:2018e8d,
  title = {Multi-Sample {{SPIM}} Image Acquisition, Processing and Analysis of Vascular Growth in Zebrafish},
  author = {Daetwyler, Stephan and G{\"u}nther, Ulrik and Modes, Carl D. and Harrington, Kyle I.S. and Huisken, Jan},
  year = {2018},
  doi = {10.1101/478149},
  abstract = {To quantitatively understand biological processes that occur over many hours or days, it is desirable to image multiple samples simultaneously and automatically process and analyze the resulting datasets. Here, we present a complete multi-sample preparation, imaging, processing, and analysis workflow to determine the development of the vascular volume in zebrafish. Up to five live embryos were mounted and imaged simultaneously over several days using selective plane illumination microscopy (SPIM). The resulting large imagery dataset of several terabytes was processed in an automated manner on a high-performance computer cluster and segmented with a novel segmentation approach that uses images of red blood cells as training data. This analysis yielded a precise quantification of growth characteristics of the whole vascular network, head vasculature, and tail vasculature over development. Our multi-sample platform demonstrates effective upgrades to conventional single-sample imaging platforms and paves the way for diverse quantitative long-term imaging studies.},
  journal = {bioRxiv}
}

@article{Daetwyler:2019f45,
  title = {Multi-Sample {{SPIM}} Image Acquisition, Processing and Analysis of Vascular Growth in Zebrafish},
  author = {Daetwyler, Stephan and G{\"u}nther, Ulrik and Modes, Carl D. and Harrington, Kyle I.S. and Huisken, Jan},
  year = {2019},
  doi = {10.1242/dev.173757},
  copyright = {Creative Commons Attribution 4.0 International License (CC-BY)},
  journal = {Development}
}

@article{daetwyler2016fast,
  title = {Fast Fluorescence Microscopy with Light Sheets},
  author = {Daetwyler, Stephan and Huisken, Jan},
  year = {2016},
  volume = {231},
  journal = {The Biological Bulletin},
  number = {1}
}

@article{Danforth:2000Platform,
  title = {A {{Platform}} for {{Gaze}}-{{Contingent Virtual Environments}}},
  author = {Danforth, Robert and Duchowski, Andrew and Geist, Robert and McAliley, Elizabeth},
  year = {2000}
}

@inproceedings{Darken:1997odt,
  title = {The Omni-Directional Treadmill: A Locomotion Device for Virtual Worlds},
  shorttitle = {The Omni-Directional Treadmill},
  booktitle = {Proceedings of the 10th Annual {{ACM}} Symposium on {{User}} Interface Software and Technology  - {{UIST}} '97},
  author = {Darken, Rudolph P. and Cockayne, William R. and Carmein, David},
  year = {1997},
  pages = {213--221},
  publisher = {{ACM Press}},
  address = {{Banff, Alberta, Canada}},
  doi = {10.1145/263407.263550},
  isbn = {978-0-89791-881-7},
  language = {en}
}

@article{daubechies1988orthonormal,
  title = {Orthonormal Bases of Compactly Supported Wavelets},
  author = {Daubechies, Ingrid},
  year = {1988},
  volume = {41},
  journal = {Communications on pure and applied mathematics},
  number = {7}
}

@article{davis1997adaptive,
  title = {Adaptive Greedy Approximations},
  author = {Davis, Geoff and Mallat, St{\'e}phane and Avellaneda, Marco},
  year = {1997},
  volume = {13},
  journal = {Constructive approximation},
  number = {1}
}

@article{davis2015humans,
  title = {Humans Perceive Flicker Artifacts at 500 {{Hz}}},
  author = {Davis, James and Hsieh, Yi-Hsuan and Lee, Hung-Chi},
  year = {2015},
  volume = {5},
  journal = {Scientific Reports}
}

@incollection{de1973good,
  title = {Good Approximation by Splines with Variable Knots},
  author = {de Boor, Carl},
  year = {1973}
}

@article{de1974good,
  title = {Good Approximation by Splines with Variable Knots. {{II}}},
  author = {Boor, Carl De},
  year = {1974},
  journal = {Conference on the numerical solution of differential equations}
}

@article{Deering:1988jd,
  title = {The Triangle Processor and Normal Vector Shader: A {{VLSI}} System for High Performance Graphics},
  author = {Deering, Michael and Winner, Stephanie and Schediwy, Bic and Duffy, Chris and Hunt, Neil and Deering, Michael and Winner, Stephanie and Schediwy, Bic and Duffy, Chris and Hunt, Neil},
  year = {1988},
  volume = {22},
  doi = {10.1145/378456.378468},
  abstract = {Abstract Current affordable architectures for high-speed display of shaded 3D objects operate orders of magnitude too slowly. Recent advances in floating point chip technology have outpaced polygon fill time, making the memory access bottleneck between the ...},
  journal = {ACM SIGGRAPH Computer Graphics},
  number = {4}
}

@article{DeFanti:2010cp,
  title = {The Future of the {{CAVE}}},
  author = {DeFanti, Thomas and Acevedo, Daniel and Ainsworth, Richard and Brown, Maxine and Cutchin, Steven and Dawe, Gregory and Doerr, Kai-Uwe and Johnson, Andrew and Knox, Chris and Kooima, Robert and Kuester, Falko and Leigh, Jason and Long, Lance and Otto, Peter and Petrovic, Vid and Ponto, Kevin and Prudhomme, Andrew and Rao, Ramesh and Renambot, Luc and Sandin, Daniel and Schulze, Jurgen and Smarr, Larry and Srinivasan, Madhu and Weber, Philip and Wickham, Gregory},
  year = {2010},
  volume = {1},
  doi = {10.2478/s13531-010-0002-5},
  journal = {Open Engineering},
  number = {1}
}

@article{defferrard2016convolutional,
  title = {Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering},
  author = {Defferrard, Micha{\"e}l and Bresson, Xavier and Vandergheynst, Pierre},
  year = {2016},
  journal = {Advances in Neural Information Processing Systems}
}

@article{demaret2002scattered,
  title = {Scattered Data Coding in Digital Image Compression},
  author = {Demaret, Laurent and Iske, Armin},
  year = {2002},
  volume = {2003},
  journal = {Curve and Surface Fitting: Saint-Malo}
}

@article{demaret2004advances,
  title = {Advances in Digital Image Compression by Adaptive Thinning},
  author = {Demaret, Laurent and Iske, Armin and {o}, t},
  year = {2004},
  volume = {3},
  journal = {Annals of the MCFA}
}

@article{demaret2006image,
  title = {Image Compression by Linear Splines over Adaptive Triangulations},
  author = {Demaret, Laurent and Dyn, Nira and Iske, Armin},
  year = {2006},
  volume = {86},
  journal = {Signal Processing},
  number = {7}
}

@article{denkSerialBlockFaceScanning2004,
  title = {Serial {{Block}}-{{Face Scanning Electron Microscopy}} to {{Reconstruct Three}}-{{Dimensional Tissue Nanostructure}}},
  author = {Denk, Winfried and Horstmann, Heinz},
  year = {2004},
  volume = {2},
  doi = {10.1371/journal.pbio.0020329},
  abstract = {Three-dimensional (3D) structural information on many length scales is of central importance in biological research. Excellent methods exist to obtain structures of molecules at atomic, organelles at electron microscopic, and tissue at light-microscopic resolution. A gap exists, however, when 3D tissue structure needs to be reconstructed over hundreds of micrometers with a resolution sufficient to follow the thinnest cellular processes and to identify small organelles such as synaptic vesicles. Such 3D data are, however, essential to understand cellular networks that, particularly in the nervous system, need to be completely reconstructed throughout a substantial spatial volume. Here we demonstrate that datasets meeting these requirements can be obtained by automated block-face imaging combined with serial sectioning inside the chamber of a scanning electron microscope. Backscattering contrast is used to visualize the heavy-metal staining of tissue prepared using techniques that are routine for transmission electron microscopy. Low-vacuum (20\textendash 60 Pa H2O) conditions prevent charging of the uncoated block face. The resolution is sufficient to trace even the thinnest axons and to identify synapses. Stacks of several hundred sections, 50\textendash 70 nm thick, have been obtained at a lateral position jitter of typically under 10 nm. This opens the possibility of automatically obtaining the electron-microscope-level 3D datasets needed to completely reconstruct the connectivity of neuronal circuits.},
  journal = {PLoS Biology},
  number = {11}
}

@incollection{deslauriers1989symmetric,
  title = {Symmetric Iterative Interpolation Processes},
  author = {Deslauriers, Gilles and Dubuc, Serge},
  year = {1989}
}

@article{devore1992image,
  title = {Image Compression through Wavelet Transform Coding},
  author = {DeVore, Ronald A and Jawerth, Bj{\"o}rn and Lucier, Bradley J},
  year = {1992},
  volume = {38},
  journal = {IEEE Transactions on Information Theory},
  number = {2}
}

@article{devore1992surface,
  title = {Surface Compression},
  author = {DeVore, Ronald A and Jawerth, Bj{\"o}rn and Lucier, Bradley J},
  year = {1992},
  volume = {9},
  journal = {Computer Aided Geometric Design},
  number = {3}
}

@article{dice1945measures,
  title = {Measures of the Amount of Ecologic Association between Species},
  author = {Dice, Lee R},
  year = {1945},
  volume = {26},
  journal = {Ecology},
  number = {3}
}

@article{donoho1992interpolating,
  title = {Interpolating Wavelet Transforms},
  author = {Donoho, David L},
  year = {1992},
  volume = {2},
  journal = {Preprint, Department of Statistics, Stanford University},
  number = {3}
}

@article{donoho1994ideal,
  title = {Ideal Spatial Adaptation by Wavelet Shrinkage},
  author = {Donoho, David L and Johnstone, Iain M},
  year = {1994},
  journal = {biometrika}
}

@article{donoho2006compressed,
  title = {Compressed Sensing},
  author = {Donoho, David L},
  year = {2006},
  volume = {52},
  journal = {IEEE Transactions on Information Theory},
  number = {4}
}

@book{Duchowski:2017ii,
  title = {Eye Tracking Methodology: Theory and Practice},
  shorttitle = {Eye Tracking Methodology},
  author = {Duchowski, Andrew Ted},
  year = {2017},
  edition = {Third edition},
  publisher = {{Springer}},
  address = {{Cham}},
  annotation = {OCLC: 993036172},
  isbn = {978-3-319-57883-5 978-3-319-57881-1},
  language = {eng}
}

@article{dyn2002adaptive,
  title = {Adaptive Thinning for Bivariate Scattered Data},
  author = {Dyn, Nira and Floater, Michael S and Iske, Armin},
  year = {2002},
  volume = {145},
  journal = {Journal of Computational and Applied Mathematics},
  number = {2}
}

@article{Edelstein:2010gf,
  title = {Computer Control of Microscopes Using {{\textmu Manager}}.},
  author = {Edelstein, Arthur and Amodaj, Nenad and Hoover, Karl and Vale, Ron and Stuurman, Nico},
  year = {2010},
  volume = {14},
  doi = {10.1002/0471142727.mb1420s92},
  abstract = {With the advent of digital cameras and motorization of mechanical components, computer control of microscopes has become increasingly important. Software for microscope image acquisition should not only be easy to use, but also enable and encourage novel approaches. The open-source software package \textmu Manager aims to fulfill those goals. This unit provides step-by-step protocols describing how to get started working with \textmu Manager, as well as some starting points for advanced use of the software.},
  journal = {Current protocols in molecular biology}
}

@article{Ehinger:2019new,
  title = {A New Comprehensive {{Eye}}-{{Tracking Test Battery}} Concurrently Evaluating the {{Pupil Labs Glasses}} and the {{EyeLink}} 1000},
  author = {Ehinger, Benedikt V and Gross, Katharina and Ibs, Inga and Koenig, Peter},
  year = {2019},
  doi = {10.1101/536243},
  abstract = {Eye-tracking experiments rely heavily on good data quality of eye-trackers. Unfortunately, it is often that only the spatial accuracy and precision values are available from the manufacturers. These two values alone are not sufficient enough to serve as a benchmark for an eye-tracker: Eye-tracking quality deteriorates during an experimental session due to head movements, changing illumination or calibration decay. Additionally, different experimental paradigms require the analysis of different types of eye movements, for instance smooth pursuit movements, blinks or microsaccades, which themselves cannot readily be evaluated by using spatial accuracy or precision alone. To obtain a more comprehensive description of properties, we developed an extensive eye-tracking test battery. In 10 different tasks, we evaluated eye-tracking related measures such as: the decay of accuracy, fixation durations, pupil dilation, smooth pursuit movement, microsaccade detection, blink detection, or the influence of head motion. For some measures, true theoretical values exist. For others, a relative comparison to a gold standard eye-tracker is needed. Therefore, we collected our gaze data simultaneously from a gold standard remote EyeLink\textasciitilde 1000 eye-tracker and compared it with the mobile Pupil Labs glasses. As expected, the average spatial accuracy of 0.57\textdegree{} for the EyeLink\textasciitilde 1000 eye-tracker was better than the 0.82\textdegree{} for the Pupil Labs glasses (N=15). Furthermore, we detected less fixations and shorter saccade durations for the Pupil Labs glasses. Similarly, we found fewer microsaccades using the Pupil Labs glasses. The accuracy over time decayed only slightly for the EyeLink\textasciitilde 1000, but strongly for the Pupil Labs glasses. Finally we observed that the measured pupil diameters differed between eye-trackers on the individual subject level but not the group level. To conclude, our eye-tracking test battery offers 10 tasks that allow us to benchmark the many parameters of interest in stereotypical eye-tracking situations, or addresses a common source of confounds in measurement errors (e.g. yaw and roll head movements). All recorded eye-tracking data (including Pupil Labs' eye video files), the stimulus code for the test battery and the modular analysis pipeline are available (https://github.com/behinger/etcomp).},
  journal = {bioRxiv}
}

@article{Eiber:20182bf,
  title = {Receptive {{Field Properties}} of {{Koniocellular On}}/{{Off Neurons}} in the {{Lateral Geniculate Nucleus}} of {{Marmoset Monkeys}}},
  author = {Eiber, Calvin D and Rahman, Abrar S and Pietersen, Alexander N J and Zeater, Natalie and Dreher, Bogdan and Solomon, Samuel G and Martin, Paul R},
  year = {2018},
  volume = {38},
  doi = {10.1523/jneurosci.1679-18.2018},
  journal = {The Journal of Neuroscience},
  number = {48}
}

@article{Engelbrecht:2007tt,
  title = {Three-Dimensional Laser Microsurgery in Light-Sheet Based Microscopy ({{SPIM}})},
  author = {Engelbrecht, Christoph J. and Greger, Klaus and Reynaud, Emmanuel G. and Kr{\v z}ic, Uro{\v s} and Colombelli, Julien and Stelzer, Ernst H. K.},
  year = {2007},
  month = may,
  volume = {15},
  pages = {6420},
  issn = {1094-4087},
  doi = {10.1364/OE.15.006420},
  journal = {Optics Express},
  language = {en},
  number = {10}
}

@article{Erazo:2015d6c,
  title = {Predicting {{Task Execution Time}} on {{Natural User Interfaces}} Based on {{Touchless Hand Gestures}}},
  author = {Erazo, Orlando and Pino, Jos{\'e} A.},
  year = {2015},
  abstract = {Model-based evaluation has been widely used in HCI. However, current predictive models are insufficient to evaluate Natural User Interfaces based on touchless hand gestures. The purpose of this paper is to present a model based on KLM to predict performance time for doing tasks using this interface type. The required model operators were defined considering the temporal structure of hand gestures (i.e. using gesture units) and performing a systematic bibliographic review. The times for these operators were estimated by a user study consisting of various parts. Finally, the model empirical evaluation gave acceptable results (root-mean-square error = 10\%, R2 = 0.936) when compared to similar models developed for other interaction styles. Thus, the proposed model should be helpful to software designers to carry out usability assessments by predicting performance time without user participation.}
}

@article{escande2015sparse,
  title = {Sparse Wavelet Representations of Spatially Varying Blurring Operators},
  author = {Escande, Paul and Weiss, Pierre},
  year = {2015},
  volume = {8},
  journal = {SIAM Journal on Imaging Sciences},
  number = {4}
}

@article{eyeref,
  title = {Notes on the {{Resolution}} and {{Other Details}} of the {{Human Eye}}},
  author = {Clark, Roger N},
  year = {2016},
  journal = {clarkvision.com}
}

@article{faure2016workflow,
  title = {A Workflow to Process {{3D}}+ Time Microscopy Images of Developing Organisms and Reconstruct Their Cell Lineage},
  author = {Faure, Emmanuel and Savy, Thierry and Rizzi, Barbara and Melani, Camilo and Sta{\v s}ov{\'a}, Olga and Fabr{\`e}ges, Dimitri and {\v S}pir, R{\'o}bert and Hammons, Mark and {\v C}{\'u}nderl{\'i}k, R{\'o}bert and Recher, Ga{\"e}lle and {o}, t},
  year = {2016},
  volume = {7},
  journal = {Nature Communications}
}

@inproceedings{Fernandes:2016cvrs,
  title = {Combating {{VR}} Sickness through Subtle Dynamic Field-of-View Modification},
  booktitle = {2016 {{IEEE Symposium}} on {{3D User Interfaces}} ({{3DUI}})},
  author = {Fernandes, Ajoy S and Feiner, Steven K.},
  year = {2016},
  month = mar,
  pages = {201--210},
  publisher = {{IEEE}},
  address = {{Greenville, SC, USA}},
  doi = {10.1109/3DUI.2016.7460053},
  isbn = {978-1-5090-0842-1}
}

@article{Fitts:1954135,
  title = {The Information Capacity of the Human Motor System in Controlling the Amplitude of Movement.},
  author = {Fitts, Paul M.},
  year = {1954},
  volume = {47},
  doi = {10.1037/h0055392},
  abstract = {Reports of 3 experiments testing the hypothesis that the average duration of responses is directly proportional to the minimum average amount of information per response. The results show that the rate of performance is approximately constant over a wide range of movement amplitude and tolerance limits. This supports the thesis that "the performance capacity of the human motor system plus its associated visual and proprioceptive feedback mechanisms, when measured in information units, is relatively constant over a considerable range of task conditions." 25 references.},
  journal = {Journal of Experimental Psychology},
  number = {6}
}

@article{Fitzgerald:2011924,
  title = {Research and {{Development}} in {{Intelligent Systems XXVIII}}, {{Incorporating Applications}} and {{Innovations}} in {{Intelligent Systems XIX Proceedings}} of {{AI}}-2011, the {{Thirty}}-First {{SGAI International Conference}} on {{Innovative Techniques}} and {{Applications}} of {{Artificial Intelligence}}},
  author = {Fitzgerald, Jeannie and Ryan, Conor},
  year = {2011},
  abstract = {This paper investigates a new application of a validation set when using a three data set methodology with Genetic Programming (GP). Our system uses Validation Pressure combined with Validation Elitism to influence fitness evaluation and population structure with the aim of improving the system's ability to evolve individuals with an enhanced capacity for generalisation. This strategy facilitates the use of a validation set to reduce over-fitting while mitigating the loss of training data associated with traditional methods employing a validation set. The method is tested on five benchmark binary classification data sets and results obtained suggest that the strategy can deliver improved generalisation on unseen test data.}
}

@article{floyd1976adaptive,
  title = {An Adaptive Algorithm for Spatial Gray-Scale},
  author = {Floyd, Robert W},
  year = {1976},
  volume = {17},
  journal = {Proc. Soc. Inf. Disp.}
}

@article{Franze:20077e7,
  title = {M\"uller Cells Are Living Optical Fibers in the Vertebrate Retina},
  author = {Franze, Kristian and Grosche, Jens and Skatchkov, Serguei N. and Schinkinger, Stefan and Foja, Christian and Schild, Detlev and Uckermann, Ortrud and Travis, Kort and Reichenbach, Andreas and Guck, Jochen},
  year = {2007},
  volume = {104},
  doi = {10.1073/pnas.0611180104},
  abstract = {Although biological cells are mostly transparent, they are phase objects that differ in shape and refractive index. Any image that is projected through layers of randomly oriented cells will normally be distorted by refraction, reflection, and scattering. Counterintuitively, the retina of the vertebrate eye is inverted with respect to its optical function and light must pass through several tissue layers before reaching the light-detecting photoreceptor cells. Here we report on the specific optical properties of glial cells present in the retina, which might contribute to optimize this apparently unfavorable situation. We investigated intact retinal tissue and individual M\"uller cells, which are radial glial cells spanning the entire retinal thickness. M\"uller cells have an extended funnel shape, a higher refractive index than their surrounding tissue, and are oriented along the direction of light propagation. Transmission and reflection confocal microscopy of retinal tissue in vitro and in vivo showed that these cells provide a low-scattering passage for light from the retinal surface to the photoreceptor cells. Using a modified dual-beam laser trap we could also demonstrate that individual M\"uller cells act as optical fibers. Furthermore, their parallel array in the retina is reminiscent of fiberoptic plates used for low-distortion image transfer. Thus, M\"uller cells seem to mediate the image transfer through the vertebrate retina with minimal distortion and low loss. This finding elucidates a fundamental feature of the inverted retina as an optical system and ascribes a new function to glial cells.},
  journal = {Proceedings of the National Academy of Sciences},
  number = {20}
}

@article{Frey:2013Explorable,
  title = {Explorable {{Volumetric Depth Images}} from {{Raycasting}}},
  author = {Frey, Steffen and Sadlo, Filip and Ertl, Thomas},
  year = {2013},
  doi = {10.1109/sibgrapi.2013.26},
  abstract = {View-dependent image-based rendering techniques have become increasingly popular as they combine the high quality of images with the explorability of interactive techniques. However, in the context of volume rendering, previous approaches suffer from various shortcomings, including the limitation to surfaces, expensive generation, and insufficient occlusion and motion parallax impairing depth perception. In this paper, we propose Volumetric Depth Images (VDI) to overcome these issues for view-dependent volume visualization by an extension of the Layered Depth Image (LDI) approach. Instead of only saving for each view ray of one camera configuration the depth and color values for a set of surfaces, as in LDIs, VDIs store socalled supersegments, each consisting of a depth range as well as composited color and opacity. This compact representation is independent from the structure of the original data and can be generated by slight modification of raycasters with very low overhead. VDIs can be rendered efficiently at high quality with arbitrary camera configurations by means of proxy frustum geometry and an efficient depth ordering scheme. When viewing the scene from the initial view point, VDIs produce results identical to the original raycasting. As demonstrated by means of a prototype implementation and data from different fields, our approach can be useful for preview rendering and a-priori analysis in in-situ contexts among others.},
  journal = {2013 XXVI Conference on Graphics, Patterns and Images}
}

@article{friedman1989flexible,
  title = {Flexible Parsimonious Smoothing and Additive Modeling},
  author = {Friedman, Jerome H and Silverman, Bernard W},
  year = {1989},
  volume = {31},
  journal = {Technometrics},
  number = {1}
}

@article{friedman1991multivariate,
  title = {Multivariate Adaptive Regression Splines},
  author = {Friedman, Jerome H},
  year = {1991},
  journal = {The annals of statistics}
}

@article{Gao:2014a3e,
  title = {Visual {{Saliency Models}} for {{Text Detection}} in {{Real World}}},
  author = {Gao, Renwu and Uchida, Seiichi and Shahab, Asif and Shafait, Faisal and Frinken, Volkmar},
  year = {2014},
  volume = {9},
  doi = {10.1371/journal.pone.0114539},
  abstract = {This paper evaluates the degree of saliency of texts in natural scenes using visual saliency models. A large scale scene image database with pixel level ground truth is created for this purpose. Using this scene image database and five state-of-the-art models, visual saliency maps that represent the degree of saliency of the objects are calculated. The receiver operating characteristic curve is employed in order to evaluate the saliency of scene texts, which is calculated by visual saliency models. A visualization of the distribution of scene texts and non-texts in the space constructed by three kinds of saliency maps, which are calculated using Itti's visual saliency model with intensity, color and orientation features, is given. This visualization of distribution indicates that text characters are more salient than their non-text neighbors, and can be captured from the background. Therefore, scene texts can be extracted from the scene images. With this in mind, a new visual saliency architecture, named hierarchical visual saliency model, is proposed. Hierarchical visual saliency model is based on Itti's model and consists of two stages. In the first stage, Itti's model is used to calculate the saliency map, and Otsu's global thresholding algorithm is applied to extract the salient region that we are interested in. In the second stage, Itti's model is applied to the salient region to calculate the final saliency map. An experimental evaluation demonstrates that the proposed model outperforms Itti's model in terms of captured scene texts.},
  journal = {PLoS ONE},
  number = {12}
}

@article{gerryPaintMeStimulating2017,
  title = {Paint with {{Me}}: {{Stimulating Creativity}} and {{Empathy While Painting}} with a {{Painter}} in {{Virtual Reality}}},
  author = {Gerry, Lynda Joy},
  year = {2017},
  volume = {23},
  doi = {10.1109/tvcg.2017.2657239},
  abstract = {While nothing can be more vivid, immediate and real than our own sensorial experiences, emerging virtual reality technologies are playing with the possibility of being able to share someone else's sensory reality. The Painter Project is a virtual environment where users see a video from a painter's point of view in tandem with a tracked rendering of their own hand while they paint on a physical canvas. The end result is an experiment in superimposition of one experiential reality on top of another, hopefully opening a new window into an artist's creative process. This explorative study tested this virtual environment on stimulating empathy and creativity. The findings indicate potential for this technology as a new expert-novice mentorship simulation.},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  number = {4}
}

@article{girstmair2016,
  title = {Light-Sheet Microscopy for Everyone? {{Experience}} of Building an {{OpenSPIM}} to Study Flatworm Development},
  author = {Girstmair, Johannes and Zakrzewski, Anne and Lapraz, Fran{\c c}ois and {Handberg-Thorsager}, Mette and Tomancak, Pavel and Pitrone, Peter Gabriel and Simpson, Fraser and Telford, Maximilian J.},
  year = {2016},
  volume = {16},
  doi = {10.1186/s12861-016-0122-0},
  abstract = {Selective plane illumination microscopy (SPIM a type of light-sheet microscopy) involves focusing a thin sheet of laser light through a specimen at right angles to the objective lens. As only the thin section of the specimen at the focal plane of the lens is illuminated, out of focus light is naturally absent and toxicity due to light (phototoxicity) is greatly reduced enabling longer term live imaging. OpenSPIM is an open access platform (Pitrone et al. 2013 and OpenSPIM.org) created to give new users step-by-step instructions on building a basic configuration of a SPIM microscope, which can in principle be adapted and upgraded to each laboratory's own requirements and budget. Here we describe our own experience with the process of designing, building, configuring and using an OpenSPIM for our research into the early development of the polyclad flatworm Maritigrella crozieri \textendash{} a non-model animal. Our OpenSPIM builds on the standard design with the addition of two colour laser illumination for simultaneous detection of two probes/molecules and dual sided illumination, which provides more even signal intensity across a specimen. Our OpenSPIM provides high resolution 3d images and time lapse recordings, and we demonstrate the use of two colour lasers and the benefits of two color dual-sided imaging. We used our microscope to study the development of the embryo of the polyclad flatworm M. crozieri. The capabilities of our microscope are demonstrated by our ability to record the stereotypical spiral cleavage pattern of M. crozieri with high-speed multi-view time lapse imaging. 3D and 4D (3D + time) reconstruction of early development from these data is possible using image registration and deconvolution tools provided as part of the open source Fiji platform. We discuss our findings on the pros and cons of a self built microscope. We conclude that home-built microscopes, such as an OpenSPIM, together with the available open source software, such as MicroManager and Fiji, make SPIM accessible to anyone interested in having continuous access to their own light-sheet microscope. However, building an OpenSPIM is not without challenges and an open access microscope is a worthwhile, if significant, investment of time and money. Multi-view 4D microscopy is more challenging than we had expected. We hope that our experience gained during this project will help future OpenSPIM users with similar ambitions.},
  journal = {BMC Developmental Biology},
  number = {1}
}

@article{Gneo:2012kn,
  title = {A Free Geometry Model-Independent Neural Eye-Gaze Tracking System.},
  author = {Gneo, Massimo and Schmid, Maurizio and Conforto, Silvia and D'Alessio, Tommaso},
  year = {2012},
  volume = {9},
  doi = {10.1186/1743-0003-9-82},
  abstract = {BACKGROUND:Eye Gaze Tracking Systems (EGTSs) estimate the Point Of Gaze (POG) of a user. In diagnostic applications EGTSs are used to study oculomotor characteristics and abnormalities, whereas in interactive applications EGTSs are proposed as input devices for human computer interfaces (HCI), e.g. to move a cursor on the screen when mouse control is not possible, such as in the case of assistive devices for people suffering from locked-in syndrome. If the user's head remains still and the cornea rotates around its fixed centre, the pupil follows the eye in the images captured from one or more cameras, whereas the outer corneal reflection generated by an IR light source, i.e. glint, can be assumed as a fixed reference point. According to the so-called pupil centre corneal reflection method (PCCR), the POG can be thus estimated from the pupil-glint vector. METHODS:A new model-independent EGTS based on the PCCR is proposed. The mapping function based on artificial neural networks allows to avoid any specific model assumption and approximation either for the user's eye physiology or for the system initial setup admitting a free geometry positioning for the user and the system components. The robustness of the proposed EGTS is proven by assessing its accuracy when tested on real data coming from: i) different healthy users; ii) different geometric settings of the camera and the light sources; iii) different protocols based on the observation of points on a calibration grid and halfway points of a test grid. RESULTS:The achieved accuracy is approximately 0.49\textdegree, 0.41\textdegree, and 0.62\textdegree{} for respectively the horizontal, vertical and radial error of the POG. CONCLUSIONS:The results prove the validity of the proposed approach as the proposed system performs better than EGTSs designed for HCI which, even if equipped with superior hardware, show accuracy values in the range 0.6\textdegree -1\textdegree.},
  journal = {Journal of neuroengineering and rehabilitation},
  number = {1}
}

@inproceedings{gold2014,
  title = {Feedback {{Control}} of {{Evolving Swarms}}},
  booktitle = {Artificial {{Life}} 14: {{Proceedings}} of the {{Fourteenth International Conference}} on the {{Synthesis}} and {{Simulation}} of {{Living Systems}}},
  author = {Gold, Jacob and Wang, Adam and Harrington, Kyle I.S.},
  year = {2014},
  month = jul,
  pages = {884--891},
  publisher = {{The MIT Press}},
  doi = {10.7551/978-0-262-32621-6-ch145},
  isbn = {978-0-262-32621-6}
}

@article{goldberg2005open,
  title = {The {{Open Microscopy Environment}} ({{OME}}) {{Data Model}} and {{XML}} File: Open Tools for Informatics and Quantitative Analysis in Biological Imaging},
  author = {Goldberg, Ilya G and Allan, Chris and Burel, Jean-Marie and Creager, Doug and Falconi, Andrea and Hochheiser, Harry and Johnston, Josiah and Mellen, Jeff and Sorger, Peter K and Swedlow, Jason R},
  year = {2005},
  volume = {6},
  journal = {Genome Biology},
  number = {5}
}

@article{gole2016opensegspim,
  title = {{{OpenSegSPIM}}: A User-Friendly Segmentation Tool for {{SPIM}} Data},
  author = {Gole, Laurent and Ong, Kok Haur and Boudier, Thomas and Yu, Weimiao and Ahmed, Sohail},
  year = {2016},
  volume = {32},
  journal = {Bioinformatics},
  number = {13}
}

@book{goodfellow2016deep,
  title = {Deep Learning},
  author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  year = {2016}
}

@book{Gray:1878ahb,
  title = {Anatomy of the Human Body},
  author = {Gray, Henry and Lewis, Warren H},
  year = {1878}
}

@inproceedings{Green:2007Improved,
  title = {Improved Alpha-Tested Magnification for Vector Textures and Special Effects},
  booktitle = {{{ACM SIGGRAPH}} 2007 Courses - {{SIGGRAPH}} '07},
  author = {Green, Chris},
  year = {2007},
  pages = {9},
  publisher = {{ACM Press}},
  address = {{San Diego, California}},
  doi = {10.1145/1281500.1281665},
  abstract = {A simple and efficient method is presented which allows improved rendering of glyphs composed of curved and linear elements. A distance field is generated from a high resolution image, and then stored into a channel of a lower-resolution texture. In the simplest case, this texture can then be rendered simply by using the alphatesting and alpha-thresholding feature of modern GPUs, without a custom shader. This allows the technique to be used on even the lowest-end 3D graphics hardware.},
  isbn = {978-1-4503-1823-5},
  language = {en}
}

@article{Grimmer:2014TruffleC,
  title = {{{TruffleC}}: Dynamic Execution of {{C}} on a {{Java}} Virtual Machine},
  author = {Grimmer, Matthias and Rigger, Manuel and Schatz, Roland and Stadler, Lukas and M{\"o}ssenb{\"o}ck, Hanspeter},
  year = {2014},
  abstract = {This paper presents TruffleC, a C interpreter that allows the dynamic execution of C code on top of a Java Virtual Machine (JVM). Rather than producing a static build of a C application, TruffleC is a self-optimizing abstract syntax tree (AST) interpreter combined with a just-in-time (JIT) compiler. Our self-optimizing interpreter specializes the AST based on run-time feedback. AST specialization relies on optimistic assumptions and allows us to build inline caches for polymorphic function pointer calls, to profile runtime values and to potentially replace them with constants, or to speculatively remove code that was not executed yet. After AST specialization, the JIT compiler translates the AST to highly optimized machine code. The machine code uses dynamic deoptimization points at which the control switches back to the interpreter in case of a violated assumption. We evaluated TruffleC using a C micro-benchmark in terms of peak performance. This evaluation showed that TruffleC outperforms the code produced by industry standard compilers such as GCC or Clang/LLVM. The evaluation of other benchmarks ("Computer Language Benchmarks Game") showed that the TruffleC performance is on average only 7\% slower than the best performance out of the GCC and Clang/LLVM performances.}
}

@article{grottelMegaMolPrototypingFramework2014,
  title = {{{MegaMol}} - {{A Prototyping Framework}} for {{Particle}}-{{Based Visualization}}},
  author = {Grottel, Sebastian and Krone, Michael and Muller, Christoph and Reina, Guido and Ertl, Thomas},
  year = {2014},
  volume = {21},
  doi = {10.1109/tvcg.2014.2350479},
  abstract = {Visualization applications nowadays not only face increasingly larger datasets, but have to solve increasingly complex research questions. They often require more than a single algorithm and consequently a software solution will exceed the possibilities of simple research prototypes. Well-established systems intended for such complex visual analysis purposes have usually been designed for classical, mesh-based graphics approaches. For particle-based data, however, existing visualization frameworks are too generic - e.g. lacking possibilities for consistent low-level GPU optimization for high-performance graphics - and at the same time are too limited - e.g. by enforcing the use of structures suboptimal for some computations. Thus, we developed the system softwareMegaMol for visualization research on particle-based data. On the one hand, flexible data structures and functional module design allow for easy adaption to changing research questions, e.g. studying vapors in thermodynamics, solid material in physics, or complex functional macromolecules like proteins in biochemistry. Therefore, MegaMol is designed as a development framework. On the other hand, common functionality for data handling and advanced rendering implementations are available and beneficial for all applications. We present several case studies of work implemented using our system as well as a comparison to other freely available or open source systems.},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  number = {2}
}

@article{grottelOptimizedDataTransfer2009,
  title = {Optimized Data Transfer for Time-Dependent, {{GPU}}-Based Glyphs},
  author = {Grottel, S and Reina, G and Ertl, T},
  year = {2009},
  abstract = {Particle-based simulations are a popular tool for researchers in various sciences. In combination with the availability of ever larger COTS clusters and the consequently increasing number of simulated particles the resulting datasets pose a challenge for real-time visualization. Additionally the semantic density of the particles exceeds the possibilities of basic glyphs, like splats or spheres and results in dataset sizes larger by at least an order of magnitude. Interactive visualization on common workstations requires a careful optimization of the data management, especially of the transfer between CPU and GPU. We propose a flexible benchmarking tool along with a series of tests to allow the evaluation of the performance of different CPU/GPU combinations in relation to a particular implementation. We evaluate different uploading strategies and rendering methods for point-based compound glyphs suitable for representing the aforementioned datasets. CPU and GPU-based approaches are compared with respect to their rendering and storage efficiency to point out the optimal solution when dealing with time-dependent datasets. The results of our research are of general interest since they can be transferred to other applications where CPU-GPU bandwidth and a high number of graphical primitives per dataset pose a problem. The employed tool set for streamlining the measurement process is made publicly available.}
}

@article{Gualda:2013gr,
  title = {{{OpenSpinMicroscopy}}: An Open-Source Integrated Microscopy Platform.},
  author = {Gualda, Emilio J and Vale, Tiago and Almada, Pedro and Feij{\'o}, Jos{\'e} A and Martins, Gabriel G and Moreno, Nuno},
  year = {2013},
  volume = {10},
  doi = {10.1038/nmeth.2508},
  journal = {Nature Methods},
  number = {7}
}

@article{Guignard:bi,
  title = {Contact-Dependent Cell Communications Drive Morphological Invariance during Ascidian Embryogenesis},
  author = {Guignard, Leo and Fiuza, Ulla-Maj and Leggio, Bruno and Faure, Emmanuel and Laussu, Julien and Hufnagel, Lars and Malandain, Gregoire and Godin, Christophe and Lemaire, Patrick},
  year = {2017},
  doi = {10.1101/238741},
  journal = {bioRxiv}
}

@article{guignard2017contact,
  title = {Contact-Dependent Cell Communications Drive Morphological Invariance during Ascidian Embryogenesis},
  author = {Guignard, Leo and Fiuza, Ulla-Maj and Leggio, Bruno and Faure, Emmanuel and Laussu, Julien and Hufnagel, Lars and Malandain, Gregoire and Godin, Christophe and Lemaire, Patrick},
  year = {2017},
  journal = {bioRxiv}
}

@article{gunter2017scenery,
  title = {Scenerygraphics/Scenery: Scenery 0.2.3-1},
  year = {2017},
  journal = {https://doi.org/10.5281/zenodo.1111824}
}

@article{Gunther:2019scenery,
  title = {Scenery: {{Flexible Virtual Reality Visualization}} on the {{Java VM}}},
  shorttitle = {Scenery},
  author = {G{\"u}nther, Ulrik and Pietzsch, Tobias and Gupta, Aryaman and Harrington, Kyle I. S. and Tomancak, Pavel and Gumhold, Stefan and Sbalzarini, Ivo F.},
  year = {2019},
  month = jun,
  abstract = {Life science today involves computational analysis of a large amount and variety of data, such as volumetric data acquired by state-of-the-art microscopes, or mesh data from analysis of such data or simulations. Visualization is often the first step in making sense of data, and a crucial part of building and debugging analysis pipelines. It is therefore important that visualizations can be quickly prototyped, as well as developed or embedded into full applications. In order to better judge spatiotemporal relationships, immersive hardware, such as Virtual or Augmented Reality (VR/AR) headsets and associated controllers are becoming invaluable tools. In this work we introduce scenery, a flexible VR/AR visualization framework for the Java VM that can handle mesh and large volumetric data, containing multiple views, timepoints, and color channels. scenery is free and open-source software, works on all major platforms, and uses the Vulkan or OpenGL rendering APIs. We introduce scenery's main features and example applications, such as its use in VR for microscopy, in the biomedical image analysis software Fiji, or for visualizing agent-based simulations.},
  archivePrefix = {arXiv},
  copyright = {Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License (CC-BY-NC-SA)},
  eprint = {1906.06726},
  eprinttype = {arxiv},
  journal = {arXiv:1906.06726 [cs]},
  keywords = {Computer Science - Graphics},
  primaryClass = {cs}
}

@article{Guterstam:2018b12,
  title = {Implicit Model of Other People's Visual Attention as an Invisible, Force-Carrying Beam Projecting from the Eyes},
  author = {Guterstam, Arvid and Kean, Hope H. and Webb, Taylor W. and Kean, Faith S. and Graziano, Michael S. A.},
  year = {2018},
  volume = {116},
  doi = {10.1073/pnas.1816581115},
  abstract = {As a part of social cognition, people automatically construct rich models of other people's vision. Here we show that when people judge the mechanical forces acting on an object, their judgments are biased by another person gazing at the object. The bias is consistent with an implicit perception that gaze adds a gentle force, pushing on the object. The bias was present even though the participants were not explicitly aware of it and claimed that they did not believe in an extramission view of vision (a common folk view of vision in which the eyes emit an invisible energy). A similar result was not obtained on control trials when participants saw a blindfolded face turned toward the object, or a face with open eyes turned away from the object. The findings suggest that people automatically and implicitly generate a model of other people's vision that uses the simplifying construct of beams coming out of the eyes. This implicit model of active gaze may be a hidden, yet fundamental, part of the rich process of social cognition, contributing to how we perceive visual agency. It may also help explain the extraordinary cultural persistence of the extramission myth of vision.},
  journal = {Proceedings of the National Academy of Sciences},
  number = {1}
}

@article{haar1910theorie,
  title = {Zur Theorie Der Orthogonalen Funktionensysteme},
  author = {Haar, Alfred},
  year = {1910},
  volume = {69},
  journal = {Mathematische Annalen},
  number = {3}
}

@article{Hall:2009WEKA,
  title = {The {{WEKA}} Data Mining Software: An Update},
  shorttitle = {The {{WEKA}} Data Mining Software},
  author = {Hall, Mark and Frank, Eibe and Holmes, Geoffrey and Pfahringer, Bernhard and Reutemann, Peter and Witten, Ian H.},
  year = {2009},
  month = nov,
  volume = {11},
  pages = {10},
  issn = {19310145},
  doi = {10.1145/1656274.1656278},
  abstract = {More than twelve years have elapsed since the first public release of WEKA. In that time, the software has been rewritten entirely from scratch, evolved substantially and now accompanies a text on data mining [35]. These days, WEKA enjoys widespread acceptance in both academia and business, has an active community, and has been downloaded more than 1.4 million times since being placed on SourceForge in April 2000. This paper provides an introduction to the WEKA workbench, reviews the history of the project, and, in light of the recent 3.6 stable release, briefly discusses what has been added since the last stable version (Weka 3.4) released in 2003.},
  journal = {ACM SIGKDD Explorations Newsletter},
  language = {en},
  number = {1}
}

@article{Hanwell:2015iv,
  title = {The {{Visualization Toolkit}} ({{VTK}}): {{Rewriting}} the Rendering Code for Modern Graphics Cards},
  author = {Hanwell, Marcus D. and Martin, Kenneth M. and Chaudhary, Aashish and Avila, Lisa S.},
  year = {2015},
  volume = {1},
  doi = {10.1016/j.softx.2015.04.001},
  abstract = {The Visualization Toolkit (VTK) is an open source, permissively licensed, cross-platform toolkit for scientific data processing, visualization, and data analysis. It is over two decades old, originally developed for a very different graphics card architecture. Modern graphics cards feature fully programmable, highly parallelized architectures with large core counts. VTK's rendering code was rewritten to take advantage of modern graphics cards, maintaining most of the toolkit's programming interfaces. This offers the opportunity to compare the performance of old and new rendering code on the same systems/cards. Significant improvements in rendering speeds and memory footprints mean that scientific data can be visualized in greater detail than ever before. The widespread use of VTK means that these improvements will reap significant benefits.},
  journal = {SoftwareX}
}

@article{Harada:2012fr,
  title = {Forward+: {{Bringing Deferred Lighting}} to the {{Next Level}}},
  shorttitle = {Forward+},
  author = {Harada, Takahiro and McKee, Jay and Yang, Jason C.},
  year = {2012},
  pages = {4 pages},
  issn = {1017-4656},
  doi = {10.2312/conf/eg2012/short/005-008},
  abstract = {This paper presents Forward+, a method of rendering many lights by culling and storing only lights that contribute to the pixel. Forward+ is an extension to traditional forward rendering. Light culling, implemented using the compute capability of the GPU, is added to the pipeline to create lists of lights; that list is passed to the final rendering shader, which can access all information about the lights. Although Forward+ increases workload to the final shader, it theoretically requires less memory traffic compared to compute-based deferred lighting. Furthermore, it removes the major drawback of deferred techniques, which is a restriction of materials and lighting models. Experiments are performed to compare the performance of Forward+ and deferred lighting.},
  journal = {Eurographics 2012},
  keywords = {Categories and Subject Descriptors (according to ACM CCS): I.3.7 [Computer Graphics]: Three-DimensionalGraphics and Realism-Color; shading; shadowing; and texture},
  language = {eng}
}

@article{haradaForwardBringingDeferred2012,
  title = {Forward+: {{Bringing}} Deferred Lighting to the next Level},
  author = {Harada, T and McKee, J and Yang, J C},
  year = {2012},
  abstract = {This paper presents Forward+, a method of rendering many lights by culling and storing only lights that contribute to the pixel. Forward+ is an extension to traditional forward rendering. Light culling, implemented using the compute capability of the GPU, is added to the pipeline}
}

@article{Harding:2008b12,
  title = {Evolution of {{Image Filters}} on {{Graphics Processor Units Using Cartesian Genetic Programming}}},
  author = {Harding, Simon},
  year = {2008},
  doi = {10.1109/cec.2008.4631051},
  abstract = {Graphics processor units are fast, inexpensive parallel computing devices. Recently there has been great interest in harnessing this power for various types of scientific computation, including genetic programming. In previous work, we have shown that using the graphics processor provides dramatic speed improvements over a standard CPU in the context of fitness evaluation. In this work, we use Cartesian Genetic Programming to generate shader programs that implement image filter operations. Using the GPU, we can rapidly apply these programs to each pixel in an image and evaluate the performance of a given filter. We show that we can successfully evolve noise removal filters that produce better image quality than a standard median filter.},
  journal = {2008 IEEE Congress on Evolutionary Computation (IEEE World Congress on Computational Intelligence)}
}

@article{Harding:2013b12,
  title = {Genetic {{Programming Theory}} and {{Practice X}}},
  author = {Harding, Simon and Leitner, J{\"u}rgen and Schmidhuber, J{\"u}rgen},
  year = {2013},
  abstract = {Combining domain knowledge about both imaging processing and machine learning techniques can expand the abilities of Genetic Programming when used for image processing. We successfully demonstrate our new approach on several different problem domains. We show that the approach is fast, scalable and robust. In addition, by virtue of using off-the-shelf image processing libraries we can generate human readable programs that incorporate sophisticated domain knowledge.}
}

@incollection{Harilal:2014gj,
  title = {Femtosecond {{Laser Ablation}}: {{Fundamentals}} and {{Applications}}},
  author = {Harilal, Sivanandan S and Freeman, Justin R and Diwakar, Prasoon K and Hassanein, Ahmed},
  year = {2014},
  isbn = {978-3-642-45084-6}
}

@inproceedings{harrington2017,
  title = {Competitive Dynamics in Eco-Evolutionary Genetically-Regulated Swarms},
  booktitle = {Proceedings of the 14th {{European Conference}} on {{Artificial Life ECAL}} 2017},
  author = {Harrington, Kyle I.S. and Magbunduku, Louise},
  year = {2017},
  month = sep,
  pages = {190--197},
  publisher = {{MIT Press}},
  address = {{Lyon, France}},
  doi = {10.7551/ecal_a_034},
  isbn = {978-0-262-34633-7},
  language = {en}
}

@article{Hart:1988tlx,
  title = {Development of {{NASA}}-{{TLX}} ({{Task Load Index}}): {{Results}} of {{Empirical}} and {{Theoretical Research}}},
  author = {Hart, Sandra G. and Staveland, Lowell E.},
  year = {1988},
  volume = {52},
  doi = {10.1016/s0166-4115(08)62386-9},
  abstract = {The results of a multi-year research program to identify the factors associated with variations in subjective workload within and between different types of tasks are reviewed. Subjective evaluations of 10 workload-related factors were obtained from 16 different experiments. The experimental tasks included simple cognitive and manual control tasks, complex laboratory and supervisory control tasks, and aircraft simulation. Task-, behavior-, and subject-related correlates of subjective workload experiences varied as a function of difficulty manipulations within experiments, different sources of workload between experiments, and individual differences in workload definition. A multi-dimensional rating scale is proposed in which information about the magnitude and sources of six workload-related factors are combined to derive a sensitive and reliable estimate of workload.},
  journal = {Advances in Psychology}
}

@article{harten1994adaptive,
  title = {Adaptive Multiresolution Schemes for Shock Computations},
  author = {Harten, Ami},
  year = {1994},
  volume = {115},
  journal = {Journal of Computational Physics},
  number = {2}
}

@article{Harz:1991ff,
  title = {Rhodopsin-Regulated Calcium Currents in {{Chlamydomonas}}},
  author = {Harz, Hartmann and Hegemann, Peter},
  year = {1991},
  volume = {351},
  doi = {10.1038/351489a0},
  abstract = {Rhodopsin-regulated calcium currents in Chlamydomonas},
  journal = {Nature},
  number = {6326}
}

@article{Hatscher:2017bi,
  title = {{{GazeTap}}: Towards Hands-Free Interaction in the Operating Room},
  author = {Hatscher, Benjamin and Luz, Maria and Nacke, Lennart E and Elkmann, Norbert and M{\"u}ller, Veit and Hansen, Christian},
  year = {2017},
  doi = {10.1145/3136755.3136759},
  journal = {the 19th ACM International Conference}
}

@misc{hdf52017,
  title = {Hierarchical {{Data Format}}, Version 5},
  author = {Group, The HDF},
  year = {1997}
}

@article{heemskerk2015tissue,
  title = {Tissue Cartography: Compressing Bio-Image Data by Dimensional Reduction},
  author = {Heemskerk, Idse and Streichan, Sebastian J},
  year = {2015},
  volume = {12},
  journal = {Nature Methods},
  number = {12}
}

@article{Heide:1999we,
  title = {Electrooculography: Technical Standards and Applications. {{The International Federation}} of {{Clinical Neurophysiology}}},
  shorttitle = {Electrooculography},
  author = {Heide, Wolfgang and Koenig, Eberhard and Trillenberg, Peter and K{\"o}mpf, Detlef and Zee, David S.},
  year = {1999},
  volume = {52},
  pages = {223--240},
  issn = {0424-8155},
  journal = {Electroencephalography and Clinical Neurophysiology. Supplement},
  keywords = {Electromagnetic Phenomena,Electrooculography,Eye Movements,Humans,Infrared Rays,Nervous System Diseases,Quality of Health Care,Television},
  language = {eng},
  pmid = {10590990}
}

@article{heim1995,
  title = {Improved Green Fluorescence},
  author = {Heim, Roger and Cubitt, Andrew B. and Tsien, Roger Y.},
  year = {1995},
  volume = {373},
  doi = {10.1038/373663b0},
  journal = {Nature},
  number = {6516}
}

@article{hejazialhosseini2010high,
  title = {High Order Finite Volume Methods on Wavelet-Adapted Grids with Local Time-Stepping on Multicore Architectures for the Simulation of Shock-Bubble Interactions},
  author = {Hejazialhosseini, Babak and Rossinelli, Diego and Bergdorf, Michael and Koumoutsakos, Petros},
  year = {2010},
  volume = {229},
  journal = {Journal of Computational Physics},
  number = {22}
}

@article{Helmuth:2017e4d,
  title = {Improving Generalization of Evolved Programs through Automatic Simplification},
  author = {Helmuth, Thomas and McPhee, Nicholas Freitag and Pantridge, Edward and Spector, Lee},
  year = {2017},
  abstract = {Programs evolved by genetic programming unfortunately often do not generalize to unseen data. Reliable synthesis of programs that generalize to unseen data is therefore an important open problem. We present evidence that smaller programs evolved using the PushGP system tend to generalize better over a range of program synthesis problems. Like in many genetic programming systems, programs evolved by PushGP usually have pieces that can be removed without changing the behavior of the program. We describe methods for automatically simplifying evolved programs to make them smaller and potentially improve their generalization. We present five simplification methods and analyze their strengths and weaknesses on a suite of general program synthesis benchmark problems. All of our methods use a straightforward hill-climbing procedure to remove pieces of a program while ensuring that the resulting program gives the same errors on the training data as did the original program. We show that automatic simplification, previously used both for post-run analysis and as a genetic operator, can significantly improve the generalization rates of evolved programs.}
}

@article{henderson2003human,
  title = {Human Gaze Control during Real-World Scene Perception},
  author = {Henderson, John M},
  year = {2003},
  volume = {7},
  journal = {Trends in Cognitive Sciences},
  number = {11}
}

@article{hePhyShareSharingPhysical2017,
  title = {{{PhyShare}}: {{Sharing Physical Interaction}} in {{Virtual Reality}}},
  author = {He, Zhenyi and Zhu, Fengyuan and Perlin, Ken},
  year = {2017},
  abstract = {We present PhyShare, a new haptic user interface based on actuated robots. Virtual reality has recently been gaining wide adoption, and an effective haptic feedback in these scenarios can strongly support user's sensory in bridging virtual and physical world. Since participants do not directly observe these robotic proxies, we investigate the multiple mappings between physical robots and virtual proxies that can utilize the resources needed to provide a well rounded VR experience. PhyShare bots can act either as directly touchable objects or invisible carriers of physical objects, depending on different scenarios. They also support distributed collaboration, allowing remotely located VR collaborators to share the same physical feedback.}
}

@article{Hernndez-Orozco:20189ef,
  title = {Algorithmically Probable Mutations Reproduce Aspects of Evolution, Such as Convergence Rate, Genetic Memory and Modularity},
  author = {{Hern{\'a}ndez-Orozco}, Santiago and Kiani, Narsis A. and Zenil, Hector},
  year = {2018},
  volume = {5},
  doi = {10.1098/rsos.180399},
  abstract = {Natural selection explains how life has evolved over millions of years from more primitive forms. The speed at which this happens, however, has sometimes defied formal explanations when based on random (uniformly distributed) mutations. Here, we investigate the application of a simplicity bias based on a natural but algorithmic distribution of mutations (no recombination) in various examples, particularly binary matrices, in order to compare evolutionary convergence rates. Results both on synthetic and on small biological examples indicate an accelerated rate when mutations are not statistically uniform but algorithmically uniform. We show that algorithmic distributions can evolve modularity and genetic memory by preservation of structures when they first occur sometimes leading to an accelerated production of diversity but also to population extinctions, possibly explaining naturally occurring phenomena such as diversity explosions (e.g. the Cambrian) and massive extinctions (e.g. the End Triassic) whose causes are currently a cause for debate. The natural approach introduced here appears to be a better approximation to biological evolution than models based exclusively upon random uniform mutations, and it also approaches a formal version of open-ended evolution based on previous formal results. These results validate some suggestions in the direction that computation may be an equally important driver of evolution. We also show that inducing the method on problems of optimization, such as genetic algorithms, has the potential to accelerate convergence of artificial evolutionary algorithms.},
  journal = {Royal Society Open Science},
  number = {8}
}

@article{Herrmann:2017bn,
  title = {A Cell-Based Computational Model of Early Embryogenesis Coupling Mechanical Behaviour and Gene Regulation},
  author = {Herrmann, Matthieu and Delile, Julien and eacute {ras}, Nadine Peyri and eacute Doursat, Ren},
  year = {2017},
  volume = {8},
  doi = {10.1038/ncomms13929},
  abstract = {Nature Communications 8,  (2017). doi:10.1038/ncomms13929},
  journal = {Nature Communications}
}

@article{Hirzle:2019Design,
  title = {A {{Design Space}} for {{Gaze Interaction}} on {{Head}}-Mounted {{Displays}}},
  author = {Hirzle, Teresa and Gugenheimer, Jan and Geiselhart, Florian and Bulling, Andreas and Rukzio, Enrico},
  year = {2019}
}

@inproceedings{hirzle2019,
  title = {A {{Design Space}} for {{Gaze Interaction}} on {{Head}}-Mounted {{Displays}}},
  booktitle = {Proceedings of the 2019 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}  - {{CHI}} '19},
  author = {Hirzle, Teresa and Gugenheimer, Jan and Geiselhart, Florian and Bulling, Andreas and Rukzio, Enrico},
  year = {2019},
  pages = {1--12},
  publisher = {{ACM Press}},
  address = {{Glasgow, Scotland Uk}},
  doi = {10.1145/3290605.3300855},
  isbn = {978-1-4503-5970-2},
  language = {en}
}

@article{Hoppe:2018ko,
  title = {Eye {{Movements During Everyday Behavior Predict Personality Traits}}},
  author = {Hoppe, Sabrina and Loetscher, Tobias and Morey, Stephanie A and Bulling, Andreas},
  year = {2018},
  volume = {12},
  doi = {10.3389/fnhum.2018.00105},
  abstract = {Besides allowing us to perceive our surroundings, eye movements are also a window into our mind and a rich source of information on who we are, how we feel, and what we do.Besides allowing us to perceive our surroundings, eye movements are also a window into our mind and a rich source of information on who we are, how we feel, and what we do.},
  journal = {Frontiers in Human Neuroscience}
}

@article{Huang:2015ce,
  title = {The Light Field Stereoscope: Immersive Computer Graphics via Factored near-Eye Light Field Displays with Focus Cues},
  author = {Huang, Fu-Chung and Chen, Kevin and Wetzstein, Gordon},
  year = {2015},
  volume = {34},
  doi = {10.1145/2766922},
  abstract = {Abstract Over the last few years, virtual reality (VR) has re-emerged as a technology that is now feasible at low cost via inexpensive cellphone components. In particular, advances of high-resolution micro displays, low-latency orientation trackers, and modern GPUs ...},
  journal = {ACM Transactions on Graphics (TOG)},
  number = {4}
}

@article{huang1994moving,
  title = {Moving Mesh Partial Differential Equations ({{MMPDES}}) Based on the Equidistribution Principle},
  author = {Huang, Weizhang and Ren, Yuhe and Russell, Robert D},
  year = {1994},
  volume = {31},
  journal = {SIAM Journal on Numerical Analysis},
  number = {3}
}

@book{huang2010adaptive,
  title = {Adaptive Moving Mesh Methods},
  author = {Huang, Weizhang and Russell, Robert D},
  year = {2010}
}

@article{Huisken:2004ky,
  title = {Optical {{Sectioning Deep Inside Live Embryos}} by {{Selective Plane Illumination Microscopy}}},
  author = {Huisken, Jan},
  year = {2004},
  volume = {305},
  doi = {10.1126/science.1100035},
  journal = {Science},
  number = {5686}
}

@phdthesis{huisken2004multi,
  ids = {Huisken:5iIUZiJj},
  title = {Multi-View {{Microscopy}} and {{Multi}}-Beam {{Manipulation}} for {{High}}-Resolution {{Optical Imaging}}},
  author = {Huisken, Jan},
  year = {2004},
  school = {Albert-Ludwigs-Universit\"at Freiburg im Breisgau}
}

@article{huisken2004optical,
  title = {Optical Sectioning Deep inside Live Embryos by Selective Plane Illumination Microscopy},
  author = {Huisken, Jan and Swoger, Jim and Bene, Filippo Del and Wittbrodt, Joachim and Stelzer, Ernst HK},
  year = {2004},
  volume = {305},
  journal = {Science},
  number = {5686}
}

@article{hunter2015problems,
  title = {Better Tools, New Problems},
  author = {Hunter, Philip},
  year = {2015},
  volume = {16},
  doi = {10.15252/embr.201541061},
  journal = {EMBO reports},
  number = {9}
}

@article{Huynh:2009Metrics,
  title = {Metrics for {{3D Rotations}}: {{Comparison}} and {{Analysis}}},
  author = {Huynh, Du Q.},
  year = {2009},
  volume = {35},
  doi = {10.1007/s10851-009-0161-2},
  abstract = {3D rotations arise in many computer vision, computer graphics, and robotics problems and evaluation of the distance between two 3D rotations is often an essential task. This paper presents a detailed analysis of six functions for measuring distance between 3D rotations that have been proposed in the literature. Based on the well-developed theory behind 3D rotations, we demonstrate that five of them are bi-invariant metrics on SO(3) but that only four of them are boundedly equivalent to each other. We conclude that it is both spatially and computationally more efficient to use quaternions for 3D rotations. Lastly, by treating the two rotations as a true and an estimated rotation matrix, we illustrate the geometry associated with iso-error measures.},
  journal = {Journal of Mathematical Imaging and Vision},
  number = {2}
}

@article{igouchkine2017,
  title = {Multi-{{Material Volume Rendering}} with a {{Physically}}-{{Based Surface Reflection Model}}},
  author = {Igouchkine, Oleg and Zhang, Yubo and Ma, Kwan-Liu},
  year = {2017},
  volume = {24},
  doi = {10.1109/tvcg.2017.2784830},
  abstract = {Rendering techniques that increase realism in volume visualization help enhance perception of the 3D features in the volume data. While techniques focusing on high-quality global illumination have been extensively studied, few works handle the interaction of light with materials in the volume. Existing techniques for light-material interaction are limited in their ability to handle high-frequency real-world material data, and the current treatment of volume data poorly supports the correct integration of surface materials. In this paper, we introduce an alternative definition for the transfer function which supports surface-like behavior at the boundaries between volume components and volume-like behavior within. We show that this definition enables multi-material rendering with high-quality, real-world material data. We also show that this approach offers an efficient alternative to pre-integrated rendering through isosurface techniques. We introduce arbitrary spatially-varying materials to achieve better multi-material support for scanned volume data. Finally, we show that it is possible to map an arbitrary set of parameters directly to a material representation for the more intuitive creation of novel materials.},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  number = {12}
}

@article{Incardona:2019OpenFPM,
  title = {{{OpenFPM}}: {{A}} Scalable Open Framework for Particle and Particle-Mesh Codes on Parallel Computers},
  shorttitle = {{{OpenFPM}}},
  author = {Incardona, Pietro and Leo, Antonio and Zaluzhnyi, Yaroslav and Ramaswamy, Rajesh and Sbalzarini, Ivo F.},
  year = {2019},
  month = aug,
  volume = {241},
  pages = {155--177},
  issn = {00104655},
  doi = {10.1016/j.cpc.2019.03.007},
  journal = {Computer Physics Communications},
  language = {en}
}

@article{iske2015optimally,
  title = {Optimally Sparse Image Approximation by Adaptive Linear Splines over Anisotropic Triangulations},
  author = {Iske, Armin and Demaret, Laurent},
  year = {2015},
  journal = {Sampling Theory and Applications (SampTA), 2015 International Conference on}
}

@article{Itti:2001cl,
  title = {Computational Modelling of Visual Attention.},
  author = {Itti, Laurent and Koch, Christof},
  year = {2001},
  volume = {2},
  doi = {10.1038/35058500},
  abstract = {Five important trends have emerged from recent work on computational models of focal visual attention that emphasize the bottom-up, image-based control of attentional deployment. First, the perceptual saliency of stimuli critically depends on the surrounding context. Second, a unique 'saliency map' that topographically encodes for stimulus conspicuity over the visual scene has proved to be an efficient and plausible bottom-up control strategy. Third, inhibition of return, the process by which the currently attended location is prevented from being attended again, is a crucial element of attentional deployment. Fourth, attention and eye movements tightly interplay, posing computational challenges with respect to the coordinate system used to control attention. And last, scene understanding and object recognition strongly constrain the selection of attended locations. Insights from these five key areas provide a framework for a computational and neurobiological understanding of visual attention.},
  journal = {Nature Reviews Neuroscience},
  number = {3}
}

@article{Itti:2005ck,
  title = {Quantifying the Contribution of Low-Level Saliency to Human Eye Movements in Dynamic Scenes},
  author = {Itti, Laurent},
  year = {2005},
  volume = {12},
  doi = {10.1080/13506280444000661},
  journal = {Visual Cognition},
  number = {6}
}

@inproceedings{Jacob:1990hz,
  title = {What You Look at Is What You Get: Eye Movement-Based Interaction Techniques},
  shorttitle = {What You Look at Is What You Get},
  booktitle = {Proceedings of the {{SIGCHI}} Conference on {{Human}} Factors in Computing Systems {{Empowering}} People - {{CHI}} '90},
  author = {Jacob, Robert J. K.},
  year = {1990},
  pages = {11--18},
  publisher = {{ACM Press}},
  address = {{Seattle, Washington, United States}},
  doi = {10.1145/97243.97246},
  isbn = {978-0-201-50932-8},
  language = {en}
}

@article{jacob:1993,
  title = {Eye Movement-Based Human-Computer Interaction Techniques: {{Toward}} Non-Command Interfaces},
  author = {Jacob, Robert J. K.},
  year = {1993},
  pages = {151--190},
  abstract = {User-computer dialogues are typically one-sided, with the bandwidth from computer to user far greater than that from user to computer. The movement of a user's eyes can provide a convenient, natural, and high-bandwidth source of additional user input, to help redress this imbalance. We therefore investigate the introduction of eye movements as a computer input medium. Our emphasis is on the study of interaction techniques that incorporate eye movements into the user-computer dialogue in a convenient and natural way. This chapter~\ldots},
  journal = {Advances in Human-Computer Interaction}
}

@article{Jang:2017dr,
  title = {Retinal {{3D}}},
  author = {Jang, Changwon and Bang, Kiseung and Moon, Seokil and Kim, Jonghyun and Lee, Seungjae and Lee, Byoungho},
  year = {2017},
  volume = {36},
  doi = {10.1145/3130800.3130889},
  journal = {ACM Transactions on Graphics},
  number = {6}
}

@article{jansen2001multiscale,
  title = {Multiscale Image Processing Using Normal Triangulated Meshes},
  author = {Jansen, Maarten and Choi, Hyeokho and Lavu, Sridhar and Baraniuk, Richard},
  year = {2001},
  volume = {2},
  journal = {Image Processing, 2001. Proceedings. 2001 International Conference on}
}

@phdthesis{jedOpenSourceLinearGenetic,
  title = {Open-{{Source Linear Genetic Programming}}},
  author = {Jed, Simson},
  abstract = {Linear Genetic Programming (LGP) is a paradigm of genetic programmingthat employs a representation of linearly sequenced instructions in automaticallygenerated programs. A linear approach lends itself to programs which have two uniqueattributes: a graph-based functional structure and the existence of non-effectiveinstructions.Motivated by the lack of existing implementations, an LGP system is developed andreleased into the open-source community. The system has a modern design withemphasis on correctness, ease of use, and extensibility. This work discusses LGPconcepts and the implementation of a modern LGP system.The system built is evaluated on a set of symbolic regression benchmark problemsto ensure performance and correctness of the implementation.  Three rounds ofexperiments demonstrate (1) the effects of different configurations of the system, (2) acomparison of different evolutionary algorithm performance within the system, and (3)the equivalence to a traditional tree-based GP approach and linear regression model.}
}

@article{jensen2016active,
  title = {Active Appearance Segmentation for Intensity Inhomogeneity in Light Sheet Fluorescence Microscopy},
  author = {Jensen, Casper Bo and Lyksborg, Mark and {Hecksher-S}, J and Secher, Anna and Conradsen, Knut and Dahl, Anders Bjorholm and {o}, t},
  year = {2016},
  journal = {Biomedical Imaging (ISBI), 2016 IEEE 13th International Symposium on}
}

@book{Jerald:2015vk,
  title = {The {{VR Book}}: {{Human}}-{{Centered Design}} for {{Virtual Reality}}},
  author = {Jerald, Jason},
  year = {2015},
  month = oct,
  publisher = {{Association for Computing Machinery}},
  doi = {10.1145/2792790},
  abstract = {Virtual reality (VR) potentially provides our minds with direct access to digital media in a way that at first seems to have no limits.However, creating compelling VR experiences is an incredibly complex challenge.When VR is done well, the results are brilliant and pleasurable experiences that go beyond what we can do in the real world.When VR is done badly, not only is the system frustrating to use, but sickness can result.Reasons for bad VR are numerous; some failures come from the limitations of technology, but many come from a lack of understanding perception, interaction, design principles, and real users. This book discusses such issues, focusing upon the human element of VR rather than technical implementation, for if we do not get the human element correct, then no amount of technology will make VR anything more than an interesting tool confined to research laboratories. Even when VR principles are fully understood, first implementations are rarely novel and never ideal due to the complex nature of VR and the countless possibilities. However, the VR principles discussed within enable us to intelligently experiment with the rules and iteratively design towards innovative experiences.},
  isbn = {978-1-970001-12-9}
}

@article{jiang2016automatic,
  title = {Automatic {{Light}}-Sheet {{Imaging Plugin}} for {{Rapid Threedimensional Visualization}} of {{Embryo Angiopoiesis}} on {{Common Wide}}-Field {{Microscope}}},
  author = {Jiang, Hao and Yu, Tingting and Nie, Jun and Fang, Chunyu and Zhu, Dan and Fei, Peng},
  year = {2016},
  journal = {Asia Communications and Photonics Conference}
}

@article{Jinek:2012hm,
  title = {A Programmable Dual-{{RNA}}-Guided {{DNA}} Endonuclease in Adaptive Bacterial Immunity.},
  author = {Jinek, Martin and Chylinski, Krzysztof and Fonfara, Ines and Hauer, Michael and Doudna, Jennifer A and Charpentier, Emmanuelle},
  year = {2012},
  volume = {337},
  doi = {10.1126/science.1225829},
  abstract = {Clustered regularly interspaced short palindromic repeats (CRISPR)/CRISPR-associated (Cas) systems provide bacteria and archaea with adaptive immunity against viruses and plasmids by using CRISPR RNAs (crRNAs) to guide the silencing of invading nucleic acids. We show here that in a subset of these systems, the mature crRNA that is base-paired to trans-activating crRNA (tracrRNA) forms a two-RNA structure that directs the CRISPR-associated protein Cas9 to introduce double-stranded (ds) breaks in target DNA. At sites complementary to the crRNA-guide sequence, the Cas9 HNH nuclease domain cleaves the complementary strand, whereas the Cas9 RuvC-like domain cleaves the noncomplementary strand. The dual-tracrRNA:crRNA, when engineered as a single RNA chimera, also directs sequence-specific Cas9 dsDNA cleavage. Our study reveals a family of endonucleases that use dual-RNAs for site-specific DNA cleavage and highlights the potential to exploit the system for RNA-programmable genome editing.},
  journal = {Science},
  number = {6096}
}

@article{jinek2012programmable,
  title = {A Programmable Dual-{{RNA}}--Guided {{DNA}} Endonuclease in Adaptive Bacterial Immunity},
  author = {Jinek, Martin and Chylinski, Krzysztof and Fonfara, Ines and Hauer, Michael and Doudna, Jennifer A and Charpentier, Emmanuelle},
  year = {2012},
  volume = {337},
  journal = {Science},
  number = {6096}
}

@article{John:1995cp,
  title = {{{CPM}}-{{GOMS}}: An Analysis Method for Tasks with Parallel Activities},
  author = {John, Bonnie E. and Gray, Wayne D.},
  year = {1995},
  doi = {10.1145/223355.223738},
  abstract = {An abstract is not available.}
}

@article{John:1996e29,
  title = {The {{GOMS}} Family of User Interface Analysis Techniques: Comparison and Contrast},
  author = {John, Bonnie E. and Kieras, David E.},
  year = {1996},
  volume = {3},
  doi = {10.1145/235833.236054},
  abstract = {Sine the publication of The Psychology of Human-Computer Interaction, the GOMS model has been one of the most widely known theoretical concepts in HCI. This concept has produced severval GOMS analysis techniques that differ in appearance and form, underlying architectural assumptions, and predictive power. This article compares and contrasts four popular variantsof the GOMS family (the Keystroke-Level Model, the original GOMS formulation, NGOMSL, and CPM-GOMS) by applying them to a single task example.},
  journal = {ACM Transactions on Computer-Human Interaction (TOCHI)},
  number = {4}
}

@article{Johnston:20189ce,
  title = {Journey to the Centre of the Cell: {{Virtual}} Reality Immersion into Scientific Data},
  author = {Johnston, Angus P.R. and Rae, James and Ariotti, Nicholas and Bailey, Benjamin and Lilja, Andrew and Webb, Robyn and Ferguson, Charles and Maher, Sheryl and Davis, Thomas P. and Webb, Richard I. and McGhee, John and Parton, Robert G.},
  year = {2018},
  volume = {19},
  doi = {10.1111/tra.12538},
  abstract = {Visualization of scientific data is crucial not only for scientific discovery but also to communicate science and medicine to both experts and a general audience. Until recently, we have been limited to visualizing the three-dimensional (3D) world of biology in 2 dimensions. Renderings of 3D cells are still traditionally displayed using two-dimensional (2D) media, such as on a computer screen or paper. However, the advent of consumer grade virtual reality (VR) headsets such as Oculus Rift and HTC Vive means it is now possible to visualize and interact with scientific data in a 3D virtual world. In addition, new microscopic methods provide an unprecedented opportunity to obtain new 3D data sets. In this perspective article, we highlight how we have used cutting edge imaging techniques to build a 3D virtual model of a cell from serial block-face scanning electron microscope (SBEM) imaging data. This model allows scientists, students and members of the public to explore and interact with a ``real'' cell. Early testing of this immersive environment indicates a significant improvement in students' understanding of cellular processes and points to a new future of learning and public engagement. In addition, we speculate that VR can become a new tool for researchers studying cellular architecture and processes by populating VR models with molecular data.},
  journal = {Traffic},
  number = {2}
}

@article{jonssonInviwoVisualizationSystem2019,
  title = {Inviwo - {{A Visualization System}} with {{Usage Abstraction Levels}}},
  author = {Jonsson, Daniel and Steneteg, Peter and Sunden, Erik and Englund, Rickard and Kottravel, Sathish and Falk, Martin and Ynnerman, Anders and Hotz, Ingrid and Ropinski, Timo},
  year = {2019},
  volume = {PP},
  doi = {10.1109/tvcg.2019.2920639},
  abstract = {The complexity of today's visualization applications demands specific visualization systems tailored for the development of these applications. Frequently, such systems utilize levels of abstraction to improve the application development process, for instance by providing a data flow network editor. Unfortunately, these abstractions result in several issues, which need to be circumvented through an abstraction-centered system design. Often, a high level of abstraction hides low level details, which makes it difficult to directly access the underlying computing platform, which would be important to achieve an optimal performance. Therefore, we propose a layer structure developed for modern and sustainable visualization systems allowing developers to interact with all contained abstraction levels. We refer to this interaction capabilities as usage abstraction levels, since we target application developers with various levels of experience. We formulate the requirements for such a system, derive the desired architecture, and present how the concepts have been exemplary realized within the Inviwo visualization system. Furthermore, we address several specific challenges that arise during the realization of such a layered architecture, such as communication between different computing platforms, performance centered encapsulation, as well as layer-independent development by supporting cross layer documentation and debugging capabilities.},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  number = {99}
}

@article{Jr.:1999b29,
  title = {What's Real about Virtual Reality?},
  author = {Jr., F.P. Brooks},
  year = {1999},
  volume = {19},
  doi = {10.1109/38.799723},
  abstract = {The author presents a personal assessment of the state of the art of VR. In 1994, he surveyed the field of VR. His assessment then was that VR almost worked, but that we were not yet there. There were lots of demos and pilot systems, but except for vehicle simulators and entertainment applications, VR was not yet in production use doing real work. This year he was invited to do an up-to-date assessment of VR, with funding to visit major centers in North America and Europe. Every one of the component technologies has made big strides. Moreover, I found that there now exist some VR applications routinely operated for the results they produce.},
  journal = {IEEE Computer Graphics and Applications},
  number = {6}
}

@article{Kajiya:1986tre,
  title = {The Rendering Equation},
  author = {Kajiya, James T.},
  year = {1986},
  volume = {20},
  doi = {10.1145/15922.15902},
  abstract = {We present an integral equation which generalizes a variety of known rendering algorithms. In the course of discussing a monte carlo solution we also present a new form of variance reduction, called Hierarchical sampling and give a number of elaborations shows that it may be an efficient new technique for a wide variety of monte carlo procedures. The resulting rendering algorithm extends the range of optical phenomena which can be effectively simulated.},
  journal = {ACM SIGGRAPH Computer Graphics},
  number = {4}
}

@article{kajiyaRayTracingVolume1984,
  title = {Ray Tracing Volume Densities},
  author = {Kajiya, James T. and Herzen, Brian P Von},
  year = {1984},
  volume = {18},
  doi = {10.1145/800031.808594},
  abstract = {This paper presents new algorithms to trace objects represented by densities within a volume grid, e.g. clouds, fog, flames, dust, particle systems. We develop the light scattering equations, discuss previous methods of solution, and present a new approximate solution to the full three-dimensional radiative scattering problem suitable for use in computer graphics. Additionally we review dynamical models for clouds used to make an animated movie.},
  journal = {ACM SIGGRAPH Computer Graphics},
  number = {3}
}

@article{kamaliBrain3DVisual2019,
  title = {Brain on the {{3D Visual Art}} through {{Virtual Reality}}; {{Introducing Neuro}}-{{Art}} in a {{Case Investigation}}},
  author = {Kamali, Ali-Mohammad and Najafi, Mohammad Taghi and Nami, Mohammad},
  year = {2019},
  abstract = {The reciprocal impact of applied neuroscience and cognitive studies on humanities has been extensive and growing over the past 30 years of research. Studies on neuroaesthetics have provided novel insights in visual arts, music as well as abstract and dramatic art. Neuro-Art is an experimental concept in applied neuroscience where scientists can study the mechanistic pathways involved for instance in visual art through which creativity and artistic capacity might receive further empowerment. Based on the existing evidence, at least 3 large-scale brain networks are involved simultaneously when one is submitted to a creativity-related task. The question whether the key brain regions involved in visual art creativity can be identified and receive neuromodulation to get empowered prompted us to perform the present case investigation. Virtual reality and functional quantitative electroencephalography upon 2- vs 3-dimentional painting were employed to study cortical neurodynamics in a professional painting artist.}
}

@article{Kampe:2013dp,
  title = {High Resolution Sparse Voxel {{DAGs}}},
  author = {K{\"a}mpe, Viktor and Sintorn, Erik and Assarsson, Ulf},
  year = {2013},
  volume = {32},
  doi = {10.1145/2461912.2462024},
  journal = {ACM Transactions on Graphics},
  number = {4}
}

@article{KartalKoc2015marsreview,
  title = {Model Selection in Multivariate Adaptive Regression Splines ({{MARS}}) Using Information Complexity as the Fitness Function},
  author = {Koc, Elcin Kartal and Bozdogan, Hamparsum},
  year = {2015},
  volume = {101},
  doi = {10.1007/s10994-014-5440-5},
  abstract = {This paper introduces information-theoretic measure of complexity (ICOMP) criterion for model selection in multivariate adaptive regression splines (MARS) to tradeoff efficiently between how well the model fits the data and the model complexity. As is well known, MARS is a popular nonparametric regression technique used to study the nonlinear relationship between a response variable and the set of predictors with the help of piecewise linear or cubic splines as basis functions. A critical aspect in determining the form of the nonparametric regression model during the MARS strategy is the evaluation of portfolio of submodels to select the best submodel with the appropriate number of knots over subset of predictors. In the usual regression modeling, when a large number of predictor variables are present in the model, and there is no precise information about the exact functional relationships among the variables, many model selection criteria still overfit the model. In this paper, to find the simplest model that balances the overfitting and underfitting for the model, ICOMP is proposed as a powerful model selection criterion for MARS modeling. Here, the model complexity is treated with respect to the interdependency of parameter estimates, as well as the number of free parameters in the model. We develop and study the performance of ICOMP along with several most popular model selection criteria such as Akaike's information criterion, Schwarz's Bayesian information criterion and generalized cross-validation in MARS modeling to select the best subset models. We provide two Monte Carlo simulation examples and a real benchmark example to demonstrate the utility and versatility of the proposed model selection approach to determine best functional form of the predictive model. Our numerical examples show that ICOMP provides a general model selection criterion with an insight to the interdependencies and/or correlational structure between parameter estimates in the selected model. This new approach can also be applicable to many complex statistical modeling problems.},
  journal = {Machine Learning},
  number = {1}
}

@inproceedings{Kassner:2014kh,
  title = {Pupil: An Open Source Platform for Pervasive Eye Tracking and Mobile Gaze-Based Interaction},
  shorttitle = {Pupil},
  booktitle = {Proceedings of the 2014 {{ACM International Joint Conference}} on {{Pervasive}} and {{Ubiquitous Computing}}},
  author = {Kassner, Moritz and Patera, William and Bulling, Andreas},
  year = {2014},
  pages = {1151--1160},
  publisher = {{ACM Press}},
  address = {{Seattle, Washington}},
  doi = {10.1145/2638728.2641695},
  isbn = {978-1-4503-3047-3},
  language = {en}
}

@article{keller2008reconstruction,
  title = {Reconstruction of Zebrafish Early Embryonic Development by Scanned Light Sheet Microscopy},
  author = {Keller, Philipp J and Schmidt, Annette D and Wittbrodt, Joachim and Stelzer, Ernst HK},
  year = {2008},
  volume = {322},
  journal = {Science},
  number = {5904}
}

@article{kennedy1993,
  title = {Simulator {{Sickness Questionnaire}}: {{An Enhanced Method}} for {{Quantifying Simulator Sickness}}},
  author = {Kennedy, Robert S. and Lane, Norman E. and Berbaum, Kevin S. and Lilienthal, Michael G.},
  year = {1993},
  volume = {3},
  doi = {10.1207/s15327108ijap0303_3},
  abstract = {Simulator sickness (SS) in high-fidelity visual simulators is a byproduct of modem simulation technology. Although it involves symptoms similar to those of motion-induced sickness (MS), SS tends to be less severe, to be of lower incidence, and to originate from elements of visual display and visuo-vestibular interaction atypical of conditions that induce MS. Most studies of SS to date index severity with some variant of the Pensacola Motion Sickness Questionnaire (MSQ). The MSQ has several deficiencies as an instrument for measuring SS. Some symptoms included in the scoring of MS are irrelevant for SS, and several are misleading. Also, the configural approach of the MSQ is not readily adaptable to computer administration and scoring. This article describes the development of a Simulator Sickness Questiomaire (SSQ), derived from the MSQ using a series of factor analyses, and illustrates its use in monitoring simulator performance with data from a computerized SSQ survey of 3,691 simulator hops. The database used for development included more than 1,100 MSQs, representing data from 10 Navy simulators. The SSQ provides straightforward computer or manual scoring, increased power to identify "problem" simulators, and improved diagnostic capability.},
  journal = {The International Journal of Aviation Psychology},
  number = {3}
}

@article{Keren:2010jd,
  title = {Saccadic Spike Potentials in Gamma-Band {{EEG}}: {{Characterization}}, Detection and Suppression},
  author = {Keren, Alon S and {Yuval-Greenberg}, Shlomit and Deouell, Leon Y},
  year = {2010},
  volume = {49},
  doi = {10.1016/j.neuroimage.2009.10.057},
  journal = {NeuroImage},
  number = {3}
}

@article{keshavarz2011,
  title = {Validating an {{Efficient Method}} to {{Quantify Motion Sickness}}},
  author = {Keshavarz, Behrang and Hecht, Heiko},
  year = {2011},
  volume = {53},
  doi = {10.1177/0018720811403736},
  abstract = {Objective: Motion sickness (MS) can be a debilitating side effect associated with motion in real or virtual environments. We analyzed the effect of expectancy on MS and propose and validate a fast and simple MS measure. Background: Several questionnaires measure MS before or after stimulus presentation, but no satisfactory tool has been established to quickly capture MS data during exposure. To fill this gap, we introduce the Fast MS Scale (FMS), a verbal rating scale ranging from zero (no sickness at all) to 20 (frank sickness). Also, little is known about the role of expectancy effects in MS studies. We conducted an experiment that addressed this issue. Method: For this study, 126 volunteers participated in two experiments. During stimulus presentation, participants had to verbally rate the severity of MS every minute before filling in the Simulator Sickness Questionnaire (SSQ). To measure expectancy effects, participants were separated into three groups with either positive, negative, or neutral expectations. Results: We compared the verbal ratings with the SSQ scores. Pearson correlations were high for both the SSQ total score (r = .785) and the nausea subscore (r = .828). No expectancy effects were found. Conclusion: The FMS is a fast and valid method to obtain MS data. It offers the possibility to record MS during stimulus presentation and to capture its time course. We found expectancy not to play a crucial role in MS. However, the FMS has some limitations. Application: The FMS offers improved MS measurement. It is fast and efficient and can be performed online in environments such as virtual reality.},
  journal = {Human Factors: The Journal of Human Factors and Ergonomics Society},
  number = {4}
}

@incollection{Kiley:2016Cortical,
  title = {Cortical {{Processing}} of {{Visual Signals}}},
  booktitle = {Neuroscience in the 21st {{Century}}},
  author = {Kiley, Caitlin Williams and Usrey, W. Martin},
  editor = {Pfaff, Donald W. and Volkow, Nora D.},
  year = {2016},
  pages = {773--792},
  publisher = {{Springer New York}},
  address = {{New York, NY}},
  doi = {10.1007/978-1-4939-3474-4_24},
  isbn = {978-1-4939-3473-7 978-1-4939-3474-4},
  language = {en}
}

@inproceedings{Klamka:2015ka,
  title = {Look \& {{Pedal}}: {{Hands}}-Free {{Navigation}} in {{Zoomable Information Spaces}} through {{Gaze}}-Supported {{Foot Input}}},
  shorttitle = {Look \& {{Pedal}}},
  booktitle = {Proceedings of the 2015 {{ACM}} on {{International Conference}} on {{Multimodal Interaction}} - {{ICMI}} '15},
  author = {Klamka, Konstantin and Siegel, Andreas and Vogt, Stefan and G{\"o}bel, Fabian and Stellmach, Sophie and Dachselt, Raimund},
  year = {2015},
  pages = {123--130},
  publisher = {{ACM Press}},
  address = {{Seattle, Washington, USA}},
  doi = {10.1145/2818346.2820751},
  isbn = {978-1-4503-3912-4},
  language = {en}
}

@article{Klier:20019e6,
  title = {The Superior Colliculus Encodes Gaze Commands in Retinal Coordinates},
  author = {Klier, Eliana M. and Wang, Hongying and Crawford, J. Douglas},
  year = {2001},
  volume = {4},
  doi = {10.1038/88450},
  abstract = {The superior colliculus (SC) has a topographic map of visual space, but the spatial nature of its output command for orienting gaze shifts remains unclear. Here we show that the SC codes neither desired gaze displacement nor gaze direction in space (as debated previously), but rather, desired gaze direction in retinal coordinates. Electrical micro-stimulation of the SC in two head-free (non-immobilized) monkeys evoked natural-looking, eye-head gaze shifts, with anterior sites producing small, fixed-vector movements and posterior sites producing larger, strongly converging movements. However, when correctly calculated in retinal coordinates, all of these trajectories became 'fixed-vector.' Moreover, our data show that this eye-centered SC command is then further transformed, as a function of eye and head position, by downstream mechanisms into the head- and body-centered commands for coordinated eye-head gaze shifts.},
  journal = {Nature Neuroscience},
  number = {6}
}

@incollection{knoll2019,
  title = {Efficient {{Particle Volume Splatting}} in a {{Ray Tracer}}},
  booktitle = {Ray {{Tracing Gems}}},
  author = {Knoll, Aaron and Morley, R. Keith and Wald, Ingo and Leaf, Nick and Messmer, Peter},
  editor = {Haines, Eric and {Akenine-M{\"o}ller}, Tomas},
  year = {2019},
  pages = {533--541},
  publisher = {{Apress}},
  address = {{Berkeley, CA}},
  doi = {10.1007/978-1-4842-4427-2_29},
  isbn = {978-1-4842-4426-5 978-1-4842-4427-2},
  language = {en}
}

@article{knollRayTracingGems2019,
  title = {Ray {{Tracing Gems}}, {{High}}-{{Quality}} and {{Real}}-{{Time Rendering}} with {{DXR}} and {{Other APIs}}},
  author = {Knoll, Aaron and Morley, R. Keith and Wald, Ingo and Leaf, Nick and Messmer, Peter},
  year = {2019},
  abstract = {Rendering of particle data sets is a common problem in many domains including games, film, and scientific visualization. Conventionally, this has been accomplished using rasterization-based splatting methods, which scale linearly with respect to problem size. Given sufficiently low-cost ray traversal with logarithmic complexity, splatting within a ray tracing framework could scale better to larger geometry. In this chapter, we provide a method for efficiently rendering larger particle data, exploiting ray coherence and leveraging hardware-accelerated traversal on architectures such as the NVIDIA RTX 2080 Ti (Turing) GPUs with RT Cores technology.}
}

@article{knollRBFVolumeRay2014,
  title = {{{RBF Volume Ray Casting}} on {{Multicore}} and {{Manycore CPUs}}},
  author = {Knoll, Aaron and Wald, Ingo and Navratil, Paul and Bowen, Anne and Reda, Khairi and Papka, Michael E. and Gaither, Kelly},
  year = {2014},
  volume = {33},
  doi = {10.1111/cgf.12363},
  abstract = {Modern supercomputers enable increasingly large N-body simulations using unstructured point data. The structures implied by these points can be reconstructed implicitly. Direct volume rendering of radial basis function (RBF) kernels in domain-space offers flexible classification and robust feature reconstruction, but achieving performant RBF volume rendering remains a challenge for existing methods on both CPUs and accelerators. In this paper, we present a fast CPU method for direct volume rendering of particle data with RBF kernels. We propose a novel two-pass algorithm: first sampling the RBF field using coherent bounding hierarchy traversal, then subsequently integrating samples along ray segments. Our approach performs interactively for a range of data sets from molecular dynamics and astrophysics up to 82 million particles. It does not rely on level of detail or subsampling, and offers better reconstruction quality than structured volume rendering of the same data, exhibiting comparable performance and requiring no additional preprocessing or memory footprint other than the BVH. Lastly, our technique enables multi-field, multi-material classification of particle data, providing better insight and analysis.},
  journal = {Computer Graphics Forum},
  number = {3}
}

@article{koch2006much,
  title = {How Much the Eye Tells the Brain},
  author = {Koch, Kristin and McLean, Judith and Segev, Ronen and Freed, Michael A and Berry, Michael J and Balasubramanian, Vijay and Sterling, Peter},
  year = {2006},
  volume = {16},
  journal = {Current Biology},
  number = {14}
}

@article{kohler2014review,
  title = {A Review and Comparison of Bandwidth Selection Methods for Kernel Regression},
  author = {K{\"o}hler, Max and Schindler, Anja and Sperlich, Stefan},
  year = {2014},
  volume = {82},
  journal = {International Statistical Review},
  number = {2}
}

@inproceedings{Kosch:2018Your,
  title = {Your {{Eyes Tell}}: {{Leveraging Smooth Pursuit}} for {{Assessing Cognitive Workload}}},
  shorttitle = {Your {{Eyes Tell}}},
  booktitle = {Proceedings of the 2018 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}  - {{CHI}} '18},
  author = {Kosch, Thomas and Hassib, Mariam and Wo{\'z}niak, Pawe{\l} W. and Buschek, Daniel and Alt, Florian},
  year = {2018},
  pages = {1--13},
  publisher = {{ACM Press}},
  address = {{Montreal QC, Canada}},
  doi = {10.1145/3173574.3174010},
  abstract = {A common objective for context-aware computing systems is to predict how user interfaces impact user performance regarding their cognitive capabilities. Existing approaches such as questionnaires or pupil dilation measurements either only allow for subjective assessments or are susceptible to environmental influences and user physiology. We address these challenges by exploiting the fact that cognitive workload influences smooth pursuit eye movements. We compared three trajectories and two speeds under different levels of cognitive workload within a user study (N=20). We found higher deviations of gaze points during smooth pursuit eye movements for specific trajectory types at higher cognitive workload levels. Using an SVM classifier, we predict cognitive workload through smooth pursuit with an accuracy of 99.5\% for distinguishing between low and high workload as well as an accuracy of 88.1\% for estimating workload between three levels of difficulty. We discuss implications and present use cases of how cognition-aware systems benefit from inferring cognitive workload in real-time by smooth pursuit eye movements.},
  isbn = {978-1-4503-5620-6},
  language = {en}
}

@article{Krebs:20105e6,
  title = {High-{{Field fMRI Reveals Brain Activation Patterns Underlying Saccade Execution}} in the {{Human Superior Colliculus}}},
  author = {Krebs, Ruth M. and Woldorff, Marty G. and Tempelmann, Claus and Bodammer, Nils and Noesselt, Toemme and Boehler, Carsten N. and Scheich, Henning and Hopf, Jens-Max and Duzel, Emrah and Heinze, Hans-Jochen and Schoenfeld, Mircea A.},
  year = {2010},
  volume = {5},
  doi = {10.1371/journal.pone.0008691},
  abstract = {The superior colliculus (SC) has been shown to play a crucial role in the initiation and coordination of eye- and head-movements. The knowledge about the function of this structure is mainly based on single-unit recordings in animals with relatively few neuroimaging studies investigating eye-movement related brain activity in humans. The present study employed high-field (7 Tesla) functional magnetic resonance imaging (fMRI) to investigate SC responses during endogenously cued saccades in humans. In response to centrally presented instructional cues, subjects either performed saccades away from (centrifugal) or towards (centripetal) the center of straight gaze or maintained fixation at the center position. Compared to central fixation, the execution of saccades elicited hemodynamic activity within a network of cortical and subcortical areas that included the SC, lateral geniculate nucleus (LGN), occipital cortex, striatum, and the pulvinar. Activity in the SC was enhanced contralateral to the direction of the saccade (i.e., greater activity in the right as compared to left SC during leftward saccades and vice versa) during both centrifugal and centripetal saccades, thereby demonstrating that the contralateral predominance for saccade execution that has been shown to exist in animals is also present in the human SC. In addition, centrifugal saccades elicited greater activity in the SC than did centripetal saccades, while also being accompanied by an enhanced deactivation within the prefrontal default-mode network. This pattern of brain activity might reflect the reduced processing effort required to move the eyes toward as compared to away from the center of straight gaze, a position that might serve as a spatial baseline in which the retinotopic and craniotopic reference frames are aligned.},
  journal = {PLoS ONE},
  number = {1}
}

@article{Kroes:2012bo,
  title = {Exposure {{Render}}: {{An Interactive Photo}}-{{Realistic Volume Rendering Framework}}},
  author = {Kroes, Thomas and Post, Frits H and Botha, Charl P},
  year = {2012},
  volume = {7},
  doi = {10.1371/journal.pone.0038586},
  abstract = {The field of volume visualization has undergone rapid development during the past years, both due to advances in suitable computing hardware and due to the increasing availability of large volume datasets. Recent work has focused on increasing the visual realism in Direct Volume Rendering (DVR) by integrating a number of visually plausible but often effect-specific rendering techniques, for instance modeling of light occlusion and depth of field. Besides yielding more attractive renderings, especially the more realistic lighting has a positive effect on perceptual tasks. Although these new rendering techniques yield impressive results, they exhibit limitations in terms of their exibility and their performance. Monte Carlo ray tracing (MCRT), coupled with physically based light transport, is the de-facto standard for synthesizing highly realistic images in the graphics domain, although usually not from volumetric data. Due to the stochastic sampling of MCRT algorithms, numerous effects can be achieved in a relatively straight-forward fashion. For this reason, we have developed a practical framework that applies MCRT techniques also to direct volume rendering (DVR). With this work, we demonstrate that a host of realistic effects, including physically based lighting, can be simulated in a generic and flexible fashion, leading to interactive DVR with improved realism. In the hope that this improved approach to DVR will see more use in practice, we have made available our framework under a permissive open source license.},
  journal = {PLoS ONE},
  number = {7}
}

@article{krzic2012multiview,
  title = {Multiview Light-Sheet Microscope for Rapid in Toto Imaging},
  author = {Krzic, Uros and Gunther, Stefan and Saunders, Timothy E and Streichan, Sebastian J and Hufnagel, Lars},
  year = {2012},
  volume = {9},
  journal = {Nature Methods},
  number = {7}
}

@article{Kumar:2018rvi,
  title = {Integrated One- and Two-Photon Scanned Oblique Plane Illumination ({{SOPi}}) Microscopy for Rapid Volumetric Imaging},
  author = {Kumar, Manish and Kishore, Sandeep and Nasenbeny, Jordan and McLean, David and Kozorovitskiy, Yevgenia},
  year = {2018},
  volume = {26},
  doi = {10.1364/oe.26.013027},
  abstract = {Versatile, sterically accessible imaging systems capable of in vivo rapid volumetric functional and structural imaging deep in the brain continue to be a limiting factor in neuroscience research. Towards overcoming this obstacle, we present integrated one- and two-photon scanned oblique plane illumination (SOPi) microscopy which uses a single front-facing microscope objective to provide light-sheet scanning based rapid volumetric imaging capability at subcellular resolution. Our planar scan-mirror based optimized light-sheet architecture allows for non-distorted scanning of volume samples, simplifying accurate reconstruction of the imaged volume. Integration of both one-photon (1P) and two-photon (2P) light-sheet microscopy in the same system allows for easy selection between rapid volumetric imaging and higher resolution imaging in scattering media. Using SOPi, we demonstrate deep, large volume imaging capability inside scattering mouse brain sections and rapid imaging speeds up to 10 volumes per second in zebrafish larvae expressing genetically encoded fluorescent proteins GFP or GCaMP6s. SOPi flexibility and steric access makes it adaptable for numerous imaging applications and broadly compatible with orthogonal techniques for actuating or interrogating neuronal structure and activity.},
  journal = {Optics Express},
  number = {10}
}

@article{Lafaurie-Janvore:2013ae0,
  title = {{{ESCRT}}-{{III Assembly}} and {{Cytokinetic Abscission Are Induced}} by {{Tension Release}} in the {{Intercellular Bridge}}},
  author = {{Lafaurie-Janvore}, Julie and Maiuri, Paolo and Wang, Ir{\`e}ne and Pinot, Mathieu and Manneville, Jean-Baptiste and Betz, Timo and Balland, Martial and Piel, Matthieu},
  year = {2013},
  volume = {339},
  doi = {10.1126/science.1233866},
  abstract = {The last step of cell division, cytokinesis, produces two daughter cells that remain connected by an intercellular bridge. This state often represents the longest stage of the division process. Severing the bridge (abscission) requires a well-described series of molecular events, but the trigger for abscission remains unknown. We found that pulling forces exerted by daughter cells on the intercellular bridge appear to regulate abscission. Counterintuitively, these forces prolonged connection, whereas a release of tension induced abscission. Tension release triggered the assembly of ESCRT-III (endosomal sorting complex required for transport\textendash III), which was followed by membrane fission. This mechanism may allow daughter cells to remain connected until they have settled in their final locations, a process potentially important for tissue organization and morphogenesis.},
  journal = {Science},
  number = {6127}
}

@article{lahaEffectsImmersionVisual2012,
  title = {Effects of {{Immersion}} on {{Visual Analysis}} of {{Volume Data}}},
  author = {Laha, Bireswar and Sensharma, Kriti and Schiffbauer, James D. and Bowman, Doug A.},
  year = {2012},
  volume = {18},
  doi = {10.1109/tvcg.2012.42},
  abstract = {Volume visualization has been widely used for decades for analyzing datasets ranging from 3D medical images to seismic data to paleontological data. Many have proposed using immersive virtual reality (VR) systems to view volume visualizations, and there is anecdotal evidence of the benefits of VR for this purpose. However, there has been very little empirical research exploring the effects of higher levels of immersion for volume visualization, and it is not known how various components of immersion influence the effectiveness of visualization in VR. We conducted a controlled experiment in which we studied the independent and combined effects of three components of immersion (head tracking, field of regard, and stereoscopic rendering) on the effectiveness of visualization tasks with two x-ray microscopic computed tomography datasets. We report significant benefits of analyzing volume data in an environment involving those components of immersion. We find that the benefits do not necessarily require all three components simultaneously, and that the components have variable influence on different task categories. The results of our study improve our understanding of the effects of immersion on perceived and actual task performance, and provide guidance on the choice of display systems to designers seeking to maximize the effectiveness of volume visualization applications.},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  number = {4}
}

@article{Laine:EffectiveSVO,
  title = {Effective {{Sparse Voxel Octrees}} - {{Analysis}}, {{Extensions}} and {{Implementation}}},
  author = {Laine, Samuel and Karras, Tero},
  year = {2010},
  journal = {Nvidia Technical Reports}
}

@article{LaMar:1999Multiresolution,
  title = {Multiresolution Techniques for Interactive Texture-Based Volume Visualization},
  author = {LaMar, E. and Hamann, B. and Joy, K.I.},
  year = {1999},
  doi = {10.1109/visual.1999.809908},
  abstract = {We present a multiresolution technique for interactive texture-based volume visualization of very large data sets. This method uses an adaptive scheme that renders the volume in a region-of-interest at a high resolution and the volume away from this region at progressively lower resolutions. The algorithm is based on the segmentation of texture space into an octree, where the leaves of the tree define the original data and the internal nodes define lower-resolution versions. Rendering is done adaptively by selecting high-resolution cells close to a center of attention and low-resolution cells away from this area. We limit the artifacts introduced by this method by modifying the transfer functions in the lower-resolution data sets and utilizing spherical shells as a proxy geometry. It is possible to use this technique to produce viewpoint-dependent renderings of very large data sets.},
  journal = {Proceedings Visualization '99 (Cat. No.99CB37067)}
}

@inproceedings{Lattner:2004vw,
  title = {{{LLVM}}: {{A}} Compilation Framework for Lifelong Program Analysis \& Transformation},
  shorttitle = {{{LLVM}}},
  booktitle = {International {{Symposium}} on {{Code Generation}} and {{Optimization}}, 2004. {{CGO}} 2004.},
  author = {Lattner, Chris and Adve, Vikram},
  year = {2004},
  pages = {75--86},
  publisher = {{IEEE}},
  address = {{San Jose, CA, USA}},
  doi = {10.1109/CGO.2004.1281665},
  isbn = {978-0-7695-2102-2}
}

@article{laufsMT4jCrossplatformMultitouch2010,
  title = {{{MT4j}} - {{A Cross}}-Platform {{Multi}}-Touch {{Development Framework}}},
  author = {Laufs, Uwe and Ruff, Christopher and Zibuschka, Jan},
  year = {2010},
  abstract = {This article describes requirements and challenges of crossplatform multi-touch software engineering, and presents the open source framework Multi-Touch for Java (MT4j) as a solution. MT4j is designed for rapid development of graphically rich applications on a variety of contemporary hardware, from common PCs and notebooks to large-scale ambient displays, as well as different operating systems. The framework has a special focus on making multi-touch software development easier and more efficient. Architecture and abstractions used by MT4j are described, and implementations of several common use cases are presented.}
}

@inproceedings{Laugwitz:2008Construction,
  title = {Construction and {{Evaluation}} of a {{User Experience Questionnaire}}},
  booktitle = {Proc. {{USAB}} 2008},
  author = {Laugwitz, Bettina and Held, Theo},
  year = {2008},
  pages = {63--76},
  publisher = {{Springer}},
  abstract = {Abstract. An end-user questionnaire to measure user experience quickly in a simple and immediate way while covering a preferably comprehensive impres-sion of the product user experience was the goal of the reported construction process. An empirical approach for the item selection was used to ensure practi-cal relevance of items. Usability experts collected terms and statements on user experience and usability, including `hard ' as well as `soft ' aspects. These state-ments were consolidated and transformed into a first questionnaire version con-taining 80 bipolar items. It was used to measure the user experience of software products in several empirical studies. Data were subjected to a factor analysis which resulted in the construction of a 26 item questionnaire including the six}
}

@article{Laver:2017vrsr,
  title = {Virtual Reality for Stroke Rehabilitation},
  author = {Laver, Kate E and Lange, Belinda and George, Stacey and Deutsch, Judith E and Saposnik, Gustavo and Crotty, Maria},
  year = {2017},
  volume = {11},
  doi = {10.1002/14651858.cd008349.pub4},
  abstract = {Virtual reality for stroke rehabilitation Review question We wanted to compare the effects of virtual reality versus an alternative treatment or no treatment on recovery after stroke using arm function and other outcomes such as walking speed and independence in managing daily activities after stroke. Background Many people after having a stroke have difficulty moving, thinking, and sensing. This often results in problems with everyday activities such as writing, walking, and driving. Virtual reality and interactive video gaming are types of therapy being provided to people after having a stroke. The therapy involves using computer-based programs designed to simulate real life objects and events. Virtual reality and interactive video gaming may have some advantages over traditional therapy approaches as they can give people an opportunity to practise everyday activities that are not or cannot be practised within the hospital environment. Furthermore, there are several features of virtual reality programs that might mean that patients spend more time in therapy: for example, the activity might be more motivating. Study characteristics We identified 72 studies involving 2470 people after stroke. A wide range of virtual reality programs were used, with most aimed to improve either arm function or walking ability. The evidence is current to April 2017. Key results Twenty-two trials tested whether the use of virtual reality compared with conventional therapy resulted in an improved ability to use one's arm and found that the use of virtual reality did not result in better function (low-quality evidence). When virtual reality was used in addition to usual care or rehabilitation to increase the amount of time the person spent in therapy there were improvements in the functioning of the arm (low-quality evidence). Six trials tested whether the use of virtual reality compared with conventional therapy resulted in improved walking speed. There was no evidence that virtual reality was more effective in this case (low-quality evidence). Ten trials found that there was some evidence that virtual reality resulted in a slightly better ability to manage everyday activities such as showering and dressing (moderate-quality evidence). However, these positive effects were found soon after the end of the treatment and it is not clear whether the effects are long lasting. Results should be interpreted with caution as, while there are a large number of studies, the studies are generally small and not of high quality. A small number of people using virtual reality reported pain, headaches, or dizziness. No serious adverse events were reported. Quality of the evidence The quality of the evidence was generally of low or moderate quality. The quality of the evidence for each outcome was limited due to small numbers of study participants, inconsistent results across studies, and poor reporting of study details.},
  journal = {Cochrane Database of Systematic Reviews},
  number = {11}
}

@article{lee1998maps,
  title = {{{MAPS}}: {{Multiresolution}} Adaptive Parameterization of Surfaces},
  author = {Lee, Aaron WF and Sweldens, Wim and Schr{\"o}der, Peter and Cowsar, Lawrence and Dobkin, David},
  year = {1998},
  journal = {Proceedings of the 25th annual conference on Computer graphics and interactive techniques}
}

@article{Leitner:2014f4e,
  title = {Improving {{Robot Vision Models}} for {{Object Detection}} through {{Interaction}}},
  author = {Leitner, J{\"u}rgen and F{\"o}rster, Alexander and Schmidhuber, J{\"u}rgen},
  year = {2014},
  doi = {10.1109/ijcnn.2014.6889556},
  abstract = {We propose a method for learning specific object representations that can be applied (and reused) in visual detection and identification tasks. A machine learning technique called Cartesian Genetic Programming (CGP) is used to create these models based on a series of images. Our research investigates how manipulation actions might allow for the development of better visual models and therefore better robot vision. This paper describes how visual object representations can be learned and improved by performing object manipulation actions, such as, poke, push and pick-up with a humanoid robot. The improvement can be measured and allows for the robot to select and perform the `right' action, i.e. the action with the best possible improvement of the detector.},
  journal = {2014 International Joint Conference on Neural Networks (IJCNN)}
}

@article{lenard2015endothelial,
  title = {Endothelial Cell Self-Fusion during Vascular Pruning},
  author = {Lenard, Anna and Daetwyler, Stephan and Betz, Charles and Ellertsdottir, Elin and Belting, Heinz-Georg and Huisken, Jan and Affolter, Markus},
  year = {2015},
  volume = {13},
  journal = {PLoS Biology},
  number = {4}
}

@article{levoy1990,
  title = {Gaze-Directed Volume Rendering},
  author = {Levoy, Marc and Whitaker, Ross},
  year = {1990},
  volume = {24},
  doi = {10.1145/91385.91449},
  abstract = {We direct our gaze at an object by rotating our eyes or head until the object's projection falls on the fovea, a small region of enhanced spatial acuity near the center of the retina. In this paper, we explore methods for encorporating gaze direction into rendering algorithms. This approach permits generation of images exhibiting continuously varying resolution, and allows these images to be displayed on conventional television monitors. Specifically, we describe a ray tracer for volume data in which the number of rays cast per unit area on the image plane and the number of samples drawn per unit length along each ray are functions of local retinal acuity. We also describe an implementation using 2D and 3D mip maps, an eye tracker, and the Pixel-Planes 5 massively parallel raster display system. Pending completion of Pixel-Planes 5 in the spring of 1990, we have written a simulator on a Stellar graphics supercomputer. Preliminary results indicate that while users are aware of the variable-resolution structure of the image, the high-resolution sweet spot follows their gaze well and promises to be useful in practice.},
  journal = {ACM SIGGRAPH Computer Graphics},
  number = {2}
}

@article{Li:2005ha,
  title = {Fast Noninvasive Activation and Inhibition of Neural and Network Activity by Vertebrate Rhodopsin and Green Algae Channelrhodopsin.},
  author = {Li, Xiang and Gutierrez, Davina V and Hanson, M Gartz and Han, Jing and Mark, Melanie D and Chiel, Hillel and Hegemann, Peter and Landmesser, Lynn T and Herlitze, Stefan},
  year = {2005},
  volume = {102},
  doi = {10.1073/pnas.0509030102},
  abstract = {Techniques for fast noninvasive control of neuronal excitability will be of major importance for analyzing and understanding neuronal networks and animal behavior. To develop these tools we demonstrated that two light-activated signaling proteins, vertebrate rat rhodopsin 4 (RO4) and the green algae channelrhodospin 2 (ChR2), could be used to control neuronal excitability and modulate synaptic transmission. Vertebrate rhodopsin couples to the Gi/o, pertussis toxin-sensitive pathway to allow modulation of G protein-gated inward rectifying potassium channels and voltage-gated Ca2+ channels. Light-mediated activation of RO4 in cultured hippocampal neurons reduces neuronal firing within ms by hyperpolarization of the somato-dendritic membrane and when activated at presynaptic sites modulates synaptic transmission and paired-pulse facilitation. In contrast, somato-dendritic activation of ChR2 depolarizes neurons sufficiently to induce immediate action potentials, which precisely follow the ChR2 activation up to light stimulation frequencies of 20 Hz. To demonstrate that these constructs are useful for regulating network behavior in intact organisms, embryonic chick spinal cords were electroporated with either construct, allowing the frequency of episodes of spontaneous bursting activity, known to be important for motor circuit formation, to be precisely controlled. Thus light-activated vertebrate RO4 and green algae ChR2 allow the antagonistic control of neuronal function within ms to s in a precise, reversible, and noninvasive manner in cultured neurons and intact vertebrate spinal cords.},
  journal = {Proceedings of the National Academy of Sciences},
  number = {49}
}

@article{Li:2014f0b,
  title = {Encoding of {{Both Analog}}- and {{Digital}}-like {{Behavioral Outputs}} by {{One C}}.~Elegans {{Interneuron}}},
  author = {Li, Zhaoyu and Liu, Jie and Zheng, Maohua and Xu, X.Z. Shawn},
  year = {2014},
  volume = {159},
  doi = {10.1016/j.cell.2014.09.056},
  abstract = {Model organisms usually possess a small nervous system but nevertheless execute a large array of complex behaviors, suggesting that some neurons are likely multifunctional and may encode multiple behavioral outputs. Here, we show that the C. elegans interneuron AIY regulates two distinct behavioral outputs: locomotion speed and direction-switch by recruiting~two different circuits. The ``speed'' circuit is excitatory with a wide dynamic range, which is well suited to encode speed, an analog-like output. The~``direction-switch'' circuit is inhibitory with a narrow dynamic range, which is ideal for encoding direction-switch, a digital-like output. Both circuits~employ the neurotransmitter ACh but utilize distinct~postsynaptic ACh receptors, whose distinct biophysical properties contribute to the distinct dynamic ranges of the two circuits. This mechanism enables graded C.~elegans synapses to encode both analog- and digital-like outputs. Our studies illustrate how an interneuron in a simple organism encodes multiple behavioral outputs at the circuit, synaptic, and molecular levels.},
  journal = {Cell},
  number = {4}
}

@article{Li:20193c4,
  title = {In~{{Vivo Quantitative Imaging Provides Insights}} into {{Trunk Neural Crest Migration}}},
  author = {Li, Yuwei and Vieceli, Felipe M. and Gonzalez, Walter G. and Li, Ang and Tang, Weiyi and Lois, Carlos and Bronner, Marianne E.},
  year = {2019},
  volume = {26},
  doi = {10.1016/j.celrep.2019.01.039},
  abstract = {Neural crest (NC) cells undergo extensive migrations during development. Here, we couple in~vivo live imaging at high resolution with custom software tools to reveal dynamic migratory behavior in chick embryos. Trunk NC cells migrate as individuals with~both stochastic and biased features as they move~dorsoventrally to form peripheral ganglia. Their leading edge displays a prominent fan-shaped lamellipodium that reorients upon cell-cell contact. Computational analysis reveals that when the lamellipodium of one cell touches the body of another, the two cells undergo ``contact attraction,'' often moving together and then separating via a pulling force exerted by lamellipodium. Targeted optical manipulation shows that cell interactions coupled with cell density generate a long-range biased random walk behavior, such that cells move from high to low density. In contrast to chain migration noted at other axial levels, the results show that individual trunk NC cells navigate the complex environment without tight coordination between neighbors.},
  journal = {Cell Reports},
  number = {6}
}

@article{liang2017namlet,
  title = {The {{NAMlet}} Transform: {{A}} Novel Image Sparse Representation Method Based on Non-Symmetry and Anti-Packing Model},
  author = {Liang, Hu and Zhao, Shengrong and Chen, Chuanbo and Sarem, Mudar},
  year = {2017},
  volume = {137},
  journal = {Signal Processing}
}

@article{Lin:20182dd,
  title = {Kinematic Analysis of Direct Pointing in Projection-Based Stereoscopic Environments},
  author = {Lin, Chiuhsiang Joe and Woldegiorgis, Bereket Haile},
  year = {2018},
  volume = {57},
  doi = {10.1016/j.humov.2017.11.002},
  journal = {Human Movement Science}
}

@article{Liu:2011048,
  title = {Revisiting Path Steering for {{3D}} Manipulation Tasks},
  author = {Liu, Lei and Martens, Jean-Bernard and van Liere, Robert},
  year = {2011},
  volume = {69},
  doi = {10.1016/j.ijhcs.2010.11.006},
  abstract = {The law of path steering, as proposed by Accot and Zhai, describes a quantitative relationship between the human temporal performance and the path spatial characteristics. The steering law is formulated as a continuous goal-crossing task, in which a large number of goals are crossed along the path. The steering law has been verified empirically for locomotion, in which a virtual driving task through straight and circular paths was performed.We revisit the path steering law for manipulation tasks in desktop virtual environments. We have conducted controlled experiments in which users operated a pen input device to steer a virtual ball through paths of varying length, width, curvature and orientation. Our results indicate that, although the steering law provides a good description of the overall task time as a function of index of difficulty ID=L/W, where L and W are the path length and width, it does not account for other relevant factors. We specifically show that the influence of curvature can be modeled by a percentage increase in steering time, independent of index of difficulty. The path orientation relative to the viewing direction has a periodic effect on the steering time, which can be optimally described by a function of Fourier series expansions. In addition, there is also an effect of the handedness of the subjects on the steering between the left and right districts in 3D manipulation tasks.},
  journal = {International Journal of Human-Computer Studies},
  number = {3}
}

@article{Liu:2018jk,
  title = {Observing the Cell in Its Native State: {{Imaging}} Subcellular Dynamics in Multicellular Organisms.},
  author = {Liu, Tsung-Li and Upadhyayula, Srigokul and Milkie, Daniel E and Singh, Ved and Wang, Kai and Swinburne, Ian A and Mosaliganti, Kishore R and Collins, Zach M and Hiscock, Tom W and Shea, Jamien and Kohrman, Abraham Q and Medwig, Taylor N and Dambournet, Daphne and Forster, Ryan and Cunniff, Brian and Ruan, Yuan and Yashiro, Hanako and Scholpp, Steffen and Meyerowitz, Elliot M and Hockemeyer, Dirk and Drubin, David G and Martin, Benjamin L and Matus, David Q and Koyama, Minoru and Megason, Sean G and Kirchhausen, Tom and Betzig, Eric},
  year = {2018},
  volume = {360},
  doi = {10.1126/science.aaq1392},
  abstract = {True physiological imaging of subcellular dynamics requires studying cells within their parent organisms, where all the environmental cues that drive gene expression, and hence the phenotypes that we actually observe, are present. A complete understanding also requires volumetric imaging of the cell and its surroundings at high spatiotemporal resolution, without inducing undue stress on either. We combined lattice light-sheet microscopy with adaptive optics to achieve, across large multicellular volumes, noninvasive aberration-free imaging of subcellular processes, including endocytosis, organelle remodeling during mitosis, and the migration of axons, immune cells, and metastatic cancer cells in vivo. The technology reveals the phenotypic diversity within cells across different organisms and developmental stages and may offer insights into how cells harness their intrinsic variability to adapt to different physiological environments.},
  journal = {Science},
  number = {6386}
}

@article{liu2010parallel,
  title = {Parallel Graph-Cuts by Adaptive Bottom-up Merging},
  author = {Liu, Jiangyu and Sun, Jian},
  year = {2010},
  journal = {Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on}
}

@article{Longair:2011snt,
  title = {Simple {{Neurite Tracer}}: Open Source Software for Reconstruction, Visualization and Analysis of Neuronal Processes},
  author = {Longair, Mark H. and Baker, Dean A. and Armstrong, J. Douglas},
  year = {2011},
  volume = {27},
  doi = {10.1093/bioinformatics/btr390},
  abstract = {Motivation: Advances in techniques to sparsely label neurons unlock the potential to reconstruct connectivity from 3D image stacks acquired by light microscopy. We present an application for semi-automated tracing of neurons to quickly annotate noisy datasets and construct complex neuronal topologies, which we call the Simple Neurite Tracer. Availability: Simple Neurite Tracer is open source software, licensed under the GNU General Public Licence (GPL) and based on the public domain image processing software ImageJ. The software and further documentation are available via http://fiji.sc/Simple\_Neurite\_Tracer as part of the package Fiji, and can be used on Windows, Mac OS and Linux. Documentation and introductory screencasts are available at the same URL. Contact:longair@ini.phys.ethz.ch; longair@ini.phys.ethz.ch},
  journal = {Bioinformatics},
  number = {17}
}

@article{Lottes:200983a,
  title = {Fast Approximate Anti-Aliasing ({{FXAA}})},
  author = {Lottes, Timothy},
  year = {2009},
  journal = {NVIDIA Corporation, Santa Clara, CA, USA, Feb}
}

@article{lou2014rapid,
  title = {A Rapid and Efficient {{2D}}/{{3D}} Nuclear Segmentation Method for Analysis of Early Mouse Embryo and Stem Cell Image Data},
  author = {Lou, Xinghua and Kang, Minjung and Xenopoulos, Panagiotis and {Munoz-Descalzo}, Silvia and Hadjantonakis, Anna-Katerina},
  year = {2014},
  volume = {2},
  journal = {Stem cell reports},
  number = {3}
}

@article{Lutz:2015ga,
  title = {{{SMOOVS}}: {{Towards}} Calibration-Free Text Entry by Gaze Using Smooth Pursuit Movements},
  author = {Lutz, Otto Hans-Martin and Venjakob, Antje Christine and Ruff, Stefan},
  year = {2015},
  volume = {8},
  doi = {10.16910/jemr.8.1.2},
  abstract = {Gaze-based text spellers have proved useful for people with severe motor diseases, but lack acceptance in general human-computer interaction. In order to use gaze spellers for public displays, they need to be robust and provide an intuitive interaction concept. However, traditional dwell- and blink-based systems need accurate calibration which contradicts fast and intuitive interaction. We developed the first gaze speller explicitly utilizing smooth pursuit eye movements and their particular characteristics. The speller achieves sufficient accuracy with a one-point calibration and does not require extensive training. Its interface consists of character elements which move apart from each other in two stages. As each element has a unique track, gaze following this track can be detected by an algorithm that does not rely on the exact gaze coordinates and compensates latency-based artefacts. In a user study, 24 participants tested four speed-levels of moving elements to determine an optimal interaction speed. At 300 px/s users showed highest overall performance of 3.34 WPM (without training). Subjective ratings support the finding that this pace is superior.},
  journal = {Journal of Eye Movement Research},
  number = {1}
}

@article{Makris:20161c0,
  title = {Augmented Reality System for Operator Support in Human\textendash Robot Collaborative Assembly},
  author = {Makris, Sotiris and Karagiannis, Panagiotis and Koukas, Spyridon and Matthaiakis, Aleksandros-Stereos},
  year = {2016},
  volume = {65},
  doi = {10.1016/j.cirp.2016.04.038},
  abstract = {This paper presents the design and implementation of an augmented reality (AR) tool in aid of operators being in a hybrid, human and robot collaborative industrial environment. The system aims to provide production and process related information as well as to enhance the operators' immersion in the safety mechanisms, dictated by the collaborative workspace. The developed system has been integrated with a service based station controller, which is responsible for orchestrating the flow of information to the operator, according to the task execution status. The tool has been applied to a case study from the automotive sector, resulting in an enhanced operator's integration with the assembly process.},
  journal = {CIRP Annals - Manufacturing Technology},
  number = {1}
}

@article{mallat1989theory,
  title = {A Theory for Multiresolution Signal Decomposition: The Wavelet Representation},
  author = {Mallat, Stephane G},
  year = {1989},
  volume = {11},
  journal = {IEEE transactions on pattern analysis and machine intelligence},
  number = {7}
}

@article{mallat1992singularity,
  title = {Singularity Detection and Processing with Wavelets},
  author = {Mallat, St{\'e}phane and Hwang, Wen Liang},
  year = {1992},
  volume = {38},
  journal = {IEEE Transactions on Information Theory},
  number = {2}
}

@book{mallat2008wavelet,
  title = {A Wavelet Tour of Signal Processing: The Sparse Way},
  author = {Mallat, St{\'e}phane},
  year = {2008}
}

@article{Mangione:2018dbf,
  title = {The {{Dachsous}}/{{Fat}}/{{Four}}-{{Jointed Pathway Directs}} the {{Uniform Axial Orientation}} of {{Epithelial Cells}} in the {{Drosophila Abdomen}}},
  author = {Mangione, Federica and {Mart{\'i}n-Blanco}, Enrique},
  year = {2018},
  volume = {25},
  doi = {10.1016/j.celrep.2018.11.036},
  abstract = {The achievement of the final form of an individual requires not only the control of cell size and differentiation but also integrative directional cues to instruct cell movements, positions, and orientations. In Drosophila, the adult epidermis of the abdomen is created de novo by histoblasts. As these expand and fuse, they uniformly orient along the anteroposterior axis. We found that the Dachsous/Fat/Four-jointed (Ds/Ft/Fj) pathway is key for their alignment. The refinement of the tissue-wide expression of the atypical cadherins Ds and Ft result in their polarization and directional adhesiveness. Mechanistically, the axially oriented changes in histoblasts respond to the redesign of the epithelial field. We suggest that the role of Ds/Ft/Fj in long-range oriented cell alignment is a general function and that the regulation of the expression of its components will be crucial in other morphogenetic models or during tissue repair.},
  journal = {Cell Reports},
  number = {10}
}

@inproceedings{Mania:2004ps,
  title = {Perceptual Sensitivity to Head Tracking Latency in Virtual Environments with Varying Degrees of Scene Complexity},
  booktitle = {Proceedings of the 1st {{Symposium}} on {{Applied}} Perception in Graphics and Visualization  - {{APGV}} '04},
  author = {Mania, Katerina and Adelstein, Bernard D. and Ellis, Stephen R. and Hill, Michael I.},
  year = {2004},
  pages = {39},
  publisher = {{ACM Press}},
  address = {{Los Angeles, California}},
  doi = {10.1145/1012551.1012559},
  isbn = {978-1-58113-914-3},
  language = {en}
}

@article{maParallelVolumeRendering1994,
  title = {Parallel Volume Rendering Using Binary-Swap Compositing},
  author = {Ma, Kwan-Liu and Painter, J.S. and Hansen, C.D. and Krogh, M.F.},
  year = {1994},
  volume = {14},
  doi = {10.1109/38.291532},
  abstract = {We describe a parallel volume-rendering algorithm, which consists of two parts: parallel ray tracing and parallel compositing. In the most recent implementation on Connection Machine's CM-5 and networked workstations, the parallel volume renderer evenly distributes data to the computing resources available. Without the need to communicate with other processing units, each subvolume is ray traced locally and generates a partial image. The parallel compositing process then merges all resulting partial images in depth order to produce the complete image. The compositing algorithm is particularly effective for massively parallel processing, as it always uses all processing units by repeatedly subdividing the partial images and distributing them to the appropriate processing units. Test results on both the CM-5 and the workstations are promising. They do, however, expose different performance issues for each platform.\&lt;\&gt;},
  journal = {IEEE Computer Graphics and Applications},
  number = {4}
}

@article{Maples-Keller:2017790,
  title = {The {{Use}} of {{Virtual Reality Technology}} in the {{Treatment}} of {{Anxiety}} and {{Other Psychiatric Disorders}}},
  author = {{Maples-Keller}, Jessica L. and Bunnell, Brian E. and Kim, Sae-Jin and Rothbaum, Barbara O.},
  year = {2017},
  volume = {25},
  doi = {10.1097/hrp.0000000000000138},
  abstract = {Learning objectives After participating in this activity, learners should be better able to: \textbullet{} Evaluate the literature regarding the effectiveness of incorporating virtual reality (VR) in the treatment of psychiatric disorders \textbullet{} Assess the use of exposure-based intervention for anxiety disorders Abstract Virtual reality (VR) allows users to experience a sense of presence in a computer-generated, three-dimensional environment. Sensory information is delivered through a head-mounted display and specialized interface devices. These devices track head movements so that the movements and images change in a natural way with head motion, allowing for a sense of immersion. VR, which allows for controlled delivery of sensory stimulation via the therapist, is a convenient and cost-effective treatment. This review focuses on the available literature regarding the effectiveness of incorporating VR within the treatment of various psychiatric disorders, with particular attention to exposure-based intervention for anxiety disorders. A systematic literature search was conducted in order to identify studies implementing VR-based treatment for anxiety or other psychiatric disorders. This article reviews the history of the development of VR-based technology and its use within psychiatric treatment, the empirical evidence for VR-based treatment, and the benefits for using VR for psychiatric research and treatment. It also presents recommendations for how to incorporate VR into psychiatric care and discusses future directions for VR-based treatment and clinical research.},
  journal = {Harvard Review of Psychiatry},
  number = {3}
}

@article{marksGettingYourNose2017,
  title = {Getting up Your Nose: A Virtual Reality Education Tool for Nasal Cavity Anatomy},
  author = {Marks, Stefan and White, David and Singh, Manpreet},
  year = {2017},
  abstract = {This article explores the application of virtual reality (VR) to the area of anatomical education, specifically the shape of and the airflow through the human nasal cavity. We argue the benefits of VR technology in this specific domain, and describe the creation of the VR application which is intended to be used in future courses. Through two preliminary case studies, we describe our experiences, and discuss advantages and disadvantages of the use of VR in this area.}
}

@article{Martin:2019cd1,
  title = {The Koniocellular Whiteboard},
  author = {Martin, Paul R. and Solomon, Samuel G.},
  year = {2019},
  volume = {527},
  doi = {10.1002/cne.24426},
  abstract = {In 1994 Vivien Casagrande published a review paper in which she summarized evidence for a koniocellular pathway to visual cortex. Here we try to explain how that review moved the field forward, and summarize some key unanswered questions about koniocellular pathways.},
  journal = {Journal of Comparative Neurology},
  number = {3}
}

@article{Matejcic:2018hj,
  title = {A Non-Cell-Autonomous Actin Redistribution Enables Isotropic Retinal Growth},
  author = {Matej{\v c}i{\'c}, Marija and Salbreux, Guillaume and Norden, Caren},
  year = {2018},
  volume = {16},
  doi = {10.1371/journal.pbio.2006018},
  journal = {PLoS Biology},
  number = {8}
}

@article{matheron1975random,
  title = {Random Sets and Integral Geometry},
  author = {Matheron, Georges and Matheron, Georges and Matheron, Georges and Matheron, Georges},
  year = {1975}
}

@article{mathew2015robust,
  title = {Robust and Automated Three-Dimensional Segmentation of Densely Packed Cell Nuclei in Different Biological Specimens with {{Lines}}-of-{{Sight}} Decomposition},
  author = {Mathew, B and Schmitz, A and {Mu{\~n}oz-Descalzo}, S and Ansari, N and Pampaloni, F and Stelzer, E H K and Fischer, S C},
  year = {2015},
  volume = {16},
  doi = {10.1186/s12859-015-0617-x},
  abstract = {Due to the large amount of data produced by advanced microscopy, automated image analysis is crucial in modern biology. Most applications require reliable cell nuclei segmentation. However, in many biological specimens cell nuclei are densely packed and appear to touch one another in the images. Therefore, a major difficulty of three-dimensional cell nuclei segmentation is the decomposition of cell nuclei that apparently touch each other. Current methods are highly adapted to a certain biological specimen or a specific microscope. They do not ensure similarly accurate segmentation performance, i.e. their robustness for different datasets is not guaranteed. Hence, these methods require elaborate adjustments to each dataset.},
  journal = {BMC Bioinformatics},
  number = {1}
}

@book{mathews1970mathematical,
  title = {Mathematical Methods of Physics},
  author = {Mathews, Jon and Walker, Robert Lee},
  year = {1970}
}

@article{Matthes:2016situ,
  title = {In Situ, Steerable, Hardware-Independent and Data-Structure Agnostic Visualization with {{ISAAC}}},
  author = {Matthes, Alexander and Huebl, Axel and Widera, Ren{\'e} and Grottel, Sebastian and Gumhold, Stefan and Bussmann, Michael},
  year = {2016},
  month = dec,
  volume = {3},
  issn = {23138734},
  doi = {10.14529/jsfi160403},
  journal = {Supercomputing Frontiers and Innovations},
  number = {4}
}

@article{meagher1982geometric,
  title = {Geometric Modeling Using Octree Encoding},
  author = {Meagher, Donald},
  year = {1982},
  volume = {19},
  journal = {Computer graphics and image processing},
  number = {2}
}

@article{Meena:2017bn,
  title = {A Multimodal Interface to Resolve the {{Midas}}-{{Touch}} Problem in Gaze Controlled Wheelchair.},
  author = {Meena, Yogesh Kumar and Cecotti, Hubert and {Wong-Lin}, KongFatt and Prasad, Girijesh},
  year = {2017},
  volume = {2017},
  doi = {10.1109/embc.2017.8036971},
  abstract = {Human-computer interaction (HCI) research has been playing an essential role in the field of rehabilitation. The usability of the gaze controlled powered wheelchair is limited due to Midas-Touch problem. In this work, we propose a multimodal graphical user interface (GUI) to control a powered wheelchair that aims to help upper-limb mobility impaired people in daily living activities. The GUI was designed to include a portable and low-cost eye-tracker and a soft-switch wherein the wheelchair can be controlled in three different ways: 1) with a touchpad 2) with an eye-tracker only, and 3) eye-tracker with soft-switch. The interface includes nine different commands (eight directions and stop) and integrated within a powered wheelchair system. We evaluated the performance of the multimodal interface in terms of lap-completion time, the number of commands, and the information transfer rate (ITR) with eight healthy participants. The analysis of the results showed that the eye-tracker with soft-switch provides superior performance with an ITR of 37.77 bits/min among the three different conditions (p\&lt;;0.05). Thus, the proposed system provides an effective and economical solution to the Midas-Touch problem and extended usability for the large population of disabled users.},
  journal = {Conference proceedings : ... Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual Conference}
}

@article{Meola:20170ce,
  title = {Augmented Reality in Neurosurgery: A Systematic Review},
  author = {Meola, Antonio and Cutolo, Fabrizio and Carbone, Marina and Cagnazzo, Federico and Ferrari, Mauro and Ferrari, Vincenzo},
  year = {2017},
  volume = {40},
  doi = {10.1007/s10143-016-0732-9},
  abstract = {Neuronavigation has become an essential neurosurgical tool in pursuing minimal invasiveness and maximal safety, even though it has several technical limitations. Augmented reality (AR) neuronavigation is a significant advance, providing a real-time updated 3D virtual model of anatomical details, overlaid on the real surgical field. Currently, only a few AR systems have been tested in a clinical setting. The aim is to review such devices. We performed a PubMed search of reports restricted to human studies of in vivo applications of AR in any neurosurgical procedure using the search terms ``Augmented reality'' and ``Neurosurgery.'' Eligibility assessment was performed independently by two reviewers in an unblinded standardized manner. The systems were qualitatively evaluated on the basis of the following: neurosurgical subspecialty of application, pathology of treated lesions and lesion locations, real data source, virtual data source, tracking modality, registration technique, visualization processing, display type, and perception location. Eighteen studies were included during the period 1996 to September 30, 2015. The AR systems were grouped by the real data source: microscope (8), hand- or head-held cameras (4), direct patient view (2), endoscope (1), and X-ray fluoroscopy (1) head-mounted display (1). A total of 195 lesions were treated: 75 (38.46~\%) were neoplastic, 77 (39.48~\%) neurovascular, and 1 (0.51~\%) hydrocephalus, and 42 (21.53~\%) were undetermined. Current literature confirms that AR is a reliable and versatile tool when performing minimally invasive approaches in a wide range of neurosurgical diseases, although prospective randomized studies are not yet available and technical improvements are needed.},
  journal = {Neurosurgical Review},
  number = {4}
}

@article{Mickoleit:2014bl,
  title = {High-Resolution Reconstruction of the Beating Zebrafish Heart.},
  author = {Mickoleit, Michaela and Schmid, Benjamin and Weber, Michael and Fahrbach, Florian O and Hombach, Sonja and Reischauer, Sven and Huisken, Jan},
  year = {2014},
  volume = {11},
  doi = {10.1038/nmeth.3037},
  abstract = {The heart's continuous motion makes it difficult to capture high-resolution images of this organ in vivo. We developed tools based on high-speed selective plane illumination microscopy (SPIM), offering pristine views into the beating zebrafish heart. We captured three-dimensional cardiac dynamics with postacquisition synchronization of multiview movie stacks, obtained static high-resolution reconstructions by briefly stopping the heart with optogenetics and resolved nonperiodic phenomena by high-speed volume scanning with a liquid lens.},
  journal = {Nature Methods},
  number = {9}
}

@article{Mietke:2018b12,
  title = {Self-Organized Shape Dynamics of Active Surfaces},
  author = {Mietke, Alexander and J{\"u}licher, Frank and Sbalzarini, Ivo F.},
  year = {2018},
  volume = {116},
  doi = {10.1073/pnas.1810896115},
  abstract = {Mechanochemical processes in thin biological structures, such as the cellular cortex or epithelial sheets, play a key role during the morphogenesis of cells and tissues. In particular, they are responsible for the dynamical organization of active stresses that lead to flows and deformations of the material. Consequently, advective transport redistributes force-generating molecules and thereby contributes to a complex mechanochemical feedback loop. It has been shown in fixed geometries that this mechanism enables patterning, but the interplay of these processes with shape changes of the material remains to be explored. In this work, we study the fully self-organized shape dynamics using the theory of active fluids on deforming surfaces and develop a numerical approach to solve the corresponding force and torque balance equations. We describe the spontaneous generation of nontrivial surface shapes, shape oscillations, and directed surface flows that resemble peristaltic waves from self-organized, mechanochemical processes on the deforming surface. Our approach provides opportunities to explore the dynamics of self-organized active surfaces and can help to understand the role of shape as an integral element of the mechanochemical organization of morphogenetic processes.},
  journal = {Proceedings of the National Academy of Sciences},
  number = {1}
}

@article{mikut2013automated,
  title = {Automated Processing of Zebrafish Imaging Data: A Survey},
  author = {Mikut, Ralf and Dickmeis, Thomas and Driever, Wolfgang and Geurts, Pierre and Hamprecht, Fred A and Kausler, Bernhard X and {Ledesma-Carbayo}, Mar{\'i}a J and Mar{\'e}e, Rapha{\"e}l and Mikula, Karol and Pantazis, Periklis and {o}, t},
  year = {2013},
  volume = {10},
  journal = {Zebrafish},
  number = {3}
}

@inproceedings{Milgram:1995cl,
  title = {Augmented Reality: A Class of Displays on the Reality-Virtuality Continuum},
  shorttitle = {Augmented Reality},
  booktitle = {Photonics for {{Industrial Applications}}},
  author = {Milgram, Paul and Takemura, Haruo and Utsumi, Akira and Kishino, Fumio},
  editor = {Das, Hari},
  year = {1995},
  month = dec,
  pages = {282--292},
  address = {{Boston, MA}},
  doi = {10.1117/12.197321}
}

@article{min2017binvox,
  title = {Binvox, {{3D}} Mesh Voxelizer},
  author = {Min, Patrick},
  year = {2017},
  journal = {patrickmin.com}
}

@article{mindekVisualizationMultiPipelineCommunicating2017,
  title = {Visualization {{Multi}}-{{Pipeline}} for {{Communicating Biology}}},
  author = {Mindek, Peter and Kouril, David and Sorger, Johannes and Toloudis, Daniel and Lyons, Blair and Johnson, Graham and Groller, M. Eduard and Viola, Ivan},
  year = {2017},
  volume = {24},
  doi = {10.1109/tvcg.2017.2744518},
  abstract = {We propose a system to facilitate biology communication by developing a pipeline to support the instructional visualization of heterogeneous biological data on heterogeneous user-devices. Discoveries and concepts in biology are typically summarized with illustrations assembled manually from the interpretation and application of heterogenous data. The creation of such illustrations is time consuming, which makes it incompatible with frequent updates to the measured data as new discoveries are made. Illustrations are typically non-interactive, and when an illustration is updated, it still has to reach the user. Our system is designed to overcome these three obstacles. It supports the integration of heterogeneous datasets, reflecting the knowledge that is gained from different data sources in biology. After pre-processing the datasets, the system transforms them into visual representations as inspired by scientific illustrations. As opposed to traditional scientific illustration these representations are generated in real-time - they are interactive. The code generating the visualizations can be embedded in various software environments. To demonstrate this, we implemented both a desktop application and a remote-rendering server in which the pipeline is embedded. The remote-rendering server supports multi-threaded rendering and it is able to handle multiple users simultaneously. This scalability to different hardware environments, including multi-GPU setups, makes our system useful for efficient public dissemination of biological discoveries.},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  number = {1}
}

@article{Mirhosseini:2019Immersive,
  title = {Immersive {{Virtual Colonoscopy}}},
  author = {Mirhosseini, Seyedkoosha and Gutenko, Ievgeniia and Ojal, Sushant and Marino, Joseph and Kaufman, Arie},
  year = {2019},
  volume = {25},
  doi = {10.1109/tvcg.2019.2898763},
  abstract = {Virtual colonoscopy (VC) is a non-invasive screening tool for colorectal polyps which employs volume visualization of a colon model reconstructed from a CT scan of the patient's abdomen. We present an immersive analytics system for VC which enhances and improves the traditional desktop VC through the use of VR technologies. Our system, using a head-mounted display (HMD), includes all of the standard VC features, such as the volume rendered endoluminal fly-through, measurement tool, bookmark modes, electronic biopsy, and slice views. The use of VR immersion, stereo, and wider field of view and field of regard has a positive effect on polyp search and analysis tasks in our immersive VC system, a volumetric-based immersive analytics application. Navigation includes enhanced automatic speed and direction controls, based on the user's head orientation, in conjunction with physical navigation for exploration of local proximity. In order to accommodate the resolution and frame rate requirements for HMDs, new rendering techniques have been developed, including mesh-assisted volume raycasting and a novel lighting paradigm. Feedback and further suggestions from expert radiologists show the promise of our system for immersive analysis for VC and encourage new avenues for exploring the use of VR in visualization systems for medical diagnosis.},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  number = {5}
}

@article{mittasch2018,
  title = {Non-Invasive Perturbations of Intracellular Flow Reveal Physical Principles of Cell Organization},
  author = {Mittasch, Matth{\"a}us and Gross, Peter and Nestler, Michael and Fritsch, Anatol W. and Iserman, Christiane and Kar, Mrityunjoy and Munder, Matthias and Voigt, Axel and Alberti, Simon and Grill, Stephan W. and Kreysing, Moritz},
  year = {2018},
  volume = {20},
  doi = {10.1038/s41556-017-0032-9},
  abstract = {Recent advances in cell biology enable precise molecular perturbations. The spatiotemporal organization of cells and organisms, however, also depends on physical processes such as diffusion or cytoplasmic flows, and strategies to perturb physical transport inside cells are not yet available. Here, we demonstrate focused-light-induced cytoplasmic streaming (FLUCS). FLUCS is local, directional, dynamic, probe-free, physiological, and is even applicable through rigid egg shells or cell walls. We explain FLUCS via time-dependent modelling of thermoviscous flows. Using FLUCS, we demonstrate that cytoplasmic flows drive partitioning-defective protein (PAR) polarization in Caenorhabditis elegans zygotes, and that cortical flows are sufficient to transport PAR domains and invert PAR polarity. In addition, we find that asymmetric cell division is a binary decision based on gradually varying PAR polarization states. Furthermore, the use of FLUCS for active microrheology revealed a metabolically induced fluid-to-solid transition of the yeast cytoplasm. Our findings establish how a wide range of transport-dependent models of cellular organization become testable by FLUCS. Mittasch et al. show that controlling cytoplasmic flow via focused-light-induced cytoplasmic streaming (FLUCS), a non-invasive technique, can be used to invert asymmetric cell division in Caenorhabditis elegans zygotes.},
  journal = {Nature Cell Biology},
  number = {3}
}

@inproceedings{Mlot2016,
  title = {{{3D Gaze Estimation}} Using {{Eye Vergence}}:},
  shorttitle = {{{3D Gaze Estimation}} Using {{Eye Vergence}}},
  booktitle = {Proceedings of the 9th {{International Joint Conference}} on {{Biomedical Engineering Systems}} and {{Technologies}}},
  author = {Mlot, Esteban Gutierrez and Bahmani, Hamed and Wahl, Siegfried and Kasneci, Enkelejda},
  year = {2016},
  pages = {125--131},
  publisher = {{SCITEPRESS - Science and and Technology Publications}},
  address = {{Rome, Italy}},
  doi = {10.5220/0005821201250131},
  isbn = {978-989-758-170-0}
}

@article{monaghan1982particle,
  title = {Why Particle Methods Work},
  author = {Monaghan, Joe J},
  year = {1982},
  volume = {3},
  journal = {SIAM Journal on Scientific and Statistical Computing},
  number = {4}
}

@article{monasse2000fast,
  title = {Fast Computation of a Contrast-Invariant Image Representation},
  author = {Monasse, Pascal and Guichard, Frederic},
  year = {2000},
  volume = {9},
  journal = {IEEE Transactions on Image Processing},
  number = {5}
}

@article{Murata:2001ebc,
  title = {Extending {{Fitts}}' Law to a Three-Dimensional Pointing Task},
  author = {Murata, Atsuo and Iwase, Hirokazu},
  year = {2001},
  volume = {20},
  doi = {10.1016/s0167-9457(01)00058-6},
  abstract = {An attempt was made to extend Fitts' law to a three-dimensional movement (pointing) task to enhance its predictive performance in this domain. An experiment was conducted in which 10 subjects performed three-dimensional pointing movements under the manipulation of target size, distance to target and direction to target. As expected, the duration of these three-dimensional movements was rather variable and affected markedly by direction to target. As a result, the variance in the movement times produced was not satisfactorily explained by the conventional Fitts' model. The conventional model was extended by incorporating a directional parameter into the model. The extended model was shown to better fit the data than the conventional Fitts' model, both in terms of r2 and the standard error of the residual between the measured movement time and the value predicted by model fit.},
  journal = {Human Movement Science},
  number = {6}
}

@article{Museth:2013gw,
  title = {{{VDB}}},
  author = {Museth, Ken},
  year = {2013},
  volume = {32},
  doi = {10.1145/2487228.2487235},
  journal = {ACM Transactions on Graphics},
  number = {3}
}

@article{mwalongoStateArtReport2016,
  title = {State-of-the-{{Art Report}} in {{Web}}-based {{Visualization}}},
  author = {Mwalongo, F. and Krone, M. and Reina, G. and Ertl, T.},
  year = {2016},
  volume = {35},
  doi = {10.1111/cgf.12929},
  abstract = {In this report, we review the current state of the art of web-based visualization applications. Recently, an increasing number of web-based visualization applications have emerged. This is due to the fact that new technologies offered by modern browsers greatly increased the capabilities for visualizations on the web. We first review these technical aspects that are enabling this development. This includes not only improvements for local rendering like WebGL and HTML5, but also infrastructures like grid or cloud computing platforms. Another important factor is the transfer of data between the server and the client. Therefore, we also discuss advances in this field, for example methods to reduce bandwidth requirements like compression and other optimizations such as progressive rendering and streaming. After establishing these technical foundations, we review existing web-based visualization applications and prototypes from various application domains. Furthermore, we propose a classification of these web-based applications based on the technologies and algorithms they employ. Finally, we also discuss promising application areas that would benefit from web-based visualization and assess their feasibility based on the existing approaches.},
  journal = {Computer Graphics Forum},
  number = {3}
}

@article{Nalbach:2016wr,
  title = {Deep {{Shading}}: {{Convolutional Neural Networks}} for {{Screen Space Shading}}},
  author = {Nalbach, O. and Arabadzhiyska, E. and Mehta, D. and Seidel, H.-P. and Ritschel, T.},
  year = {2017},
  volume = {36},
  doi = {10.1111/cgf.13225},
  abstract = {In computer vision, convolutional neural networks (CNNs) achieve unprecedented performance for inverse problems where RGB pixel appearance is mapped to attributes such as positions, normals or reflectance. In computer graphics, screen space shading has boosted the quality of real-time rendering, converting the same kind of attributes of a virtual scene back to appearance, enabling effects like ambient occlusion, indirect light, scattering and many more. In this paper we consider the diagonal problem: synthesizing appearance from given per-pixel attributes using a CNN. The resulting Deep Shading renders screen space effects at competitive quality and speed while not being programmed by human experts but learned from example images.},
  journal = {Computer Graphics Forum},
  number = {4}
}

@article{Nielsen:kq,
  title = {Iterative User-Interface Design},
  author = {Nielsen, Jacob and 1, 9},
  volume = {26},
  doi = {10.1109/2.241424},
  abstract = {ABSTRACT\&lt; p\&gt; A method for developing user interfaces by refining them iteratively over several versions is presented. Each iteration is subjected to user testing or other usability- evaluation methods designed to uncover usability problems. This method not only eliminates problems of this nature, but also allows designers to take advantage of any insights into user needs that emerge from the tests. The author describes four case studies where the median improvement in overall usability from the first to the last iteration was~\ldots},
  journal = {computer.org},
  number = {11}
}

@book{Niemz:2007laa,
  title = {Laser-{{Tissue Interactions}}: {{Fundamentals}} and {{Applications}}},
  shorttitle = {Laser-{{Tissue Interactions}}},
  author = {Niemz, Markolf H.},
  year = {2019},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-11917-1},
  isbn = {978-3-030-11916-4 978-3-030-11917-1},
  language = {en}
}

@incollection{nochetto2011primer,
  title = {Primer of Adaptive Finite Element Methods},
  author = {Nochetto, Ricardo H and Veeser, Andreas},
  year = {2011}
}

@article{nooruddin2003simplification,
  title = {Simplification and Repair of Polygonal Models Using Volumetric Techniques},
  author = {Nooruddin, Fakir S and Turk, Greg},
  year = {2003},
  volume = {9},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  number = {2}
}

@article{Novak:2018Monte,
  title = {Monte {{Carlo Methods}} for {{Volumetric Light Transport Simulation}}},
  author = {Nov{\'a}k, Jan and Georgiev, Iliyan and Hanika, Johannes and Jarosz, Wojciech},
  year = {2018},
  volume = {37},
  doi = {10.1111/cgf.13383},
  abstract = {The wide adoption of path-tracing algorithms in high-end realistic rendering has stimulated many diverse research initiatives. In this paper we present a coherent survey of methods that utilize Monte Carlo integration for estimating light transport in scenes containing participating media. Our work complements the volume-rendering state-of-the-art report by Cerezo et al. [CPP*05]; we review publications accumulated since its publication over a decade ago, and include earlier methods that are key for building light transport paths in a stochastic manner. We begin by describing analog and non-analog procedures for free-path sampling and discuss various expected-value, collision, and track-length estimators for computing transmittance. We then review the various rendering algorithms that employ these as building blocks for path sampling. Special attention is devoted to null-collision methods that utilize fictitious matter to handle spatially varying densities; we import two ``next-flight'' estimators originally developed in nuclear sciences. Whenever possible, we draw connections between image-synthesis techniques and methods from particle physics and neutron transport to provide the reader with a broader context.},
  journal = {Computer Graphics Forum},
  number = {2}
}

@article{oates2009quantitative,
  title = {Quantitative Approaches in Developmental Biology},
  author = {Oates, Andrew C and Gorfinkiel, Nicole and {Gonzalez-Gaitan}, Marcos and Heisenberg, Carl-Philipp},
  year = {2009},
  volume = {10},
  journal = {Nature reviews. Genetics},
  number = {8}
}

@article{OConnor:2018339,
  title = {Sampling Molecular Conformations and Dynamics in a Multiuser Virtual Reality Framework},
  author = {O'Connor, Michael and Deeks, Helen M. and Dawn, Edward and Metatla, Oussama and Roudaut, Anne and Sutton, Matthew and Thomas, Lisa May and Glowacki, Becca Rose and Sage, Rebecca and Tew, Philip and Wonnacott, Mark and Bates, Phil and Mulholland, Adrian J. and Glowacki, David R.},
  year = {2018},
  volume = {4},
  doi = {10.1126/sciadv.aat2731},
  abstract = {We describe a framework for interactive molecular dynamics in a multiuser virtual reality (VR) environment, combining rigorous cloud-mounted atomistic physics simulations with commodity VR hardware, which we have made accessible to readers (see isci.itch.io/nsb-imd). It allows users to visualize and sample, with atomic-level precision, the structures and dynamics of complex molecular structures ``on the fly'' and to interact with other users in the same virtual environment. A series of controlled studies, in which participants were tasked with a range of molecular manipulation goals (threading methane through a nanotube, changing helical screw sense, and tying a protein knot), quantitatively demonstrate that users within the interactive VR environment can complete sophisticated molecular modeling tasks more quickly than they can using conventional interfaces, especially for molecular pathways and structural transitions whose conformational choreographies are intrinsically three-dimensional. This framework should accelerate progress in nanoscale molecular engineering areas including conformational mapping, drug development, synthetic biology, and catalyst design. More broadly, our findings highlight the potential of VR in scientific domains where three-dimensional dynamics matter, spanning research and education.},
  journal = {Science Advances},
  number = {6}
}

@article{okikiolu1992characterization,
  title = {Characterization of Subsets of Rectifiable Curves in {{Rn}}},
  author = {Okikiolu, Kate},
  year = {1992},
  volume = {2},
  journal = {Journal of the London Mathematical Society},
  number = {2}
}

@article{olivier2010cell,
  title = {Cell Lineage Reconstruction of Early Zebrafish Embryos Using Label-Free Nonlinear Microscopy},
  author = {Olivier, Nicolas and {Luengo-Oroz}, Miguel A and Duloquin, Louise and Faure, Emmanuel and Savy, Thierry and Veilleux, Isra{\"e}l and Solinas, Xavier and D{\'e}barre, Delphine and Bourgine, Paul and Santos, Andr{\'e}s and {o}, t},
  year = {2010},
  volume = {329},
  journal = {Science},
  number = {5994}
}

@article{Olsson:2012vr,
  title = {Clustered Deferred and Forward Shading},
  author = {Olsson, O and Billeter, M and Assarsson, U},
  year = {2012},
  abstract = {Abstract This paper presents and investigates Clustered Shading for deferred and forward rendering. In Clustered Shading, view samples with similar properties (eg 3D-position and/or normal) are grouped into clusters. This is comparable to tiled shading, where view ...},
  journal = {Proceedings of the Fourth ACM \ldots}
}

@article{Olszak:2011125,
  title = {Heterochromatin Boundaries Are Hotspots for de Novo Kinetochore Formation},
  author = {Olszak, Agata M. and van Essen, Dominic and Pereira, Ant{\'o}nio J. and Diehl, Sarah and Manke, Thomas and Maiato, Helder and Saccani, Simona and Heun, Patrick},
  year = {2011},
  volume = {13},
  doi = {10.1038/ncb2272},
  abstract = {The centromere-specific histone H3 variant CENH3 (also known as CENP-A) is considered to be an epigenetic mark for establishment and propagation of centromere identity. Pulse induction of CENH3 (Drosophila CID) in Schneider S2 cells leads to its incorporation into non-centromeric regions and generates CID islands that resist clearing from chromosome arms for multiple cell generations. We demonstrate that CID islands represent functional ectopic kinetochores, which are non-randomly distributed on the chromosome and show a preferential localization near telomeres and pericentric heterochromatin in transcriptionally silent, intergenic chromatin domains. Although overexpression of heterochromatin protein 1 (HP1) or increasing histone acetylation interferes with CID island formation on a global scale, induction of a locally defined region of synthetic heterochromatin by targeting HP1\textendash LacI fusions to stably integrated Lac operator arrays produces a proximal hotspot for CID deposition. These data indicate that the characteristics of regions bordering heterochromatin promote de novo kinetochore assembly and thereby contribute to centromere identity.},
  journal = {Nature Cell Biology},
  number = {7}
}

@article{openmp4,
  title = {({{No}} Title},
  author = {Board, OpenMP Architecture Review},
  year = {2013},
  journal = {openmp.org}
}

@phdthesis{Oswald:2010pr,
  title = {A Precise and Rapid {{UV}} Laser Ablation System for Cell Biology},
  author = {Oswald, Felix},
  year = {2010},
  school = {Technische Universit\"at Dresden}
}

@article{Papadopoulos:2015bw,
  title = {The {{Reality Deck}}--an Immersive Gigapixel Display.},
  author = {Papadopoulos, Charilaos and Petkov, Kaloian and Kaufman, Arie E and Mueller, Klaus},
  year = {2015},
  volume = {35},
  doi = {10.1109/mcg.2014.80},
  journal = {IEEE computer graphics and applications},
  number = {1}
}

@article{Parker:2013hxa,
  title = {{{GPU}} Ray Tracing},
  author = {Parker, Steven G and Humphreys, Greg and McGuire, Morgan and Stich, Martin and Friedrich, Heiko and Luebke, David and Morley, Keith and Bigler, James and Hoberock, Jared and McAllister, David and Robison, Austin and Dietrich, Andreas},
  year = {2013},
  volume = {56},
  doi = {10.1145/2447976.2447997},
  journal = {Communications of the ACM},
  number = {5}
}

@article{Patney:2016b4e,
  title = {Towards Foveated Rendering for Gaze-Tracked Virtual Reality},
  author = {Patney, Anjul and Salvi, Marco and Kim, Joohwan and Kaplanyan, Anton and Wyman, Chris and Benty, Nir and Luebke, David and Lefohn, Aaron},
  year = {2016},
  volume = {35},
  doi = {10.1145/2980179.2980246},
  abstract = {Foveated rendering synthesizes images with progressively less detail outside the eye fixation region, potentially unlocking significant speedups for wide field-of-view displays, such as head mounted displays, where target framerate and resolution is increasing faster than the performance of traditional real-time renderers. To study and improve potential gains, we designed a foveated rendering user study to evaluate the perceptual abilities of human peripheral vision when viewing today's displays. We determined that filtering peripheral regions reduces contrast, inducing a sense of tunnel vision. When applying a postprocess contrast enhancement, subjects tolerated up to 2\texttimes{} larger blur radius before detecting differences from a non-foveated ground truth. After verifying these insights on both desktop and head mounted displays augmented with high-speed gaze-tracking, we designed a perceptual target image to strive for when engineering a production foveated renderer. Given our perceptual target, we designed a practical foveated rendering system that reduces number of shades by up to 70\% and allows coarsened shading up to 30\textdegree{} closer to the fovea than Guenter et al. [2012] without introducing perceivable aliasing or blur. We filter both pre- and post-shading to address aliasing from undersampling in the periphery, introduce a novel multiresolution- and saccade-aware temporal antialising algorithm, and use contrast enhancement to help recover peripheral details that are resolvable by our eye but degraded by filtering. We validate our system by performing another user study. Frequency analysis shows our system closely matches our perceptual target. Measurements of temporal stability show we obtain quality similar to temporally filtered non-foveated renderings.},
  journal = {ACM Transactions on Graphics (TOG)},
  number = {6}
}

@article{paul2013coupling,
  title = {Coupling Image Restoration and Segmentation: A Generalized Linear Model/{{Bregman}} Perspective},
  author = {Paul, Gr{\'e}gory and Cardinale, Janick and Sbalzarini, Ivo F},
  year = {2013},
  volume = {104},
  journal = {International Journal of Computer Vision},
  number = {1}
}

@article{Peng:2014bu,
  title = {Virtual Finger Boosts Three-Dimensional Imaging and Microsurgery as Well as Terabyte Volume Image Visualization and Analysis.},
  author = {Peng, Hanchuan and Tang, Jianyong and Xiao, Hang and Bria, Alessandro and Zhou, Jianlong and Butler, Victoria and Zhou, Zhi and {Gonzalez-Bellido}, Paloma T and Oh, Seung W and Chen, Jichao and Mitra, Ananya and Tsien, Richard W and Zeng, Hongkui and Ascoli, Giorgio A and Iannello, Giulio and Hawrylycz, Michael and Myers, Eugene and Long, Fuhui},
  year = {2014},
  volume = {5},
  doi = {10.1038/ncomms5342},
  abstract = {Three-dimensional (3D) bioimaging, visualization and data analysis are in strong need of powerful 3D exploration techniques. We develop virtual finger (VF) to generate 3D curves, points and regions-of-interest in the 3D space of a volumetric image with a single finger operation, such as a computer mouse stroke, or click or zoom from the 2D-projection plane of an image as visualized with a computer. VF provides efficient methods for acquisition, visualization and analysis of 3D images for roundworm, fruitfly, dragonfly, mouse, rat and human. Specifically, VF enables instant 3D optical zoom-in imaging, 3D free-form optical microsurgery, and 3D visualization and annotation of terabytes of whole-brain image volumes. VF also leads to orders of magnitude better efficiency of automated 3D reconstruction of neurons and similar biostructures over our previous systems. We use VF to generate from images of 1,107 Drosophila GAL4 lines a projectome of a Drosophila brain.},
  journal = {Nature Communications}
}

@article{peng2010v3d,
  title = {{{V3D}} Enables Real-Time {{3D}} Visualization and Quantitative Analysis of Large-Scale Biological Image Data Sets},
  author = {Peng, Hanchuan and Ruan, Zongcai and Long, Fuhui and Simpson, Julie H and Myers, Eugene W},
  year = {2010},
  volume = {28},
  journal = {Nature Biotechnology},
  number = {4}
}

@article{peng2014extensible,
  title = {Extensible Visualization and Analysis for Multidimensional Images Using {{Vaa3D}}},
  author = {Peng, Hanchuan and Bria, Alessandro and Zhou, Zhi and Iannello, Giulio and Long, Fuhui},
  year = {2014},
  volume = {9},
  journal = {Nature Protocols},
  number = {1}
}

@article{pereyra1974mesh,
  title = {Mesh Selection for Discrete Solution of Boundary Problems in Ordinary Differential Equations},
  author = {Pereyra, V and Sewell, E G},
  year = {1974},
  volume = {23},
  journal = {Numerische Mathematik},
  number = {3}
}

@article{peyre2011review,
  title = {A Review of Adaptive Image Representations},
  author = {Peyr{\'e}, Gabriel},
  year = {2011},
  volume = {5},
  journal = {IEEE Journal of Selected Topics in Signal Processing},
  number = {5}
}

@inproceedings{Pfeuffer:2017jk,
  title = {Gaze + Pinch Interaction in Virtual Reality},
  booktitle = {Proceedings of the 5th {{Symposium}} on {{Spatial User Interaction}}  - {{SUI}} '17},
  author = {Pfeuffer, Ken and Mayer, Benedikt and Mardanbegi, Diako and Gellersen, Hans},
  year = {2017},
  pages = {99--108},
  publisher = {{ACM Press}},
  address = {{Brighton, United Kingdom}},
  doi = {10.1145/3131277.3132180},
  isbn = {978-1-4503-5486-8},
  language = {en}
}

@article{pidhorskyiSyGlassInteractiveExploration2018,
  title = {{{syGlass}}: {{Interactive Exploration}} of {{Multidimensional Images Using Virtual Reality Head}}-Mounted {{Displays}}},
  author = {Pidhorskyi, Stanislav and Morehead, Michael and Jones, Quinn and Spirou, George and Doretto, Gianfranco},
  year = {2018},
  abstract = {The quest for deeper understanding of biological systems has driven the acquisition of increasingly larger multidimensional image datasets. Inspecting and manipulating data of this complexity is very challenging in traditional visualization systems. We developed syGlass, a software package capable of visualizing large scale volumetric data with inexpensive virtual reality head-mounted display technology. This allows leveraging stereoscopic vision to significantly improve perception of complex 3D structures, and provides immersive interaction with data directly in 3D. We accomplished this by developing highly optimized data flow and volume rendering pipelines, tested on datasets up to 16TB in size, as well as tools available in a virtual reality GUI to support advanced data exploration, annotation, and cataloguing.}
}

@article{Pietzsch:2012img,
  title = {{{ImgLib2}}\textemdash Generic Image Processing in {{Java}}},
  author = {Pietzsch, Tobias and Preibisch, Stephan and Toman{\v c}{\'a}k, Pavel and Saalfeld, Stephan},
  year = {2012},
  volume = {28},
  doi = {10.1093/bioinformatics/bts543},
  abstract = {Summary: ImgLib2 is an open-source Java library for n-dimensional data representation and manipulation with focus on image processing. It aims at minimizing code duplication by cleanly separating pixel-algebra, data access and data representation in memory. Algorithms can be implemented for classes of pixel types and generic access patterns by which they become independent of the specific dimensionality, pixel type and data representation. ImgLib2 illustrates that an elegant high-level programming interface can be achieved without sacrificing performance. It provides efficient implementations of common data types, storage layouts and algorithms. It is the data model underlying ImageJ2, the KNIME Image Processing toolbox and an increasing number of Fiji-Plugins. Availability: ImgLib2 is licensed under BSD. Documentation and source code are available at http://imglib2.net and in a public repository at https://github.com/imagej/imglib. Supplementary Information:Supplementary data are available at Bioinformatics Online. Contact: saalfeld@mpi-cbg.de},
  journal = {Bioinformatics},
  number = {22}
}

@article{Pietzsch:2015hl,
  title = {{{BigDataViewer}}: Visualization and Processing for Large Image Data Sets},
  author = {Pietzsch, Tobias and Saalfeld, Stephan and Preibisch, Stephan and Tomancak, Pavel},
  year = {2015},
  volume = {12},
  doi = {10.1038/nmeth.3392},
  abstract = {Nature Methods 12, 481 (2015). doi:10.1038/nmeth.3392},
  journal = {Nature Publishing Group},
  number = {6}
}

@article{pietzsch2015bigdataviewer,
  title = {{{BigDataViewer}}: Visualization and Processing for Large Image Data Sets},
  author = {Pietzsch, Tobias and Saalfeld, Stephan and Preibisch, Stephan and Tomancak, Pavel},
  year = {2015},
  volume = {12},
  journal = {Nature Methods},
  number = {6}
}

@article{Pitrone:2013ki,
  title = {{{OpenSPIM}}: An Open-Access Light-Sheet Microscopy Platform},
  author = {Pitrone, Peter G and Schindelin, Johannes and Stuyvenberg, Luke and Preibisch, Stephan and Weber, Michael and Eliceiri, Kevin W and Huisken, Jan and Tomancak, Pavel},
  year = {2013},
  volume = {10},
  doi = {10.1038/nmeth.2507},
  journal = {Nature Methods},
  number = {7}
}

@inproceedings{piumsomboon2017,
  title = {Exploring Natural Eye-Gaze-Based Interaction for Immersive Virtual Reality},
  booktitle = {2017 {{IEEE Symposium}} on {{3D User Interfaces}} ({{3DUI}})},
  author = {Piumsomboon, Thammathip and Lee, Gun and Lindeman, Robert W. and Billinghurst, Mark},
  year = {2017},
  pages = {36--39},
  publisher = {{IEEE}},
  address = {{Los Angeles, CA, USA}},
  doi = {10.1109/3DUI.2017.7893315},
  isbn = {978-1-5090-6716-9}
}

@article{plonka2009easy,
  title = {The Easy Path Wavelet Transform: {{A}} New Adaptive Wavelet Transform for Sparse Representation of Two-Dimensional Data},
  author = {Plonka, Gerlind},
  year = {2009},
  volume = {7},
  journal = {Multiscale Modeling and Simulation},
  number = {3}
}

@article{Pohl:2016fy,
  title = {Concept for Using Eye Tracking in a Head-Mounted Display to Adapt Rendering to the User's Current Visual Field},
  author = {Pohl, Daniel and Zhang, Xucong and Bulling, Andreas and Grau, Oliver},
  year = {2016},
  doi = {10.1145/2993369.2996300},
  journal = {the 22nd ACM Conference}
}

@article{Poletti:201727a,
  title = {Selective Attention within the Foveola},
  author = {Poletti, Martina and Rucci, Michele and Carrasco, Marisa},
  year = {2017},
  volume = {20},
  doi = {10.1038/nn.4622},
  abstract = {Efficient control of attentional resources and high-acuity vision are both fundamental for survival. Shifts in visual attention are known to covertly enhance processing at locations away from the center of gaze, where visual resolution is low. It is unknown, however, whether selective spatial attention operates where the observer is already looking\textemdash that is, within the high-acuity foveola, the small yet disproportionally important rod-free region of the retina. Using new methods for precisely controlling retinal stimulation, here we show that covert attention flexibly improves and speeds up both detection and discrimination at loci only a fraction of a degree apart within the foveola. These findings reveal a surprisingly precise control of attention and its involvement in fine spatial vision. They show that the commonly studied covert shifts of attention away from the fovea are the expression of a global mechanism that exerts its action across the entire visual field.},
  journal = {Nature Neuroscience},
  number = {10}
}

@article{power2017guide,
  title = {A Guide to Light-Sheet Fluorescence Microscopy for Multiscale Imaging},
  author = {Power, Rory M and Huisken, Jan},
  year = {2017},
  volume = {14},
  journal = {Nature Methods},
  number = {4}
}

@article{prasher1992primary,
  title = {Primary Structure of the {{Aequorea}} Victoria Green-Fluorescent Protein},
  author = {Prasher, Douglas C and Eckenrode, Virginia K and Ward, William W and Prendergast, Frank G and Cormier, Milton J},
  year = {1992},
  volume = {111},
  journal = {Gene},
  number = {2}
}

@article{preibisch2008mosaicing,
  title = {Mosaicing of Single Plane Illumination Microscopy Images Using Groupwise Registration and Fast Content-Based Image Fusion},
  author = {Preibisch, Stephan and Rohlfing, Torsten and Hasak, Michael P and Tomancak, Pavel},
  year = {2008},
  volume = {6914},
  journal = {Medical Imaging 2008: Image Processing},
  number = {1}
}

@article{preibisch2008towards,
  title = {Towards Digital Representation of {{Drosophila}} Embryogenesis},
  author = {Preibisch, Stephan and Ejsmont, Radoslaw and Rohlfing, Torsten and Tomancak, Pavel},
  year = {2008},
  journal = {Biomedical Imaging: From Nano to Macro, 2008. ISBI 2008. 5th IEEE International Symposium on}
}

@article{preibisch2009bead,
  title = {Bead-Based Mosaicing of Single Plane Illumination Microscopy Images Using Geometric Local Descriptor Matching},
  author = {Preibisch, Stephan and Saalfeld, Stephan and Rohlfing, Torsten and Tomancak, Pavel},
  year = {2009},
  volume = {7259},
  journal = {Proc. of SPIE Vol}
}

@article{preibisch2010software,
  title = {Software for Bead-Based Registration of Selective Plane Illumination Microscopy Data},
  author = {Preibisch, Stephan and Saalfeld, Stephan and Schindelin, Johannes and Tomancak, Pavel},
  year = {2010},
  volume = {7},
  journal = {Nature Methods},
  number = {6}
}

@article{preibisch2014efficient,
  title = {Efficient {{Bayesian}}-Based Multiview Deconvolution},
  author = {Preibisch, Stephan and Amat, Fernando and Stamataki, Evangelia and Sarov, Mihail and Singer, Robert H and Myers, Eugene and Tomancak, Pavel},
  year = {2014},
  volume = {11},
  doi = {10.1038/nmeth.2929},
  journal = {Nature Methods},
  number = {6}
}

@incollection{Prsa:2016Cerebellum,
  title = {Cerebellum: {{Eye Movements}}},
  shorttitle = {Cerebellum},
  booktitle = {Neuroscience in the 21st {{Century}}},
  author = {Prsa, Mario and Thier, Peter},
  editor = {Pfaff, Donald W. and Volkow, Nora D.},
  year = {2016},
  pages = {1297--1314},
  publisher = {{Springer New York}},
  address = {{New York, NY}},
  doi = {10.1007/978-1-4939-3474-4_39},
  isbn = {978-1-4939-3473-7 978-1-4939-3474-4},
  language = {en}
}

@article{radha1991binary,
  title = {Binary Space Partitioning Tree Representation of Images},
  author = {Radha, Hayder and Leonardi, Riccardo and Vetterli, Martin and Naylor, Bruce},
  year = {1991},
  volume = {2},
  journal = {Journal of Visual Communication and Image Representation},
  number = {3}
}

@article{rafael2002digital,
  title = {Digital Image Processing},
  author = {Gonzalez, C Rafael and Woods, Richard},
  year = {2002},
  journal = {Pearson Education}
}

@book{Raskin:2000thi,
  title = {The {{Humane Interface}}},
  author = {Raskin, Jef},
  year = {2000},
  isbn = {0-201-37937-6}
}

@article{Rayner:Eye,
  title = {Eye {{Movements}} in {{Reading}} and {{Information Processing}}: 20 {{Years}} of {{Research}}},
  author = {Rayner, Keith},
  pages = {51},
  journal = {EYE MOVEMENTS IN READING},
  language = {en}
}

@article{reboux2012self,
  title = {A Self-Organizing {{Lagrangian}} Particle Method for Adaptive-Resolution Advection--Diffusion Simulations},
  author = {Reboux, Sylvain and Schrader, Birte and Sbalzarini, Ivo F},
  year = {2012},
  volume = {231},
  journal = {Journal of Computational Physics},
  number = {9}
}

@article{regele2009adaptive,
  title = {An Adaptive Wavelet-Collocation Method for Shock Computations},
  author = {Regele, J D and Vasilyev, O V},
  year = {2009},
  volume = {23},
  journal = {International Journal of Computational Fluid Dynamics},
  number = {7}
}

@incollection{Reichenbach:2016Retina,
  title = {Retina: {{Neuroanatomy}} and {{Physiology}}},
  shorttitle = {Retina},
  booktitle = {Neuroscience in the 21st {{Century}}},
  author = {Reichenbach, Andreas and Bringmann, Andreas},
  editor = {Pfaff, Donald W. and Volkow, Nora D.},
  year = {2016},
  pages = {673--745},
  publisher = {{Springer New York}},
  address = {{New York, NY}},
  doi = {10.1007/978-1-4939-3474-4_22},
  abstract = {The sensory retina of vertebrates, a highly specialized extension of the brain, is a thin (\textasciitilde 0.25 mm thick in the human eye), multilayered, photosensitive tissue coating the inner back of the eyeball (Fig. 1). The retina is responsible for (1) photoreception and transduction of light energy into neuronal activity and (2) initial stages of visual processing and integration according to the environmental light conditions. The visual information is then transferred through the optic nerve to the brain.},
  isbn = {978-1-4939-3473-7 978-1-4939-3474-4},
  language = {en}
}

@article{reinagel1999natural,
  title = {Natural Scene Statistics at the Centre of Gaze},
  author = {Reinagel, Pamela and Zador, Anthony M},
  year = {1999},
  volume = {10},
  journal = {Network: Computation in Neural Systems},
  number = {4}
}

@article{reinaGPUbasedHyperstreamlinesDiffusion2006,
  title = {{{GPU}}-Based {{Hyperstreamlines}} for {{Diffusion Tensor Imaging}}},
  author = {Reina, Guido and Bidmon, Katrin and Enders, F. and Hastreiter, Peter and Ertl, Thomas},
  year = {2006},
  journal = {Eurographics/IEEE-VGTC Symposium on Visualization}
}

@inproceedings{Reipschlger:2018945,
  title = {{{DebugAR}}: {{Mixed Dimensional Displays}} for {{Immersive Debugging}} of {{Distributed Systems}}},
  shorttitle = {{{DebugAR}}},
  booktitle = {Extended {{Abstracts}} of the 2018 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}  - {{CHI}} '18},
  author = {Reipschl{\"a}ger, Patrick and Ozkan, Burcu Kulahcioglu and Mathur, Aman Shankar and Gumhold, Stefan and Majumdar, Rupak and Dachselt, Raimund},
  year = {2018},
  pages = {1--6},
  publisher = {{ACM Press}},
  address = {{Montreal QC, Canada}},
  doi = {10.1145/3170427.3188679},
  isbn = {978-1-4503-5621-3},
  language = {en}
}

@article{Reynaud:2015dx,
  title = {Guide to Light-Sheet Microscopy for Adventurous Biologists.},
  author = {Reynaud, Emmanuel G and Peychl, Jan and Huisken, Jan and Tomancak, Pavel},
  year = {2014},
  volume = {12},
  doi = {10.1038/nmeth.3222},
  journal = {Nature Methods},
  number = {1}
}

@article{reynaud2015guide,
  title = {Guide to Light-Sheet Microscopy for Adventurous Biologists},
  author = {Reynaud, Emmanuel G and Peychl, Jan and Huisken, Jan and Tomancak, Pavel},
  year = {2015},
  volume = {12},
  journal = {Nature Methods},
  number = {1}
}

@article{reynolds1987,
  title = {Flocks, Herds and Schools: {{A}} Distributed Behavioral Model},
  shorttitle = {Flocks, Herds and Schools},
  author = {Reynolds, Craig W.},
  year = {1987},
  month = aug,
  volume = {21},
  pages = {25--34},
  issn = {00978930},
  doi = {10.1145/37402.37406},
  journal = {ACM SIGGRAPH Computer Graphics},
  language = {en},
  number = {4}
}

@article{Rice:2014341,
  title = {Touch-Level Model ({{TLM}}): Evolving {{KLM}}-{{GOMS}} for Touchscreen and Mobile Devices},
  author = {Rice, Andrew D. and Lartigue, Jonathan W.},
  year = {2014},
  abstract = {In the early days of personal computing, a model called "Goals, Operators, Methods, and Selection Rules" (GOMS) provided a method with which to quantify user interaction with a system. [2] Soon after, the Keystroke Level Model (KLM) allowed decomposition of complex tasks into atomic, benchmarked 'operators' that could generalize and estimate interactions on any keyboard interface. However, this the model is dated and unsuitable for today's modern devices. These touchscreen interfaces are now pervasive [4], but the HCI implications of this shift are not fully researched; an imperative exists for research in human-computer interaction to study these interfaces and the interactions of the people using them. [3] In this paper, we introduce new operators and other modifications to KLM-GOMS to accommodate modern touchscreen interfaces. We call these additions, together with updates to the existing KLM operators, the Touch Level Model (TLM). We propose that this model can be employed to model human task performance on a constrained-input touchscreen device and, with proper benchmarking, accurately predict actual user performance. Our goal is to provide a means for quantitative analysis of touchscreen interfaces for HCI research and to enable description of interactions with such interfaces in terms of these operators, thus predicting user performance with less need to create prototypes or perform user studies.}
}

@article{richardson1972bayesian,
  title = {Bayesian-Based Iterative Method of Image Restoration},
  author = {Richardson, William Hadley},
  year = {1972},
  volume = {62},
  journal = {JOsA},
  number = {1}
}

@article{Robinson:1963wf,
  title = {A {{Method}} of {{Measuring Eye Movemnent Using}} a {{Scieral Search Coil}} in a {{Magnetic Field}}},
  author = {Robinson, David A.},
  year = {1963},
  volume = {10},
  doi = {10.1109/tbmel.1963.4322822},
  abstract = {With the subject exposed to an alternating magnetic field, eye position may be accurately recorded from the voltage generated in a coil of wire embedded in a scleral contact lens worn by the subject. Using two magnetic fields in quadrature phase and two coils on the lens, one may measure horizontal, vertical and torsional eye movements simultaneously. The instrument described has an accuracy and linearity of about 2 per cent of full scale, a resolution of 15 seconds of arc and a bandwidth of 1000 cyles per second.},
  journal = {IEEE Transactions on Bio-medical Electronics},
  number = {4}
}

@article{Rompolas:2012e70,
  title = {Live Imaging of Stem Cell and Progeny Behaviour in Physiological Hair-Follicle Regeneration},
  author = {Rompolas, Panteleimon and Deschene, Elizabeth R. and Zito, Giovanni and Gonzalez, David G. and Saotome, Ichiko and Haberman, Ann M. and Greco, Valentina},
  year = {2012},
  volume = {487},
  doi = {10.1038/nature11218},
  abstract = {Tissue development and regeneration depend on cell\textendash cell interactions and signals that target stem cells and their immediate progeny1. However, the cellular behaviours that lead to a properly regenerated tissue are not well understood. Using a new, non-invasive, intravital two-photon imaging approach we study physiological hair-follicle regeneration over time in live mice. By these means we have monitored the behaviour of epithelial stem cells and their progeny2,3,4 during physiological hair regeneration and addressed how the mesenchyme5 influences their behaviour. Consistent with earlier studies6, stem cells are quiescent during the initial stages of hair regeneration, whereas the progeny are more actively dividing. Moreover, stem cell progeny divisions are spatially organized within follicles. In addition to cell divisions, coordinated cell movements of the progeny allow the rapid expansion of the hair follicle. Finally, we show the requirement of the mesenchyme for hair regeneration through targeted cell ablation and long-term tracking of live hair follicles. Thus, we have established an in vivo approach that has led to the direct observation of cellular mechanisms of growth regulation within the hair follicle and that has enabled us to precisely investigate functional requirements of hair-follicle components during the process of physiological regeneration.},
  journal = {Nature},
  number = {7408}
}

@article{rossinelli2015mrag,
  title = {{{MRAG}}-{{I2D}}: Multi-Resolution Adapted Grids for Remeshed Vortex Methods on Multicore Architectures},
  author = {Rossinelli, Diego and Hejazialhosseini, Babak and van Rees, Wim and Gazzola, Mattia and Bergdorf, Michael and Koumoutsakos, Petros},
  year = {2015},
  volume = {288},
  journal = {Journal of Computational Physics}
}

@article{Royer:2015tg,
  title = {{{ClearVolume}}: Open-Source Live {{3D}} Visualization for Light-Sheet Microscopy},
  author = {Royer, Lo{\"i}c A and Weigert, Martin and G{\"u}nther, Ulrik and Maghelli, Nicola and Jug, Florian and Sbalzarini, Ivo F and Myers, Eugene W},
  year = {2015},
  volume = {12},
  doi = {10.1038/nmeth.3372},
  copyright = {All rights reserved},
  journal = {Nature Methods},
  number = {6}
}

@article{Royer:2016fh,
  title = {Adaptive Light-Sheet Microscopy for Long-Term, High-Resolution Imaging in Living Organisms.},
  author = {Royer, Lo{\"i}c A and Lemon, William C and Chhetri, Raghav K and Wan, Yinan and Coleman, Michael and Myers, Eugene W and Keller, Philipp J},
  year = {2016},
  volume = {34},
  doi = {10.1038/nbt.3708},
  abstract = {Optimal image quality in light-sheet microscopy requires a perfect overlap between the illuminating light sheet and the focal plane of the detection objective. However, mismatches between the light-sheet and detection planes are common owing to the spatiotemporally varying optical properties of living specimens. Here we present the AutoPilot framework, an automated method for spatiotemporally adaptive imaging that integrates (i) a multi-view light-sheet microscope capable of digitally translating and rotating light-sheet and detection planes in three dimensions and (ii) a computational method that continuously optimizes spatial resolution across the specimen volume in real time. We demonstrate long-term adaptive imaging of entire developing zebrafish (Danio rerio) and Drosophila melanogaster embryos and perform adaptive whole-brain functional imaging in larval zebrafish. Our method improves spatial resolution and signal strength two to five-fold, recovers cellular and sub-cellular structures in many regions that are not resolved by non-adaptive imaging, adapts to spatiotemporal dynamics of genetically encoded fluorescent markers and robustly optimizes imaging performance during large-scale morphogenetic changes in living organisms.},
  journal = {Nature Biotechnology},
  number = {12}
}

@article{royer2015clearvolume,
  title = {{{ClearVolume}}: Open-Source Live {{3D}} Visualization for Light-Sheet Microscopy},
  author = {Royer, Lo{\"i}c A and Weigert, Martin and Guenther, Ulrik and Maghelli, Nicola and Jug, Florian and Sbalzarini, Ivo F and Myers, Eugene W},
  year = {2015},
  volume = {12},
  journal = {Nature Methods},
  number = {6}
}

@article{royer2016adaptive,
  title = {Adaptive Light-Sheet Microscopy for Long-Term, High-Resolution Imaging in Living Organisms},
  author = {Royer, Lo{\"i}c A and Lemon, William C and Chhetri, Raghav K and Wan, Yinan and Coleman, Michael and Myers, Eugene W and Keller, Philipp J},
  year = {2016},
  volume = {34},
  journal = {Nature Biotechnology},
  number = {12}
}

@article{rubio2011wavelet,
  title = {Wavelet-Based Image Fusion in Multi-View Three-Dimensional Microscopy},
  author = {{Rubio-Guivernau}, Jose L and Gurchenkov, Vasily and {Luengo-Oroz}, Miguel A and Duloquin, Louise and Bourgine, Paul and Santos, Andr{\'e}s and Peyri{\'e}ras, Nadine and {Ledesma-Carbayo}, Mar{\'i}a J},
  year = {2011},
  volume = {28},
  journal = {Bioinformatics},
  number = {2}
}

@article{Rucci:20070f2,
  title = {Miniature Eye Movements Enhance Fine Spatial Detail},
  author = {Rucci, Michele and Iovin, Ramon and Poletti, Martina and Santini, Fabrizio},
  year = {2007},
  volume = {447},
  doi = {10.1038/nature05866},
  abstract = {Our eyes are constantly in motion. Even during visual fixation, small eye movements continually jitter the location of gaze1,2,3,4. It is known that visual percepts tend to fade when retinal image motion is eliminated in the laboratory5,6,7,8,9. However, it has long been debated whether, during natural viewing, fixational eye movements have functions in addition to preventing the visual scene from fading10,11,12,13,14,15,16,17. In this study, we analysed the influence in humans of fixational eye movements on the discrimination of gratings masked by noise that has a power spectrum similar to that of natural images. Using a new method of retinal image stabilization18, we selectively eliminated the motion of the retinal image that normally occurs during the intersaccadic intervals of visual fixation. Here we show that fixational eye movements improve discrimination of high spatial frequency stimuli, but not of low spatial frequency stimuli. This improvement originates from the temporal modulations introduced by fixational eye movements in the visual input to the retina, which emphasize the high spatial frequency harmonics of the stimulus. In a natural visual world dominated by low spatial frequencies, fixational eye movements appear to constitute an effective sampling strategy by which the visual system enhances the processing of spatial detail.},
  journal = {Nature},
  number = {7146}
}

@article{ruderman1994statistics,
  title = {Statistics of Natural Images: {{Scaling}} in the Woods},
  author = {Ruderman, Daniel L and Bialek, William},
  year = {1994},
  journal = {Advances in neural information processing systems}
}

@article{Rueden:2017ij2,
  title = {{{ImageJ2}}: {{ImageJ}} for the next Generation of Scientific Image Data},
  author = {Rueden, Curtis T. and Schindelin, Johannes and Hiner, Mark C. and DeZonia, Barry E. and Walter, Alison E. and Arena, Ellen T. and Eliceiri, Kevin W.},
  year = {2017},
  volume = {18},
  doi = {10.1186/s12859-017-1934-z},
  abstract = {ImageJ is an image analysis program extensively used in the biological sciences and beyond. Due to its ease of use, recordable macro language, and extensible plug-in architecture, ImageJ enjoys contributions from non-programmers, amateur programmers, and professional developers alike. Enabling such a diversity of contributors has resulted in a large community that spans the biological and physical sciences. However, a rapidly growing user base, diverging plugin suites, and technical limitations have revealed a clear need for a concerted software engineering effort to support emerging imaging paradigms, to ensure the software's ability to handle the requirements of modern science. We rewrote the entire ImageJ codebase, engineering a redesigned plugin mechanism intended to facilitate extensibility at every level, with the goal of creating a more powerful tool that continues to serve the existing community while addressing a wider range of scientific requirements. This next-generation ImageJ, called ``ImageJ2'' in places where the distinction matters, provides a host of new functionality. It separates concerns, fully decoupling the data model from the user interface. It emphasizes integration with external applications to maximize interoperability. Its robust new plugin framework allows everything from image formats, to scripting languages, to visualization to be extended by the community. The redesigned data model supports arbitrarily large, N-dimensional datasets, which are increasingly common in modern image acquisition. Despite the scope of these changes, backwards compatibility is maintained such that this new functionality can be seamlessly integrated with the classic ImageJ interface, allowing users and developers to migrate to these new methods at their own pace. Scientific imaging benefits from open-source programs that advance new method development and deployment to a diverse audience. ImageJ has continuously evolved with this idea in mind; however, new and emerging scientific requirements have posed corresponding challenges for ImageJ's development. The described improvements provide a framework engineered for flexibility, intended to support these requirements as well as accommodate future needs. Future efforts will focus on implementing new algorithms in this framework and expanding collaborations with other popular scientific software suites.},
  journal = {BMC Bioinformatics},
  number = {1}
}

@article{Russell:2016711,
  title = {{{3D}} Correlative Light and Electron Microscopy of Cultured Cells Using Serial Blockface Scanning Electron Microscopy},
  author = {Russell, Matthew R. G. and Lerner, Thomas R. and Burden, Jemima J. and Nkwe, David O. and {Pelchen-Matthews}, Annegret and Domart, Marie-Charlotte and Durgan, Joanne and Weston, Anne and Jones, Martin L. and Peddie, Christopher J. and Carzaniga, Raffaella and Florey, Oliver and Marsh, Mark and Gutierrez, Maximiliano G. and Collinson, Lucy M.},
  year = {2016},
  volume = {130},
  doi = {10.1242/jcs.188433},
  journal = {J Cell Sci},
  number = {1}
}

@book{saad2003iterative,
  title = {Iterative Methods for Sparse Linear Systems},
  author = {Saad, Yousef},
  year = {2003}
}

@article{Sabella:1984ara,
  title = {A Rendering Algorithm for Visualizing {{3D}} Scalar Fields},
  author = {Sabella, Paolo},
  year = {1988},
  volume = {22},
  doi = {10.1145/378456.378476},
  abstract = {This paper presents a ray tracing algorithm for rendering 3D scalar fields. An illumination model is developed in which the field is characterized as a varying density emittter with a single level of scattering. This model is equivalent to a particle system in which the particles are sufficiently small. Along each ray cast from the eye, the field is expressed as a function of the ray parameter. The algorithm computes properties of the field along the ray such as the attenuated intensity, the peak density, and the center of gravity, etc., These are mapped into HSV color space to produce an image for visualization.Images produced in this manner are perceived as a varying density 'cloud' where color highlights the computed attributes. The application of this technique is demonstrated for visualizing a three dimensional seismic data set.},
  journal = {ACM SIGGRAPH Computer Graphics},
  number = {4}
}

@article{sage2002,
  title = {Local {{Normalization}}},
  author = {Sage, Daniel},
  year = {2002}
}

@article{Saha:2016ca8,
  title = {Determining {{Physical Properties}} of the {{Cell Cortex}}},
  author = {Saha, Arnab and Nishikawa, Masatoshi and Behrndt, Martin and Heisenberg, Carl-Philipp and J{\"u}licher, Frank and Grill, Stephan W.},
  year = {2016},
  volume = {110},
  doi = {10.1016/j.bpj.2016.02.013},
  abstract = {Actin and myosin assemble into a thin layer of a highly dynamic network underneath the membrane of eukaryotic cells. This network generates the forces that drive cell- and tissue-scale morphogenetic processes. The effective material properties of this active network determine large-scale deformations and other morphogenetic events. For example, the characteristic time of stress relaxation (the Maxwell time {$\tau$} M ) in the actomyosin sets the timescale of large-scale deformation of the cortex. Similarly, the characteristic length of stress propagation (the hydrodynamic length {$\lambda$}) sets the length scale of slow deformations, and a large hydrodynamic length is a prerequisite for long-ranged cortical flows. Here we introduce a method to determine physical parameters of the actomyosin cortical layer in~vivo directly from laser ablation experiments. For this we investigate the cortical response to laser ablation in the one-cell-stage Caenorhabditis elegans embryo and in the gastrulating zebrafish embryo. These responses can be interpreted using a coarse-grained physical description of the cortex in terms of a two-dimensional thin film of an active viscoelastic gel. To determine the Maxwell time {$\tau$} M , the hydrodynamic length {$\lambda$}, the ratio of active stress {$\zeta$} {$\Delta$} {$\mu$} , and per-area friction {$\gamma$}, we evaluated the response to laser ablation in two different ways: by quantifying flow and density fields as a function of space and time, and by determining the time evolution of the shape of the ablated region. Importantly, both methods provide best-fit physical parameters that are in close agreement with each other and that are similar to previous estimates in the two systems. Our method provides an accurate and robust means for measuring physical parameters of the actomyosin cortical layer. It can be useful for investigations of actomyosin mechanics at the cellular-scale, but also for providing insights into the active mechanics processes that govern tissue-scale morphogenesis.},
  journal = {Biophysical Journal},
  number = {6}
}

@article{said1996new,
  title = {A New, Fast, and Efficient Image Codec Based on Set Partitioning in Hierarchical Trees},
  author = {Said, Amir and Pearlman, William A},
  year = {1996},
  volume = {6},
  journal = {IEEE Transactions on circuits and systems for video technology},
  number = {3}
}

@book{saint1991elementary,
  title = {Elementary Introduction to the Theory of Pseudodifferential Operators},
  author = {Raymond, Xavier Saint},
  year = {1991}
}

@article{sarkis2009content,
  title = {Content Adaptive Mesh Representation of Images Using Binary Space Partitions},
  author = {Sarkis, Michel and Diepold, Klaus},
  year = {2009},
  volume = {18},
  journal = {IEEE Transactions on Image Processing},
  number = {5}
}

@book{saucez2001adaptive,
  title = {Adaptive Method of Lines},
  author = {Saucez, Ph and Schiesser, W E and {o}, t},
  year = {2001}
}

@article{sbalzarini2006ppm,
  title = {{{PPM}}--{{A}} Highly Efficient Parallel Particle--Mesh Library for the Simulation of Continuum Systems},
  author = {Sbalzarini, Ivo F and Walther, Jens H and Bergdorf, Michael and Hieber, Simone Elke and Kotsalis, Evangelos M and Koumoutsakos, Petros},
  year = {2006},
  volume = {215},
  journal = {Journal of Computational Physics},
  number = {2}
}

@article{sbalzarini2013modeling,
  title = {Modeling and Simulation of Biological Systems from Image Data},
  author = {Sbalzarini, Ivo F},
  year = {2013},
  volume = {35},
  journal = {Bioessays},
  number = {5}
}

@article{Scherf:2015ba,
  title = {The Smart and Gentle Microscope},
  author = {Scherf, Nico and Huisken, Jan},
  year = {2015},
  volume = {33},
  doi = {10.1038/nbt.3310},
  abstract = {Nature Biotechnology 33, 815 (2015). doi:10.1038/nbt.3310},
  journal = {Nature Biotechnology},
  number = {8}
}

@article{scherf2015smart,
  title = {The Smart and Gentle Microscope},
  author = {Scherf, Nico and Huisken, Jan},
  year = {2015},
  volume = {33},
  journal = {Nature Biotechnology},
  number = {8}
}

@article{schindelin2012fiji,
  title = {Fiji: An Open-Source Platform for Biological-Image Analysis},
  author = {Schindelin, Johannes and {Arganda-Carreras}, Ignacio and Frise, Erwin and Kaynig, Verena and Longair, Mark and Pietzsch, Tobias and Preibisch, Stephan and Rueden, Curtis and Saalfeld, Stephan and Schmid, Benjamin and Tinevez, Jean-Yves and White, Daniel James and Hartenstein, Volker and Eliceiri, Kevin and Tomancak, Pavel and Cardona, Albert},
  year = {2012},
  volume = {9},
  doi = {10.1038/nmeth.2019},
  abstract = {Fiji is a distribution of the popular open-source software ImageJ focused on biological-image analysis. Fiji uses modern software engineering practices to combine powerful software libraries with a broad range of scripting languages to enable rapid prototyping of image-processing algorithms. Fiji facilitates the transformation of new algorithms into ImageJ plugins that can be shared with end users through an integrated update system. We propose Fiji as a platform for productive collaboration between computer science and biology research communities.},
  journal = {Nature Methods},
  number = {7}
}

@article{Schmid:2010gm,
  title = {A High-Level {{3D}} Visualization {{API}} for {{Java}} and {{ImageJ}}.},
  author = {Schmid, Benjamin and Schindelin, Johannes and Cardona, Albert and Longair, Mark and Heisenberg, Martin},
  year = {2010},
  volume = {11},
  doi = {10.1186/1471-2105-11-274},
  abstract = {BACKGROUND:Current imaging methods such as Magnetic Resonance Imaging (MRI), Confocal microscopy, Electron Microscopy (EM) or Selective Plane Illumination Microscopy (SPIM) yield three-dimensional (3D) data sets in need of appropriate computational methods for their analysis. The reconstruction, segmentation and registration are best approached from the 3D representation of the data set. RESULTS:Here we present a platform-independent framework based on Java and Java 3D for accelerated rendering of biological images. Our framework is seamlessly integrated into ImageJ, a free image processing package with a vast collection of community-developed biological image analysis tools. Our framework enriches the ImageJ software libraries with methods that greatly reduce the complexity of developing image analysis tools in an interactive 3D visualization environment. In particular, we provide high-level access to volume rendering, volume editing, surface extraction, and image annotation. The ability to rely on a library that removes the low-level details enables concentrating software development efforts on the algorithm implementation parts. CONCLUSIONS:Our framework enables biomedical image software development to be built with 3D visualization capabilities with very little effort. We offer the source code and convenient binary packages along with extensive documentation at http://3dviewer.neurofly.de.},
  journal = {BMC Bioinformatics},
  number = {1}
}

@article{schmid2013high,
  title = {High-Speed Panoramic Light-Sheet Microscopy Reveals Global Endodermal Cell Dynamics},
  author = {Schmid, Benjamin and Shah, Gopi and Scherf, Nico and Weber, Michael and Thierbach, Konstantin and Campos, Citlali P{\'e}rez and Roeder, Ingo and Aanstad, Pia and Huisken, Jan},
  year = {2013},
  month = oct,
  volume = {4},
  pages = {2207},
  issn = {2041-1723},
  doi = {10.1038/ncomms3207},
  journal = {Nature Communications},
  language = {en},
  number = {1}
}

@article{schmid2015real,
  title = {Real-Time Multi-View Deconvolution},
  author = {Schmid, Benjamin and Huisken, Jan},
  year = {2015},
  volume = {31},
  journal = {Bioinformatics},
  number = {20}
}

@article{schmidt2013eureqa,
  title = {Eureqa},
  author = {Schmidt, Michael and Lipson, Hod},
  year = {2013},
  journal = {Nutonian, Somerville, Mass, USA}
}

@article{schmied2015automated,
  title = {An Automated Workflow for Parallel Processing of Large Multiview {{SPIM}} Recordings},
  author = {Schmied, Christopher and Steinbach, Peter and Pietzsch, Tobias and Preibisch, Stephan and Tomancak, Pavel},
  year = {2015},
  volume = {32},
  journal = {Bioinformatics},
  number = {7}
}

@article{Schneider:2012nihi,
  title = {{{NIH Image}} to {{ImageJ}}: 25 Years of Image Analysis},
  author = {Schneider, Caroline A and Rasband, Wayne S and Eliceiri, Kevin W},
  year = {2012},
  volume = {9},
  doi = {10.1038/nmeth.2089},
  abstract = {For the past 25 years NIH Image and ImageJ software have been pioneers as open tools for the analysis of scientific images. We discuss the origins, challenges and solutions of these two programs, and how their history can serve to advise and inform other software projects.},
  journal = {Nature Methods},
  number = {7}
}

@article{schneider2010wavelet,
  title = {Wavelet Methods in Computational Fluid Dynamics},
  author = {Schneider, Kai and Vasilyev, Oleg V},
  year = {2010},
  volume = {42},
  journal = {Annual Review of Fluid Mechanics}
}

@article{schrader2010discretization,
  title = {Discretization Correction of General Integral {{PSE Operators}} for Particle Methods},
  author = {Schrader, Birte and Reboux, Sylvain and Sbalzarini, Ivo F},
  year = {2010},
  volume = {229},
  journal = {Journal of Computational Physics},
  number = {11}
}

@article{shell2003,
  title = {Interacting with Groups of Computers},
  author = {Shell, Jeffrey S. and Selker, Ted and Vertegaal, Roel},
  year = {2003},
  volume = {46},
  doi = {10.1145/636772.636796},
  abstract = {AUIs recognize human attention in order to respect and react to how users distribute their attention in technology-laden environments.},
  journal = {Communications of the ACM},
  number = {3}
}

@article{shilkrotAugmentedAirbrushComputer2015,
  title = {Augmented {{Airbrush}} for {{Computer Aided Painting}} ({{CAP}})},
  author = {Shilkrot, Roy and Maes, Pattie and Paradiso, Joseph A. and Zoran, Amit},
  year = {2015},
  volume = {34},
  doi = {10.1145/2699649},
  abstract = {We present an augmented airbrush that allows novices to experience the art of spray painting. Inspired by the thriving field of smart tools, our handheld device uses 6DOF tracking, augmentation of the airbrush trigger, and a specialized algorithm to restrict the application of paint to a preselected reference image. Our device acts both as a physical spraying device and as an intelligent assistive tool, providing simultaneous manual and computerized control. Unlike prior art, here the virtual simulation guides the physical rendering (inverse rendering), allowing for a new spray painting experience with singular physical results. We present our novel hardware design, control software, and a user study that verifies our research objectives.},
  journal = {ACM Transactions on Graphics (TOG)},
  number = {2}
}

@inproceedings{singh2018,
  title = {Physiologically {{Attentive User Interface}} for {{Robot Teleoperation}} - {{Real Time Emotional State Estimation}} and {{Interface Modification}} Using {{Physiology}}, {{Facial Expressions}} and {{Eye Movements}}:},
  shorttitle = {Physiologically {{Attentive User Interface}} for {{Robot Teleoperation}} - {{Real Time Emotional State Estimation}} and {{Interface Modification}} Using {{Physiology}}, {{Facial Expressions}} and {{Eye Movements}}},
  booktitle = {Proceedings of the 11th {{International Joint Conference}} on {{Biomedical Engineering Systems}} and {{Technologies}}},
  author = {Singh, Gaganpreet and i Badia, Sergi Berm{\'u}dez and Ventura, Rodrigo and Silva, Jos{\'e} Lu{\'i}s},
  year = {2018},
  pages = {294--302},
  publisher = {{SCITEPRESS - Science and Technology Publications}},
  address = {{Funchal, Madeira, Portugal}},
  doi = {10.5220/0006733002940302},
  isbn = {978-989-758-279-0}
}

@inproceedings{Singla:2017Measuring,
  title = {Measuring and Comparing {{QoE}} and Simulator Sickness of Omnidirectional Videos in Different Head Mounted Displays},
  booktitle = {2017 {{Ninth International Conference}} on {{Quality}} of {{Multimedia Experience}} ({{QoMEX}})},
  author = {Singla, Ashutosh and Fremerey, Stephan and Robitza, Werner and Raake, Alexander},
  year = {2017},
  month = may,
  pages = {1--6},
  issn = {2472-7814},
  doi = {10.1109/QoMEX.2017.7965658},
  abstract = {In this paper, we evaluated and compared the integral quality of different omnidirectional contents for two head mounted displays (HMDs), namely HTC Vive and Oculus Rift. We also investigated motion sickness and head-movements. To this aim, we categorized omnidirectional contents into three categories based on the degree of motion: high, medium and low motion. For assessing simulator sickness, we used the Simulator Sickness Questionnaire for each of the contents in both HMDs. The viewing direction for subjects while watching the contents were recorded in terms of the three coordinates yaw, roll and pitch. Experimental results show that HTC Vive offers better integral quality compared to Oculus Rift. We also compared simulator sickness scores along with the behavioral data for different contents and HMDs and discussed the results in the paper.},
  keywords = {Analysis of variance,behavioral analysis,Electronic mail,Head,head mounted displays,head-movements,helmet mounted displays,HMDs,HTC Vive,Image coding,image motion analysis,integral quality,Magnetic heads,motion sickness,Oculus Rift,omnidirectional content,omnidirectional videos,QoE,quality of experience,simulator sickness,simulator sickness questionnaire,subjective evaluation,video signal processing,Videos}
}

@article{Sitzmann:to,
  title = {Saliency in {{VR}}: {{How Do People Explore Virtual Environments}}?},
  shorttitle = {Saliency in {{VR}}},
  author = {Sitzmann, Vincent and Serrano, Ana and Pavel, Amy and Agrawala, Maneesh and Gutierrez, Diego and Masia, Belen and Wetzstein, Gordon},
  year = {2018},
  month = apr,
  volume = {24},
  pages = {1633--1642},
  issn = {1077-2626},
  doi = {10.1109/TVCG.2018.2793599},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  number = {4}
}

@article{Slater:2016552,
  title = {Enhancing {{Our Lives}} with {{Immersive Virtual Reality}}},
  author = {Slater, Mel and {Sanchez-Vives}, Maria V.},
  year = {2016},
  volume = {3},
  doi = {10.3389/frobt.2016.00074},
  journal = {Frontiers in Robotics and AI}
}

@article{smirnakis1997adaptation,
  title = {Adaptation of Retinal Processing to Image Contrast and Spatial Scale},
  author = {Smirnakis, Stelios M and Berry, Michael J and Warland, David K and Bialek, William and Meister, Markus},
  year = {1997},
  volume = {386},
  journal = {Nature},
  number = {6620}
}

@article{Smith:2015ld,
  title = {Look, {{Don}}'t {{Touch}}},
  author = {Smith, Melissa A. and Mead, Patrick R. and Squire, Peter N. and Coons, Robert L. and Mead, Allison S.},
  year = {2015},
  volume = {23},
  doi = {10.1177/1064804613516113},
  abstract = {With each new technology interface introduced in the environment, users spend more time switching between and managing these interfaces. When the interfaces involve screen-based displays and controls, eye movements may provide an intuitive and efficient means of switching between screens. This research focused on evaluating manual keyboard and gaze-based control methods for switching control between displays of a simulated surveillance system. Results showed that gaze-based tracking was faster and produced lower subjective workload than using a manual keyboard. Operators' performance was also consistent with Keystroke-Level Model\textendash Goals Operators Methods Selection predictions for each control method. These findings identify gaze-based control as a viable method for switching control between multiple monitors.},
  journal = {Ergonomics in Design: The Quarterly of Human Factors Applications},
  number = {2}
}

@book{Snowden:2012wu,
  title = {Basic Vision: An Introduction to Visual Perception},
  shorttitle = {Basic Vision},
  author = {Snowden, Robert J. and Thompson, Peter and Troscianko, Tom},
  year = {2011},
  edition = {Rev. ed},
  publisher = {{Oxford University Press}},
  address = {{Oxford}},
  annotation = {OCLC: ocn656767547},
  isbn = {978-0-19-957202-1},
  keywords = {Visual perception},
  lccn = {QP475 .S593 2011}
}

@article{Snyers:19950b1,
  title = {Image Processing Optimization by Genetic Algorithm with a New Coding Scheme},
  author = {Snyers, D. and P{\'e}tillot, Y.},
  year = {1995},
  volume = {16},
  doi = {10.1016/0167-8655(95)00044-h},
  abstract = {An original coding scheme is introduced to take advantage of the two-dimensional structural information of images within the genetic algorithm framework. Results are presented showing that this new technique outperforms classical optimization methods for the optimization of 32 \texttimes{} 32 and 128 \texttimes{} 128 holograms.},
  journal = {Pattern Recognition Letters},
  number = {8}
}

@article{Soetedjo:20021f5,
  title = {Evidence {{That}} the {{Superior Colliculus Participates}} in the {{Feedback Control}} of {{Saccadic Eye Movements}}},
  author = {Soetedjo, Robijanto and Kaneko, Chris R S and Fuchs, Albert F},
  year = {2002},
  volume = {87},
  doi = {10.1152/jn.00886.2000},
  journal = {Journal of Neurophysiology},
  number = {2}
}

@article{Song:2016GazeDx,
  title = {{{GazeDx}}: {{Interactive Visual Analytics Framework}} for {{Comparative Gaze Analysis}} with {{Volumetric Medical Images}}},
  author = {Song, Hyunjoo and Lee, Jeongjin and Kim, Tae Jung and Lee, Kyoung Ho and Kim, Bohyoung and Seo, Jinwook},
  year = {2016},
  volume = {23},
  doi = {10.1109/tvcg.2016.2598796},
  abstract = {We present an interactive visual analytics framework, GazeDx (abbr. of GazeDiagnosis), for the comparative analysis of gaze data from multiple readers examining volumetric images while integrating important contextual information with the gaze data. Gaze pattern comparison is essential to understanding how radiologists examine medical images, and to identifying factors influencing the examination. Most prior work depended upon comparisons with manually juxtaposed static images of gaze tracking results. Comparative gaze analysis with volumetric images is more challenging due to the additional cognitive load on 3D perception. A recent study proposed a visualization design based on direct volume rendering (DVR) for visualizing gaze patterns in volumetric images; however, effective and comprehensive gaze pattern comparison is still challenging due to a lack of interactive visualization tools for comparative gaze analysis. We take the challenge with GazeDx while integrating crucial contextual information such as pupil size and windowing into the analysis process for more in-depth and ecologically valid findings. Among the interactive visualization components in GazeDx, a context-embedded interactive scatterplot is especially designed to help users examine abstract gaze data in diverse contexts by embedding medical imaging representations well known to radiologists in it. We present the results from two case studies with two experienced radiologists, where they compared the gaze patterns of 14 radiologists reading two patients' volumetric CT images.},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  number = {1}
}

@article{Speicher:2019What,
  title = {What Is {{Mixed Reality}}?},
  author = {Speicher, Maximilian and Hall, Brian D and Nebeling, Michael},
  year = {2019},
  doi = {10.1145/3290605.3300767}
}

@article{Starruss:2014Morpheus,
  title = {Morpheus: A User-Friendly Modeling Environment for Multiscale and Multicellular Systems Biology},
  shorttitle = {Morpheus},
  author = {Starru{\ss}, J{\"o}rn and {de Back}, Walter and Brusch, Lutz and Deutsch, Andreas},
  year = {2014},
  month = may,
  volume = {30},
  pages = {1331--1332},
  issn = {1460-2059, 1367-4803},
  doi = {10.1093/bioinformatics/btt772},
  journal = {Bioinformatics},
  language = {en},
  number = {9}
}

@article{stegmaier2016real,
  title = {Real-Time Three-Dimensional Cell Segmentation in Large-Scale Microscopy Data of Developing Embryos},
  author = {Stegmaier, Johannes and Amat, Fernando and Lemon, William C and McDole, Katie and Wan, Yinan and Teodoro, George and Mikut, Ralf and Keller, Philipp J},
  year = {2016},
  volume = {36},
  journal = {Developmental cell},
  number = {2}
}

@incollection{Stein:2016Superior,
  title = {The {{Superior Colliculus}} and {{Visual Thalamus}}},
  booktitle = {Neuroscience in the 21st {{Century}}},
  author = {Stein, Barry E. and Stanford, Terrence R. and Godwin, Dwayne W. and McHaffie, John G.},
  editor = {Pfaff, Donald W. and Volkow, Nora D.},
  year = {2016},
  pages = {747--772},
  publisher = {{Springer New York}},
  address = {{New York, NY}},
  doi = {10.1007/978-1-4939-3474-4_23},
  isbn = {978-1-4939-3473-7 978-1-4939-3474-4},
  language = {en}
}

@book{Stellmach:2010co,
  title = {{{3D}} Attentional Maps: Aggregated Gaze Visualizations in Three-Dimensional Virtual Environments},
  author = {Stellmach, Sophie and Nacke, Lennart and Dachselt, Raimund},
  year = {2010},
  abstract = {Abstract Gaze visualizations hold the potential to facilitate usability studies of interactive systems. However, visual gaze analysis in three-dimensional virtual environments still lacks methods and techniques for aggregating attentional representations. We propose three},
  isbn = {978-1-4503-0076-6}
}

@book{Stellmach:2010fo,
  title = {Advanced Gaze Visualizations for Three-Dimensional Virtual Environments},
  author = {Stellmach, Sophie and Nacke, Lennart and Dachselt, Raimund},
  year = {2010},
  abstract = {Abstract Gaze visualizations represent an effective way for gaining fast insights into eye tracking data. Current approaches do not adequately support eye tracking studies for three- dimensional (3D) virtual environments. Hence, we propose a set of advanced gaze},
  isbn = {978-1-60558-994-7}
}

@inproceedings{Stellmach:2012Looka,
  title = {Look \& Touch: Gaze-Supported Target Acquisition},
  shorttitle = {Look \& Touch},
  booktitle = {Proceedings of the 2012 {{ACM}} Annual Conference on {{Human Factors}} in {{Computing Systems}} - {{CHI}} '12},
  author = {Stellmach, Sophie and Dachselt, Raimund},
  year = {2012},
  pages = {2981},
  publisher = {{ACM Press}},
  address = {{Austin, Texas, USA}},
  doi = {10.1145/2207676.2208709},
  abstract = {While eye tracking has a high potential for fast selection tasks, it is often regarded as error-prone and unnatural, especially for gaze-only interaction. To improve on that, we propose gaze-supported interaction as a more natural and effective way combining a user's gaze with touch input from a handheld device. In particular, we contribute a set of novel and practical gaze-supported selection techniques for distant displays. Designed according to the principle gaze suggests, touch confirms they include an enhanced gaze-directed cursor, local zoom lenses and more elaborated techniques utilizing manual fine positioning of the cursor via touch. In a comprehensive user study with 24 participants, we investigated the potential of these techniques for different target sizes and distances. All novel techniques outperformed a simple gaze-directed cursor and showed individual advantages. In particular those techniques using touch for fine cursor adjustments (MAGIC touch) and for cycling through a list of possible close-to-gaze targets (MAGIC tab) demonstrated a high overall performance and usability.},
  isbn = {978-1-4503-1015-4},
  language = {en}
}

@phdthesis{stellmach2013,
  title = {Gaze-Supported {{Multimodal Interaction}}},
  author = {Stellmach, Sophie},
  year = {2013},
  school = {Technische Universit\"at Dresden}
}

@article{stellmachLookTouchGazesupported2012a,
  title = {Look \& Touch: Gaze-Supported Target Acquisition},
  author = {Stellmach, Sophie and Dachselt, Raimund},
  year = {2012},
  abstract = {While eye tracking has a high potential for fast selection tasks, it is often regarded as error-prone and unnatural, especially for gaze-only interaction. To improve on that, we propose gaze-supported interaction as a more natural and effective way combining a user's gaze with touch input from a handheld device. In particular, we contribute a set of novel and practical gaze-supported selection techniques for distant displays. Designed according to the principle gaze suggests, touch confirms they include an enhanced gaze-directed cursor, local zoom lenses and more elaborated techniques utilizing manual fine positioning of the cursor via touch. In a comprehensive user study with 24 participants, we investigated the potential of these techniques for different target sizes and distances. All novel techniques outperformed a simple gaze-directed cursor and showed individual advantages. In particular those techniques using touch for fine cursor adjustments (MAGIC touch) and for cycling through a list of possible close-to-gaze targets (MAGIC tab) demonstrated a high overall performance and usability.}
}

@article{strobl2017improving,
  title = {Improving Your Four-Dimensional Image: Traveling through a Decade of Light-Sheet-Based Fluorescence Microscopy Research},
  author = {Strobl, Frederic and Schmitz, Alexander and Stelzer, Ernst HK},
  year = {2017},
  volume = {12},
  journal = {Nature Protocols},
  number = {6}
}

@article{Sun:2017ia,
  title = {Perceptually-Guided Foveation for Light Field Displays},
  author = {Sun, Qi and Huang, Fu-Chung and Kim, Joohwan and Wei, Li-Yi and Luebke, David and Kaufman, Arie},
  year = {2017},
  volume = {36},
  doi = {10.1145/3130800.3130807},
  journal = {ACM Transactions on Graphics},
  number = {6}
}

@inproceedings{sun2009,
  title = {Dynamic Fringe-Saving {{A}}*},
  booktitle = {Proceedings of {{The}} 8th {{International Conference}} on {{Autonomous Agents}} and {{Multiagent Systems}}},
  author = {Sun, Xiaoxun and Yeoh, William and Koenig, Sven},
  year = {2009},
  volume = {2},
  pages = {891--898},
  publisher = {{International Foundation for Autonomous Agents and Multiagent Systems}},
  address = {{Richland, SC}}
}

@article{supatto2009quantitative,
  title = {Quantitative Imaging of Collective Cell Migration during {{Drosophila}} Gastrulation: Multiphoton Microscopy and Computational Analysis},
  author = {Supatto, Willy and McMahon, Amy and Fraser, Scott E and Stathopoulos, Angelike},
  year = {2009},
  volume = {4},
  journal = {Nature Protocols},
  number = {10}
}

@inproceedings{Sutherland:1963kq,
  title = {Sketchpad: A Man-Machine Graphical Communication System},
  shorttitle = {Sketchpad},
  booktitle = {Proceedings of the {{May}} 21-23, 1963, Spring Joint Computer Conference on - {{AFIPS}} '63 ({{Spring}})},
  author = {Sutherland, Ivan E.},
  year = {1963},
  pages = {329},
  publisher = {{ACM Press}},
  address = {{Detroit, Michigan}},
  doi = {10.1145/1461551.1461591},
  language = {en}
}

@inproceedings{Sutherland:1968im,
  title = {A Head-Mounted Three Dimensional Display},
  booktitle = {Proceedings of the {{December}} 9-11, 1968, Fall Joint Computer Conference, Part {{I}} on - {{AFIPS}} '68 ({{Fall}}, Part {{I}})},
  author = {Sutherland, Ivan E.},
  year = {1968},
  pages = {757},
  publisher = {{ACM Press}},
  address = {{San Francisco, California}},
  doi = {10.1145/1476589.1476686},
  language = {en}
}

@article{sutherlandSketchpadManmachineGraphical1963,
  title = {Sketchpad: {{A}} Man-Machine Graphical Communication System, {{MRLincoln Laboratory}}},
  author = {Sutherland, I C},
  year = {1963}
}

@article{Swanson:2016ht,
  title = {From {{Cajal}} to {{Connectome}} and {{Beyond}}},
  author = {Swanson, Larry W and Lichtman, Jeff W},
  year = {2016},
  volume = {39},
  doi = {10.1146/annurev-neuro-071714-033954},
  journal = {Annual Review of Neuroscience},
  number = {1}
}

@article{sweldens1998lifting,
  title = {The Lifting Scheme: {{A}} Construction of Second Generation Wavelets},
  author = {Sweldens, Wim},
  year = {1998},
  volume = {29},
  journal = {SIAM journal on mathematical analysis},
  number = {2}
}

@inproceedings{Swirski:2013b12,
  title = {A Fully-Automatic, Temporal Approach to Single Camera, Glint-Free 3d Eye Model Fitting},
  booktitle = {Proceedings of {{ECEM}} 2013},
  author = {Swirski, Lech and Dodgson, Neil A.},
  year = {2013},
  address = {{Lund, Sweden}},
  abstract = {We present a 3D eye model fitting algorithm for use in gaze estimation, that operates on pupil ellipse geometry alone. It works with no user-calibration and does not require calibrated lighting features such as glints. Our algorithm is based on fitting a consistent pupil motion model to a set of eye images. We describe a non-iterative method of initialising this model from detected pupil ellipses, and two methods of iteratively optimising the parameters of the model to best fit the original eye images. We also present a novel eye image dataset~\ldots}
}

@article{swoger2007multi,
  title = {Multi-View Image Fusion Improves Resolution in Three-Dimensional Microscopy},
  author = {Swoger, Jim and Verveer, Peter and Greger, Klaus and Huisken, Jan and Stelzer, Ernst HK},
  year = {2007},
  volume = {15},
  journal = {Optics Express},
  number = {13}
}

@inproceedings{Taylor:19932a5,
  title = {The Nanomanipulator: A Virtual-Reality Interface for a Scanning Tunneling Microscope},
  shorttitle = {The Nanomanipulator},
  booktitle = {Proceedings of the 20th Annual Conference on {{Computer}} Graphics and Interactive Techniques  - {{SIGGRAPH}} '93},
  author = {Taylor, Russell M. and Robinett, Warren and Chi, Vernon L. and Brooks, Frederick P. and Wright, William V. and Williams, R. Stanley and Snyder, Erik J.},
  year = {1993},
  pages = {127--134},
  publisher = {{ACM Press}},
  doi = {10.1145/166117.166133},
  isbn = {978-0-89791-601-1},
  language = {en}
}

@inproceedings{TaylorII:2001bq,
  title = {{{VRPN}}: A Device-Independent, Network-Transparent {{VR}} Peripheral System},
  shorttitle = {{{VRPN}}},
  booktitle = {Proceedings of the {{ACM}} Symposium on {{Virtual}} Reality Software and Technology  - {{VRST}} '01},
  author = {Taylor, Russell M. and Hudson, Thomas C. and Seeger, Adam and Weber, Hans and Juliano, Jeffrey and Helser, Aron T.},
  year = {2001},
  pages = {55},
  publisher = {{ACM Press}},
  address = {{Baniff, Alberta, Canada}},
  doi = {10.1145/505008.505019},
  isbn = {978-1-58113-427-8},
  language = {en}
}

@article{temerinac2011spatially,
  title = {Spatially-Variant {{Lucy}}-{{Richardson}} Deconvolution for Multiview Fusion of Microscopical {{3D}} Images},
  author = {{Temerinac-Ott}, Maja and Ronneberger, Olaf and Nitschke, Roland and Driever, Wolfgang and Burkhardt, Hans},
  year = {2011},
  journal = {Biomedical Imaging: From Nano to Macro, 2011 IEEE International Symposium on}
}

@article{temerinac2012multiview,
  title = {Multiview Deblurring for 3-{{D}} Images from Light-Sheet-Based Fluorescence Microscopy},
  author = {{Temerinac-Ott}, Maja and Ronneberger, Olaf and Ochs, Peter and Driever, Wolfgang and Brox, Thomas and Burkhardt, Hans},
  year = {2012},
  volume = {21},
  journal = {IEEE Transactions on Image Processing},
  number = {4}
}

@article{Theis:2018tw,
  title = {Faster Gaze Prediction with Dense Networks and {{Fisher}} Pruning},
  author = {Theis, Lucas and Korshunova, Iryna and Tejani, Alykhan and Husz{\'a}r, Ferenc},
  year = {2018},
  month = jan,
  abstract = {Predicting human fixations from images has recently seen large improvements by leveraging deep representations which were pretrained for object recognition. However, as we show in this paper, these networks are highly overparameterized for the task of fixation prediction. We first present a simple yet principled greedy pruning method which we call Fisher pruning. Through a combination of knowledge distillation and Fisher pruning, we obtain much more runtime-efficient architectures for saliency prediction, achieving a 10x speedup for the same AUC performance as a state of the art network on the CAT2000 dataset. Speeding up single-image gaze prediction is important for many real-world applications, but it is also a crucial step in the development of video saliency models, where the amount of data to be processed is substantially larger.},
  archivePrefix = {arXiv},
  eprint = {1801.05787},
  eprinttype = {arxiv},
  journal = {arXiv:1801.05787 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Statistics - Machine Learning},
  primaryClass = {cs, stat}
}

@article{Thomson:2010de,
  title = {Neocortical Layer 6, a Review},
  author = {Thomson, Alex M.},
  year = {2010},
  issn = {16625129},
  doi = {10.3389/fnana.2010.00013},
  journal = {Frontiers in Neuroanatomy}
}

@article{tinevez2017,
  title = {{{TrackMate}}: {{An}} Open and Extensible Platform for Single-Particle Tracking},
  author = {Tinevez, Jean-Yves and Perry, Nick and Schindelin, Johannes and Hoopes, Genevieve M. and Reynolds, Gregory D. and Laplantine, Emmanuel and Bednarek, Sebastian Y. and Shorte, Spencer L. and Eliceiri, Kevin W.},
  year = {2017},
  volume = {115},
  doi = {10.1016/j.ymeth.2016.09.016},
  abstract = {We present TrackMate, an open source Fiji plugin for the automated, semi-automated, and manual tracking of single-particles. It offers a versatile and modular solution that works out of the box for end users, through a simple and intuitive user interface. It is also easily scriptable and adaptable, operating equally well on 1D over time, 2D over time, 3D over time, or other single and multi-channel image variants. TrackMate provides several visualization and analysis tools that aid in assessing the relevance of results. The utility of TrackMate is further enhanced through its ability to be readily customized to meet specific tracking problems. TrackMate is an extensible platform where developers can easily write their own detection, particle linking, visualization or analysis algorithms within the TrackMate environment. This evolving framework provides researchers with the opportunity to quickly develop and optimize new algorithms based on existing TrackMate modules without the need of having to write de novo user interfaces, including visualization, analysis and exporting tools. The current capabilities of TrackMate are presented in the context of three different biological problems. First, we perform Caenorhabditis-elegans lineage analysis to assess how light-induced damage during imaging impairs its early development. Our TrackMate-based lineage analysis indicates the lack of a cell-specific light-sensitive mechanism. Second, we investigate the recruitment of NEMO (NF-{$\kappa$}B essential modulator) clusters in fibroblasts after stimulation by the cytokine IL-1 and show that photodamage can generate artifacts in the shape of TrackMate characterized movements that confuse motility analysis. Finally, we validate the use of TrackMate for quantitative lifetime analysis of clathrin-mediated endocytosis in plant cells.},
  journal = {Methods},
  number = {IEEE Signal Proc. Mag. 23 3 2006}
}

@article{tomer2012quantitative,
  title = {Quantitative High-Speed Imaging of Entire Developing Embryos with Simultaneous Multiview Light-Sheet Microscopy},
  author = {Tomer, Raju and Khairy, Khaled and Amat, Fernando and Keller, Philipp J},
  year = {2012},
  volume = {9},
  journal = {Nature Methods},
  number = {7}
}

@article{tosic2011dictionary,
  title = {Dictionary Learning},
  author = {Tosic, Ivana and Frossard, Pascal},
  year = {2011},
  volume = {28},
  journal = {IEEE Signal Processing Magazine},
  number = {2}
}

@article{Traore:2018Interactive,
  title = {Interactive Obstruction-Free Lensing for Volumetric Data Visualization},
  author = {Traore, Michael and Hurter, Christophe and Telea, Alexandru},
  year = {2018},
  volume = {25},
  doi = {10.1109/tvcg.2018.2864690},
  abstract = {Occlusion is an issue in volumetric visualization as it prevents direct visualization of the region of interest. While many techniques such as transfer functions, volume segmentation or view distortion have been developed to address this, there is still room for improvement to better support the understanding of objects' vicinity. However, most existing Focus+Context fail to solve partial occlusion in datasets where the target and the occluder are very similar density-wise. For these reasons, we investigate a new technique which maintains the general structure of the investigated volumetric dataset while addressing occlusion issues. With our technique, the user interactively defines an area of interest where an occluded region or object is partially visible. Then our lens starts pushing at its border occluding objects, thus revealing hidden volumetric data. Next, the lens is modified with an extended field of view (fish-eye deformation) to better see the vicinity of the selected region. Finally, the user can freely explore the surroundings of the area under investigation within the lens. To provide real-time exploration, we implemented our lens using a GPU accelerated ray-casting framework to handle ray deformations, local lighting, and local viewpoint manipulation. We illustrate our technique with five application scenarios in baggage inspection, 3D fluid flow visualization, chest radiology, air traffic planning, and DTI fiber exploration.},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  number = {1}
}

@article{truong2011toward,
  title = {Toward High-Content/High-Throughput Imaging and Analysis of Embryonic Morphogenesis},
  author = {Truong, Thai V and Supatto, Willy},
  year = {2011},
  volume = {49},
  journal = {genesis},
  number = {7}
}

@article{Ukai:20085b2,
  title = {Visual Fatigue Caused by Viewing Stereoscopic Motion Images: {{Background}}, Theories, and Observations},
  author = {Ukai, Kazuhiko and Howarth, Peter A.},
  year = {2008},
  volume = {29},
  doi = {10.1016/j.displa.2007.09.004},
  abstract = {The background, theories, and observations on visual stress possibly caused by viewing stereoscopic motion images are reviewed. Visual fatigue caused by stereoscopic images is a safety issue. Fatigue is possible caused by the discrepancy between accommodative and convergence stimuli that are included in the image. Studies on accommodation and convergence are surveyed and an explanation regarding the characteristics of these functions is offered. Studies in the literature on changes in oculomotor function after viewing stereoscopic images, including changes in pupillary responses, are discussed. Evaluation of visual fatigue, particularly in relation to different methods of viewing stereoscopic displays is described.},
  journal = {Displays},
  number = {2}
}

@article{Ulman:2017objective,
  title = {An Objective Comparison of Cell-Tracking Algorithms},
  author = {Ulman, Vladim{\'i}r and Ma{\v s}ka, Martin and Magnusson, Klas E G and Ronneberger, Olaf and Haubold, Carsten and Harder, Nathalie and Matula, Pavel and Matula, Petr and Svoboda, David and Radojevic, Miroslav and Smal, Ihor and Rohr, Karl and Jald{\'e}n, Joakim and Blau, Helen M and Dzyubachyk, Oleh and Lelieveldt, Boudewijn and Xiao, Pengdong and Li, Yuexiang and Cho, Siu-Yeung and Dufour, Alexandre C and {Olivo-Marin}, Jean-Christophe and {Reyes-Aldasoro}, Constantino C and {Solis-Lemus}, Jose A and Bensch, Robert and Brox, Thomas and Stegmaier, Johannes and Mikut, Ralf and Wolf, Steffen and Hamprecht, Fred A and Esteves, Tiago and Quelhas, Pedro and Demirel, {\"O}mer and Malmstr{\"o}m, Lars and Jug, Florian and Tomancak, Pavel and Meijering, Erik and {Mu{\~n}oz-Barrutia}, Arrate and Kozubek, Michal and {Ortiz-de-Solorzano}, Carlos},
  year = {2017},
  month = dec,
  volume = {14},
  pages = {1141--1152},
  issn = {1548-7091, 1548-7105},
  doi = {10.1038/nmeth.4473},
  abstract = {SEG and TRA evaluate results in terms of similarity to the ground truth and are particularly relevant for comparing algorithms with one another. Method developers use such measures to show the superiority of new methods over current state-of-the-art methods.},
  journal = {Nature Methods},
  language = {en},
  number = {12}
}

@article{unser1993b,
  title = {B-Spline Signal Processing. {{II}}. {{Efficiency}} Design and Applications},
  author = {Unser, Michael and Aldroubi, Akram and Eden, Murray},
  year = {1993},
  volume = {41},
  journal = {IEEE transactions on signal processing},
  number = {2}
}

@article{unser1996review,
  title = {A Review of Wavelets in Biomedical Applications},
  author = {Unser, Michael and Aldroubi, Akram},
  year = {1996},
  volume = {84},
  journal = {Proceedings of the IEEE},
  number = {4}
}

@article{Usher:2017bda,
  title = {A {{Virtual Reality Visualization Tool}} for {{Neuron Tracing}}},
  author = {Usher, Will and Klacansky, Pavol and Federer, Frederick and Bremer, Peer-Timo and Knoll, Aaron and Yarch, Jeff and Angelucci, Alessandra and Pascucci, Valerio},
  year = {2017},
  volume = {24},
  doi = {10.1109/tvcg.2017.2744079},
  abstract = {Tracing neurons in large-scale microscopy data is crucial to establishing a wiring diagram of the brain, which is needed to understand how neural circuits in the brain process information and generate behavior. Automatic techniques often fail for large and complex datasets, and connectomics researchers may spend weeks or months manually tracing neurons using 2D image stacks. We present a design study of a new virtual reality (VR) system, developed in collaboration with trained neuroanatomists, to trace neurons in microscope scans of the visual cortex of primates. We hypothesize that using consumer-grade VR technology to interact with neurons directly in 3D will help neuroscientists better resolve complex cases and enable them to trace neurons faster and with less physical and mental strain. We discuss both the design process and technical challenges in developing an interactive system to navigate and manipulate terabyte-sized image volumes in VR. Using a number of different datasets, we demonstrate that, compared to widely used commercial software, consumer-grade VR presents a promising alternative for scientists.},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  number = {1}
}

@article{van1998image,
  title = {Image Detectors for Digital Image Microscopy},
  author = {Vliet, Lucas J Van and Boddeke, Frank R and Sudar, Damir and Young, Ian T},
  year = {1998},
  journal = {Digital Image Analysis of Microbes: Imaging, Morphometry, Fluorometry, and Motility Techniques and Applications}
}

@article{vasilyev2000second,
  title = {Second-Generation Wavelet Collocation Method for the Solution of Partial Differential Equations},
  author = {Vasilyev, Oleg V and Bowman, Christopher},
  year = {2000},
  volume = {165},
  journal = {Journal of Computational Physics},
  number = {2}
}

@article{verveer2007high,
  title = {High-Resolution Three-Dimensional Imaging of Large Specimens with Light Sheet--Based Microscopy},
  author = {Verveer, Peter J and Swoger, Jim and Pampaloni, Francesco and Greger, Klaus and Marcello, Marco and Stelzer, Ernst HK},
  year = {2007},
  volume = {4},
  journal = {Nature Methods},
  number = {4}
}

@incollection{vicidomini2005image,
  title = {Image {{Formation}} in {{Fluorescence Microscopy}}},
  author = {Vicidomini, Giuseppe},
  year = {2005}
}

@inproceedings{Vidal:2013Pursuits,
  title = {Pursuits: Spontaneous Interaction with Displays Based on Smooth Pursuit Eye Movement and Moving Targets},
  shorttitle = {Pursuits},
  booktitle = {Proceedings of the 2013 {{ACM}} International Joint Conference on {{Pervasive}} and Ubiquitous Computing - {{UbiComp}} '13},
  author = {Vidal, M{\'e}lodie and Bulling, Andreas and Gellersen, Hans},
  year = {2013},
  pages = {439},
  publisher = {{ACM Press}},
  address = {{Zurich, Switzerland}},
  doi = {10.1145/2493432.2493477},
  abstract = {Although gaze is an attractive modality for pervasive interactions, the real-world implementation of eye-based interfaces poses significant challenges, such as calibration. We present Pursuits, an innovative interaction technique that enables truly spontaneous interaction with eye-based interfaces. A user can simply walk up to the screen and readily interact with moving targets. Instead of being based on gaze location, Pursuits correlates eye pursuit movements with objects dynamically moving on the interface. We evaluate the influence of target speed, number and trajectory and develop guidelines for designing Pursuits-based interfaces. We then describe six realistic usage scenarios and implement three of them to evaluate the method in a usability study and a field study. Our results show that Pursuits is a versatile and robust technique and that users can interact with Pursuits-based interfaces without prior knowledge or preparation phase.},
  isbn = {978-1-4503-1770-2},
  language = {en}
}

@article{Vogel:2003dv,
  title = {Mechanisms of {{Pulsed Laser Ablation}} of {{Biological Tissues}}},
  author = {Vogel, Alfred and Venugopalan, Vasan},
  year = {2003},
  volume = {103},
  doi = {10.1021/cr010379n},
  journal = {Chemical Reviews},
  number = {2}
}

@article{vonZadow:2017di,
  title = {{{GIAnT}}},
  author = {von Zadow, Ulrich and Dachselt, Raimund},
  year = {2017},
  doi = {10.1145/3025453.3026006},
  journal = {the 2017 CHI Conference}
}

@article{vovkSimulatorSicknessAugmented2018,
  title = {Simulator {{Sickness}} in {{Augmented Reality Training Using}} the {{Microsoft HoloLens}}},
  author = {Vovk, Alla and Wild, Fridolin and Guest, Will and Kuula, Timo},
  year = {2018},
  abstract = {Augmented Reality is on the rise with consumer-grade smart glasses becoming available in recent years. Those interested in deploying these head-mounted displays need to understand better the effect technology has on the end user. One key aspect potentially hindering the use is motion sickness, a known problem inherited from virtual reality, which so far remains under-explored. In this paper we address this problem by conducting an experiment with 142 subjects in three different industries: aviation, medical, and space. We evaluate whether the Microsoft HoloLens, an augmented reality head-mounted display, causes simulator sickness and how different symptom groups contribute to it (nausea, oculomotor and disorientation). Our findings suggest that the Microsoft HoloLens causes across all participants only negligible symptoms of simulator sickness. Most consumers who use it will face no symptoms while only few experience minimal discomfort in the training environments we tested it in.}
}

@article{wagnerInstantaneousIsotropicVolumetric2019,
  title = {Instantaneous Isotropic Volumetric Imaging of Fast Biological Processes},
  author = {Wagner, Nils and Norlin, Nils and Gierten, Jakob and de Medeiros, Gustavo and Bal{\'a}zs, B{\'a}lint and Wittbrodt, Joachim and Hufnagel, Lars and Prevedel, Robert},
  year = {2019},
  doi = {10.1038/s41592-019-0393-z},
  abstract = {Iso-LFM enables rapid, instantaneous volumetric imaging of biological processes with isotropic and improved resolution by simultaneously capturing orthogonal light fields.},
  journal = {Nature Methods}
}

@article{wait2014visualization,
  title = {Visualization and Correction of Automated Segmentation, Tracking and Lineaging from 5-{{D}} Stem Cell Image Sequences},
  author = {Wait, Eric and Winter, Mark and Bjornsson, Chris and Kokovay, Erzsebet and Wang, Yue and Goderie, Susan and Temple, Sally and Cohen, Andrew R},
  year = {2014},
  volume = {15},
  journal = {BMC Bioinformatics},
  number = {1}
}

@article{Wald:2014db,
  title = {Embree},
  author = {Wald, Ingo and Woop, Sven and Benthin, Carsten and Johnson, Gregory S and Ernst, Manfred},
  year = {2014},
  volume = {33},
  doi = {10.1145/2601097.2601199},
  journal = {ACM Transactions on Graphics},
  number = {4}
}

@article{Wald:2017ee,
  title = {{{OSPRay}} - {{A CPU Ray Tracing Framework}} for {{Scientific Visualization}}},
  author = {Wald, Ingo and Johnson, GP and Amstutz, Jefferson and Brownlee, Carson and Knoll, Aaron M. and Jeffers, Jim and G{\"u}nther, Johannes and Navratil, Paul Arthur},
  year = {2017},
  month = jan,
  volume = {23},
  pages = {931--940},
  issn = {1077-2626},
  doi = {10.1109/TVCG.2016.2599041},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  number = {1}
}

@article{Wang:2016fz,
  title = {Thermographic Eye Tracking},
  author = {Wang, Quan and Boccanfuso, Laura and Li, Beibin and Ahn, Amy Yeo-jin and Foster, Claire E and Orr, Margaret P and Scassellati, Brian and Shic, Frederick},
  year = {2016},
  doi = {10.1145/2857491.2857543},
  journal = {the Ninth Biennial ACM Symposium}
}

@article{wang1994active,
  title = {Active Mesh-a Feature Seeking and Tracking Image Sequence Representation Scheme},
  author = {Wang, Yao and Lee, Ouseb},
  year = {1994},
  volume = {3},
  journal = {IEEE Transactions on Image Processing},
  number = {5}
}

@article{wang1996use,
  title = {Use of Two-Dimensional Deformable Mesh Structures for Video Coding. {{II}}. {{The}} Analysis Problem and a Region-Based Coder Employing an Active Mesh Representation},
  author = {Wang, Yao and Lee, Ouseb and Vetro, Anthony},
  year = {1996},
  volume = {6},
  journal = {IEEE Transactions on circuits and systems for video technology},
  number = {6}
}

@article{Weber:2012kw,
  title = {Omnidirectional Microscopy.},
  author = {Weber, Michael and Huisken, Jan},
  year = {2012},
  volume = {9},
  doi = {10.1038/nmeth.2022},
  journal = {Nature Methods},
  number = {7}
}

@article{weber2011light,
  title = {Light Sheet Microscopy for Real-Time Developmental Biology},
  author = {Weber, Michael and Huisken, Jan},
  year = {2011},
  volume = {21},
  journal = {Current opinion in genetics and development},
  number = {5}
}

@article{weigert2017care,
  title = {Content-Aware Image Restoration: Pushing the Limits of Fluorescence Microscopy},
  author = {Weigert, Martin and Schmidt, Uwe and Boothe, Tobias and M{\"u}ller, Andreas and Dibrov, Alexandr and Jain, Akanksha and Wilhelm, Benjamin and Schmidt, Deborah and Broaddus, Coleman and Culley, Si{\^a}n and {Rocha-Martins}, Mauricio and {Segovia-Miranda}, Fabi{\'a}n and Norden, Caren and Henriques, Ricardo and Zerial, Marino and Solimena, Michele and Rink, Jochen and Tomancak, Pavel and Royer, Lo{\"i}c A and Jug, Florian and Myers, Eugene W.},
  year = {2018},
  volume = {15},
  doi = {10.1038/s41592-018-0216-7},
  abstract = {Fluorescence microscopy is a key driver of discoveries in the life sciences, with observable phenomena being limited by the optics of the microscope, the chemistry of the fluorophores, and the maximum photon exposure tolerated by the sample. These limits necessitate trade-offs between imaging speed, spatial resolution, light exposure, and imaging depth. In this work we show how content-aware image restoration based on deep learning extends the range of biological phenomena observable by microscopy. We demonstrate on eight concrete examples how microscopy images can be restored even if 60-fold fewer photons are used during acquisition, how near isotropic resolution can be achieved with up to tenfold under-sampling along the axial direction, and how tubular and granular structures smaller than the diffraction limit can be resolved at 20-times-higher frame rates compared to state-of-the-art methods. All developed image restoration methods are freely available as open source software in Python, FIJI, and KNIME. Content-aware image restoration (CARE) uses deep learning to improve microscopy images. CARE bypasses the trade-offs between imaging speed, resolution, and maximal light exposure that limit fluorescence imaging to enable discovery.},
  journal = {Nature Methods},
  number = {12}
}

@article{weigert2017careOpen,
  title = {Content-{{Aware Image Restoration}}: {{Pushing}} the {{Limits}} of {{Fluorescence Microscopy}}},
  author = {Weigert, Martin and Schmidt, Uwe and Boothe, Tobias and M{\"u}ller, Andreas and Dibrov, Alexandr and Jain, Akanksha and Wilhelm, Benjamin and Schmidt, Deborah and Broaddus, Coleman and Culley, Si{\^a}n and {Rocha-Martins}, Maur{\'i}cio and {Segovia-Miranda}, Fabi{\'a}n and Norden, Caren and Henriques, Ricardo and Zerial, Marino and Solimena, Michele and Rink, Jochen and Tomancak, Pavel and Royer, Lo{\"i}c A and Jug, Florian and Myers, Eugene W.},
  year = {2017},
  doi = {10.1101/236463},
  abstract = {Fluorescence microscopy is a key driver of discoveries in the life-sciences, with observable phenomena being limited by the optics of the microscope, the chemistry of the fluorophores, and the maximum photon exposure tolerated by the sample. These limits necessitate trade-offs between imaging speed, spatial resolution, light exposure, and imaging depth. In this work we show how image restoration based on deep learning extends the range of biological phenomena observable by microscopy. On seven concrete examples we demonstrate how microscopy images can be restored even if 60-fold fewer photons are used during acquisition, how near isotropic resolution can be achieved with up to 10-fold under-sampling along the axial direction, and how tubular and granular structures smaller than the diffraction limit can be resolved at 20-times higher frame-rates compared to state-of-the-art methods. All developed image restoration methods are freely available as open source software in Python, FIJI, and KNIME.},
  journal = {bioRxiv}
}

@article{weigert2017isotropic,
  title = {Isotropic Reconstruction of {{3D}} Fluorescence Microscopy Images Using Convolutional Neural Networks},
  author = {Weigert, Martin and Royer, Lo{\"i}c A and Jug, Florian and Myers, Gene},
  year = {2017},
  archivePrefix = {arXiv},
  eprint = {1704.01510},
  eprinttype = {arxiv},
  journal = {arXiv preprint arXiv:1704.01510}
}

@article{Westheimer:2009e66,
  title = {The Third Dimension in the Primary Visual Cortex},
  author = {Westheimer, Gerald},
  year = {2009},
  volume = {587},
  doi = {10.1113/jphysiol.2009.170175},
  abstract = {Anatomical superposition of the cortical projections from the overlapping visual fields of the two eyes does not make it obvious how the disposition of objects in the third dimension is encoded. Hubel and Wiesel's demonstration that units in the primary visual cortex of the mammal respond preferentially to elongated contours of specific orientation encouraged the inquiry into whether binocular disparity might not similarly be represented as an attribute interdigitated within the orderly progression of position. When this was found to indeed be the case, this entrained a brisk research activity into the disparity of receptive fields of single units in the primary visual cortex and the influence on their response of the three-dimensional locations of outside world stimuli. That cells' preferred orientations covered the whole gamut whereas space perception required only horizontal disparity was an apparent paradox that needed resolution. A connection with an observer's stereoscopic performance was made by the discovery that cells in the primate primary visual cortex display good tuning to the disparity in random-dot stereograms. But a wide gap still remains between the properties of these cortical units and human stereo thresholds in simple target configurations, let alone depth judgments in which perceptual and cognitive factors enter. When the neural circuits in the primary visual cortex that are involved in processing depth are eventually traced in detail they will also need to have properties that allow for the plasticity in learning and experience.},
  journal = {The Journal of Physiology},
  number = {12}
}

@article{Wetzstein:2013jo,
  title = {On {{Plenoptic Multiplexing}} and {{Reconstruction}}},
  author = {Wetzstein, Gordon and Ihrke, Ivo and Heidrich, Wolfgang},
  year = {2013},
  volume = {101},
  doi = {10.1007/s11263-012-0585-9},
  abstract = {Photography has been striving to capture an ever increasing amount of visual information in a single image. Digital sensors, however, are limited to recording a small subset of the desired information at each pixel. A common approach to overcoming the},
  journal = {International Journal of Computer Vision},
  number = {2}
}

@article{White:2009bu,
  title = {Color-{{Related Signals}} in the {{Primate Superior Colliculus}}},
  author = {White, B J and Boehnke, S E and Marino, R A and Itti, L and Munoz, D P},
  year = {2009},
  volume = {29},
  doi = {10.1523/jneurosci.1986-09.2009},
  journal = {The Journal of neuroscience : the official journal of the Society for Neuroscience},
  number = {39}
}

@article{Whittinghill:2015581,
  title = {Nasum Virtualis: {{A}} Simple Technique for Reducing Simulator Sickness},
  author = {Whittinghill, David Matthew and Ziegler, Bradley and Case, Tristan and Moore, James},
  year = {2015},
  journal = {Games Developers Conference (GDC)}
}

@article{Wilson:2018b12,
  title = {Evolving Simple Programs for Playing Atari Games},
  author = {Wilson, Dennis G and {Cussat-Blanc}, Sylvain and Luga, Herv{\'e} and Miller, Julian F},
  year = {2018},
  abstract = {Cartesian Genetic Programming (CGP) has previously shown capabilities in image processing tasks by evolving programs with a function set specialized for computer vision. A similar approach can be applied to Atari playing. Programs are evolved using mixed type CGP with a function set suited for matrix operations, including image processing, but allowing for controller behavior to emerge. While the programs are relatively small, many controllers are competitive with state of the art methods for the Atari benchmark set and require less training time. By evaluating the programs of the best evolved individuals, simple but effective strategies can be found.}
}

@article{Wilson:2018cd7,
  title = {Neuromodulated {{Learning}} in {{Deep Neural Networks}}},
  author = {Wilson, Dennis G and {Cussat-Blanc}, Sylvain and Luga, Herv{\'e} and Harrington, Kyle I.S.},
  year = {2018},
  abstract = {In the brain, learning signals change over time and synaptic location, and are applied based on the learning history at the synapse, in the complex process of neuromodulation. Learning in artificial neural networks, on the other hand, is shaped by hyper-parameters set before learning starts, which remain static throughout learning, and which are uniform for the entire network. In this work, we propose a method of deep artificial neuromodulation which applies the concepts of biological neuromodulation to stochastic gradient descent. Evolved neuromodulatory dynamics modify learning parameters at each layer in a deep neural network over the course of the network's training. We show that the same neuromodulatory dynamics can be applied to different models and can scale to new problems not encountered during evolution. Finally, we examine the evolved neuromodulation, showing that evolution found dynamic, location-specific learning strategies.}
}

@article{Wingrave:wx,
  title = {Reflecting on the Design and Implementation Issues of Virtual Environments},
  author = {Wingrave, C A and Presence, JJ LaViola and 2, 0},
  abstract = {We present a candid reflection on the issues surrounding virtual environment design and implementation (VEDI) in order to:(1) motivate the topic as a researchworthy undertaking, and (2) attempt a comprehensive listing of impeding VEDI issues so they can be addressed. In order to structure this reflection, an idealized model of VEDI is presented. This model, investigated using mixed methods, resulted in 67 distinct issues along the model's transitions and pathways. These were clustered into 11 themes and used to support five~\ldots},
  journal = {ieeexplore.ieee.org}
}

@article{witkin1984scale,
  title = {Scale-Space Filtering: {{A}} New Approach to Multi-Scale Description},
  author = {Witkin, Andrew},
  year = {1984},
  volume = {9},
  journal = {Acoustics, Speech, and Signal Processing, IEEE International Conference on ICASSP'84.}
}

@article{wolff2017reconstruction,
  title = {Reconstruction of Cell Lineages and Behaviors Underlying Arthropod Limb Outgrowth with Multi-View Light-Sheet Imaging and Tracking},
  author = {Wolff, Carsten and Tinevez, Jean-Yves and Pietzsch, Tobias and Stamataki, Evangelia and Harich, Benjamin and Preibisch, Stephan and Shorte, Spencer and Keller, Philipp J and Tomancak, Pavel and Pavlopoulos, Anastasios},
  year = {2017},
  journal = {bioRxiv}
}

@article{wolff2018,
  title = {Multi-View Light-Sheet Imaging and Tracking with the {{MaMuT}} Software Reveals the Cell Lineage of a Direct Developing Arthropod Limb},
  author = {Wolff, Carsten and Tinevez, Jean-Yves and Pietzsch, Tobias and Stamataki, Evangelia and Harich, Benjamin and Guignard, L{\'e}o and Preibisch, Stephan and Shorte, Spencer and Keller, Philipp J and Tomancak, Pavel and Pavlopoulos, Anastasios},
  year = {2018},
  volume = {7},
  doi = {10.7554/elife.34410},
  abstract = {During development, coordinated cell behaviors orchestrate tissue and organ morphogenesis. Detailed descriptions of cell lineages and behaviors provide a powerful framework to elucidate the mechanisms of morphogenesis. To study the cellular basis of limb development, we imaged transgenic fluorescently-labeled embryos from the crustacean Parhyale hawaiensis with multi-view light-sheet microscopy at high spatiotemporal resolution over several days of embryogenesis. The cell lineage of outgrowing thoracic limbs was reconstructed at single-cell resolution with new software called Massive Multi-view Tracker (MaMuT). In silico clonal analyses suggested that the early limb primordium becomes subdivided into anterior-posterior and dorsal-ventral compartments whose boundaries intersect at the distal tip of the growing limb. Limb-bud formation is associated with spatial modulation of cell proliferation, while limb elongation is also driven by preferential orientation of cell divisions along the proximal-distal growth axis. Cellular reconstructions were predictive of the expression patterns of limb development genes including the BMP morphogen Decapentaplegic.},
  journal = {eLife}
}

@article{woodward2001powerwall,
  title = {Powerwall},
  author = {Woodward, Paul and Ruwart, T and Porter, D and Edgar, K and Anderson, S and Palmer, M and Cattelan, R and Jacobson, T and Stromberg, J and Varghese, T},
  year = {2001},
  journal = {University of Minnesota}
}

@article{Workshop:uc,
  title = {{{SWIG}} : {{An Easy}} to {{Use Tool For Integrating Scripting Languages}} with {{C}} and {{C}}++},
  author = {Beazley, David M.},
  year = {1996},
  abstract = {Abstract I present SWIG (Simplified Wrapper and Interface Generator), a program development tool that automatically generates the bindings between C/C++ code and common scripting languages including Tcl, Python, Perl and Guile. SWIG supports most~\ldots},
  journal = {usenix.org}
}

@article{Wu:2015kt,
  title = {A Visual Attention-Based Method to Address the Midas Touch Problem Existing in Gesture-Based Interaction},
  author = {Wu, Huiyue and Wang, Jianmin},
  year = {2015},
  volume = {32},
  doi = {10.1007/s00371-014-1060-0},
  journal = {The Visual Computer},
  number = {1}
}

@article{wuNeuralSceneDerendering2017,
  title = {Neural {{Scene De}}-Rendering},
  author = {Wu, Jiajun and Tenenbaum, Joshua B. and Kohli, Pushmeet},
  year = {2017},
  abstract = {We study the problem of holistic scene understanding. We would like to obtain a compact, expressive, and interpretable representation of scenes that encodes information such as the number of objects and their categories, poses, positions, etc. Such a representation would allow us to reason about and even reconstruct or manipulate elements of the scene. Previous works have used encoder-decoder based neural architectures to learn image representations; however, representations obtained in this way are typically uninterpretable, or only explain a single object in the scene. In this work, we propose a new approach to learn an interpretable distributed representation of scenes. Our approach employs a deterministic rendering function as the decoder, mapping a naturally structured and disentangled scene description, which we named scene XML, to an image. By doing so, the encoder is forced to perform the inverse of the rendering operation (a.k.a. de-rendering) to transform an input image to the structured scene XML that the decoder used to produce the image. We use a object proposal based encoder that is trained by minimizing both the supervised prediction and the unsupervised reconstruction errors. Experiments demonstrate that our approach works well on scene de-rendering with two different graphics engines, and our learned representation can be easily adapted for a wide range of applications like image editing, inpainting, visual analogy-making, and image captioning.}
}

@article{wuStreamExplorerMultiStageSystem2017,
  title = {{{StreamExplorer}}: {{A Multi}}-{{Stage System}} for {{Visually Exploring Events}} in {{Social Streams}}},
  author = {Wu, Yingcai and Chen, Zhutian and Sun, Guodao and Xie, Xiao and Cao, Nan and Liu, Shixia and Cui, Weiwei},
  year = {2017},
  volume = {24},
  doi = {10.1109/tvcg.2017.2764459},
  abstract = {Analyzing social streams is important for many applications, such as crisis management. However, the considerable diversity, increasing volume, and high dynamics of social streams of large events continue to be significant challenges that must be overcome to ensure effective exploration. We propose a novel framework by which to handle complex social streams on a budget PC. This framework features two components: 1) an online method to detect important time periods (i.e., subevents), and 2) a tailored GPU-assisted Self-Organizing Map (SOM) method, which clusters the tweets of subevents stably and efficiently. Based on the framework, we present StreamExplorer to facilitate the visual analysis, tracking, and comparison of a social stream at three levels. At a macroscopic level, StreamExplorer uses a new glyph-based timeline visualization, which presents a quick multi-faceted overview of the ebb and flow of a social stream. At a mesoscopic level, a map visualization is employed to visually summarize the social stream from either a topical or geographical aspect. At a microscopic level, users can employ interactive lenses to visually examine and explore the social stream from different perspectives. Two case studies and a task-based evaluation are used to demonstrate the effectiveness and usefulness of StreamExplorer.},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  number = {10}
}

@article{yang2003fast,
  title = {A Fast Approach for Accurate Content-Adaptive Mesh Generation},
  author = {Yang, Yongyi and Wernick, Miles N. and Brankov, Jovan G.},
  year = {2003},
  month = aug,
  volume = {12},
  pages = {866--881},
  issn = {1057-7149},
  doi = {10.1109/TIP.2003.812757},
  journal = {IEEE Transactions on Image Processing},
  language = {en},
  number = {8}
}

@article{Yazdanbakhsh:2006ec0,
  title = {End Stopping in {{V1}} Is Sensitive to Contrast},
  author = {Yazdanbakhsh, Arash and Livingstone, Margaret S},
  year = {2006},
  volume = {9},
  doi = {10.1038/nn1693},
  abstract = {Common situations that result in different perceptions of grouping and border ownership, such as shadows and occlusion, have distinct sign-of-contrast relationships at their edge-crossing junctions. Here we report a property of end stopping in V1 that distinguishes among different sign-of-contrast situations, thereby obviating the need for explicit junction detectors. We show that the inhibitory effect of the end zones in end-stopped cells is highly selective for the relative sign of contrast between the central activating stimulus and stimuli presented at the end zones. Conversely, the facilitatory effect of end zones in length-summing cells is not selective for the relative sign of contrast between the central activating stimulus and stimuli presented at the end zones. This finding indicates that end stopping belongs in the category of cortical computations that are selective for sign of contrast, such as direction selectivity and disparity selectivity, but length summation does not.},
  journal = {Nature Neuroscience},
  number = {5}
}

@article{yuMassivelyParallelVolume2008,
  title = {Massively Parallel Volume Rendering Using 2--3 Swap Image Compositing},
  author = {Yu, Hongfeng and Wang, Chaoli and Ma, Kwan-Liu},
  year = {2008},
  doi = {10.1145/1508044.1508084}
}

@article{Zeng:201201f,
  title = {Fitts' {{Law}} in {{3D Space}} with {{Coordinated Hand Movements}}},
  author = {Zeng, Xiaolu and Hedge, Alan and Guimbretiere, Francois},
  year = {2012},
  volume = {56},
  doi = {10.1177/1071181312561207},
  abstract = {The study tested the applicability of Fitts' law to coordinated hand movements in a 3D response space with. An experiment was conducted in which 20 participants performed the Fitts' pointing tasks with varying target distances, target sizes and approaching angles from a home position. Results confirmed that Fitts' law applies to coordinated hand movements in 3D space.},
  journal = {Proceedings of the Human Factors and Ergonomics Society Annual Meeting},
  number = {1}
}

@inproceedings{Zhang:2008ex,
  title = {Improving Eye Cursor's Stability for Eye Pointing Tasks},
  booktitle = {Proceeding of the Twenty-Sixth Annual {{CHI}} Conference on {{Human}} Factors in Computing Systems  - {{CHI}} '08},
  author = {Zhang, Xinyong and Ren, Xiangshi and Zha, Hongbin},
  year = {2008},
  pages = {525},
  publisher = {{ACM Press}},
  address = {{Florence, Italy}},
  doi = {10.1145/1357054.1357139},
  isbn = {978-1-60558-011-1},
  language = {en}
}

@article{zhao2002lossless,
  title = {Lossless Compression of Very Large Volume Data with Fast Dynamic Access},
  author = {Zhao, Rongkai and Tao, Tao and Gabriel, Michael and Belford, Geneva G},
  year = {2002},
  volume = {4925},
  journal = {Proc. SPIE}
}

@article{Zigolle:2014ase,
  title = {A {{Survey}} of {{Efficient Representations}} for {{Independent Unit Vectors}}},
  author = {Cigolle, Zina and Donow, Sam and Evangelakos, Daniel and Mara, Michael and McGuire, Morgan and Meyer, Quirin},
  year = {2014},
  volume = {3},
  journal = {Journal of Computer Graphics Techniques}
}

@article{Zimmerman:19875d6,
  title = {A Hand Gesture Interface Device},
  author = {Zimmerman, Thomas G. and Lanier, Jaron and Blanchard, Chuck and Bryson, Steve and Harvill, Young},
  year = {1987},
  volume = {18},
  doi = {10.1145/29933.275628},
  abstract = {This paper reports on the development of a hand to machine interface device that provides real-time gesture, position and orientation information. The key element is a glove and the device as a whole incorporates a collection of technologies. Analog flex sensors on the glove measure finger bending. Hand position and orientation are measured either by ultrasonics, providing five degrees of freedom, or magnetic flux sensors, which provide six degrees of freedom. Piezoceramic benders provide the wearer of the glove with tactile feedback. These sensors are mounted on the light-weight glove and connected to the driving hardware via a small cable. Applications of the glove and its component technologies include its use in conjunction with a host computer which drives a real-time 3-dimensional model of the hand allowing the glove wearer to manipulate computer-generated objects as if they were real, interpretation of finger-spelling, evaluation of hand impairment in addition to providing an interface to a visual programming language.},
  journal = {ACM SIGCHI Bulletin},
  number = {4}
}

@article{Zimmermann:2016hv,
  title = {Oculomatic: {{High}} Speed, Reliable, and Accurate Open-Source Eye Tracking for Humans and Non-Human Primates},
  author = {Zimmermann, Jan and Vazquez, Yuriria and Glimcher, Paul W and Pesaran, Bijan and Louie, Kenway},
  year = {2016},
  volume = {270},
  doi = {10.1016/j.jneumeth.2016.06.016},
  abstract = {Journal of Neuroscience Methods, 270 (2016) 138-146. doi:10.1016/j.jneumeth.2016.06.016},
  journal = {Journal of Neuroscience Methods}
}


